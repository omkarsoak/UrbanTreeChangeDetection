{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize"
      ],
      "metadata": {
        "id": "_iVsWd1M7VIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "\n",
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize the library.\n",
        "ee.Initialize(project='ee-nazrerukmini')"
      ],
      "metadata": {
        "id": "yJoUC6vZ6Rar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate TIF (NDVI)"
      ],
      "metadata": {
        "id": "zZbxMUaJEk0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process a single point\n",
        "def process_point(lon, lat, city, state, year, filename):\n",
        "    # Define the center point\n",
        "    center = ee.Geometry.Point([lon, lat])\n",
        "\n",
        "    # Define the bounding box with a buffer radius (2560 meters for 512x512 pixels at 10m resolution)\n",
        "    geometry = center.buffer(2560).bounds()\n",
        "\n",
        "    # Load Sentinel-2 MSI Level-2A as ImageCollection\n",
        "    sentinel2 = (ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
        "                 .filterBounds(geometry)\n",
        "                 .filterDate(f'{year}-07-01', f'{year}-09-30')\n",
        "                 .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 3))\n",
        "                 .median())\n",
        "\n",
        "    # Calculate NDVI\n",
        "    ndvi = sentinel2.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
        "\n",
        "    # Classify NDVI into three categories\n",
        "    ndvi_classified = ndvi.expression(\n",
        "        \"(ndvi < 0.4) ? 1 : (ndvi <= 0.7) ? 2 : 3\",\n",
        "        {'ndvi': ndvi}\n",
        "    ).rename('NDVI_Classified')\n",
        "\n",
        "    # Visualization parameters for the classified NDVI\n",
        "    ndvi_class_vis = {\n",
        "        'min': 1,\n",
        "        'max': 3,\n",
        "        'palette': ['white', 'lightgreen', 'darkgreen']  # Assign colors to each class\n",
        "    }\n",
        "\n",
        "    # Enhance each band by a different factor\n",
        "    enhanced_rgb = (sentinel2.select(['B4', 'B3', 'B2']).multiply(2.0))\n",
        "\n",
        "    viz_params = {\n",
        "        'bands': ['B4', 'B3', 'B2'],\n",
        "        'min': 0,\n",
        "        'max': 3000,\n",
        "        'gamma': 1\n",
        "    }\n",
        "\n",
        "    # Export EnhancedRGB Layer to Google Drive\n",
        "    enhanced_rgb_task = ee.batch.Export.image.toDrive(\n",
        "        image=enhanced_rgb.clip(geometry).visualize(**viz_params),\n",
        "        description=f'EnhancedRGB_{filename}_{year}',\n",
        "        #folder=year,\n",
        "        fileNamePrefix=f'{filename}_{year}',\n",
        "        region=geometry,\n",
        "        fileFormat='GEOTIFF',\n",
        "        crs='EPSG:3857',\n",
        "        dimensions='512x512'\n",
        "    )\n",
        "    enhanced_rgb_task.start()\n",
        "\n",
        "    # Export the classified NDVI as a single-band image\n",
        "    ndvi_classified_task = ee.batch.Export.image.toDrive(\n",
        "        image=ndvi_classified.clip(geometry),\n",
        "        description=f'NDVI_Classified_{filename}_{year}',\n",
        "        #folder=year,\n",
        "        fileNamePrefix=f'm_NDVI_{filename}_{year}',\n",
        "        region=geometry,\n",
        "        fileFormat='GEOTIFF',\n",
        "        crs='EPSG:3857',\n",
        "        dimensions='512x512'\n",
        "    )\n",
        "    ndvi_classified_task.start()\n",
        "\n",
        "    print(f\"Tasks started for {city} at ({lon}, {lat}).\")\n"
      ],
      "metadata": {
        "id": "Nuh4CY7-BHS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##COMBINED RGB + MASK SVM"
      ],
      "metadata": {
        "id": "w4q8Elxgt69h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_point_2(lon, lat, city, state, year, filename):\n",
        "    # Define the center point\n",
        "    center = ee.Geometry.Point([lon, lat])\n",
        "\n",
        "    # Define the bounding box with a buffer radius (2560 meters for 512x512 pixels at 10m resolution)\n",
        "    geometry = center.buffer(2560).bounds()\n",
        "\n",
        "    # Load Sentinel-2 MSI Level-2A as ImageCollection\n",
        "    sentinel2 = (ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
        "                 .filterBounds(geometry)\n",
        "                 .filterDate(f'{year}-07-01', f'{year}-09-30')\n",
        "                 .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 3))\n",
        "                 .median())\n",
        "\n",
        "    # Calculate indices and masks\n",
        "    ndvi = sentinel2.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
        "    ndwi = sentinel2.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
        "    swm = sentinel2.expression(\n",
        "        '(B2 + B3) / (B8 + B11)',\n",
        "        {\n",
        "            'B2': sentinel2.select('B2'),\n",
        "            'B3': sentinel2.select('B3'),\n",
        "            'B8': sentinel2.select('B8'),\n",
        "            'B11': sentinel2.select('B11')\n",
        "        }\n",
        "    ).rename('SWM')\n",
        "\n",
        "    # Combine NDVI and NDWI into a single image for sampling\n",
        "    feature_image = ndvi.addBands(ndwi)\n",
        "\n",
        "    # Define class masks\n",
        "    water_mask = swm.gt(1.5)\n",
        "    building_mask = ndvi.gt(0.0).And(ndvi.lt(0.4))\n",
        "    sparse_veg_mask = ndvi.gte(0.4).And(ndvi.lt(0.7))\n",
        "    dense_veg_mask = ndvi.gte(0.7)\n",
        "\n",
        "    # Sample points for each class\n",
        "    NUM_OF_PIXELS = 50000\n",
        "\n",
        "    def sample_points(mask, class_value):\n",
        "        return feature_image.updateMask(mask).sample(\n",
        "            region=geometry,\n",
        "            scale=10,\n",
        "            numPixels=NUM_OF_PIXELS,\n",
        "            geometries=True\n",
        "        ).map(lambda f: f.set('class', class_value))\n",
        "\n",
        "    water_points = sample_points(water_mask, 0)\n",
        "    building_points = sample_points(building_mask, 1)\n",
        "    sparse_veg_points = sample_points(sparse_veg_mask, 2)\n",
        "    dense_veg_points = sample_points(dense_veg_mask, 3)\n",
        "\n",
        "    # Merge all training points\n",
        "    training_points = water_points.merge(building_points).merge(sparse_veg_points).merge(dense_veg_points)\n",
        "\n",
        "    # Split the data into training (80%) and validation (20%) sets\n",
        "    with_random = training_points.randomColumn()\n",
        "    split = 0.8\n",
        "    training_data = with_random.filter(ee.Filter.lt('random', split))\n",
        "    validation_data = with_random.filter(ee.Filter.gte('random', split))\n",
        "\n",
        "    # Train an SVM classifier\n",
        "    svm_classifier = ee.Classifier.libsvm().train(\n",
        "        features=training_data,\n",
        "        classProperty='class',\n",
        "        inputProperties=['NDVI', 'NDWI']\n",
        "    )\n",
        "\n",
        "    # Classify the image\n",
        "    classified_image = feature_image.classify(svm_classifier)\n",
        "\n",
        "    # Evaluate the classifier using the validation data\n",
        "    validation = validation_data.classify(svm_classifier)\n",
        "    validation_confusion_matrix = validation.errorMatrix('class', 'classification')\n",
        "    print('Validation Error Matrix:', validation_confusion_matrix.getInfo())\n",
        "    print('Validation Overall Accuracy:', validation_confusion_matrix.accuracy().getInfo())\n",
        "\n",
        "    # Compute training accuracy\n",
        "    training_confusion_matrix = svm_classifier.confusionMatrix()\n",
        "    print('Training Error Matrix:', training_confusion_matrix.getInfo())\n",
        "    print('Training Overall Accuracy:', training_confusion_matrix.accuracy().getInfo())\n",
        "\n",
        "    # Enhanced RGB export\n",
        "    enhanced_rgb = sentinel2.select(['B4', 'B3', 'B2']).multiply(2.0)\n",
        "    viz_params = {\n",
        "        'bands': ['B4', 'B3', 'B2'],\n",
        "        'min': 0,\n",
        "        'max': 3000,\n",
        "        'gamma': 1\n",
        "    }\n",
        "\n",
        "    # Export tasks\n",
        "    # 1. Enhanced RGB\n",
        "    enhanced_rgb_task = ee.batch.Export.image.toDrive(\n",
        "        image=enhanced_rgb.clip(geometry).visualize(**viz_params),\n",
        "        description=f'EnhancedRGB_{filename}_{year}',\n",
        "        folder='ChangeDetection',\n",
        "        fileNamePrefix=f'{filename}_{year}',\n",
        "        region=geometry,\n",
        "        fileFormat='GEOTIFF',\n",
        "        crs='EPSG:3857',\n",
        "        dimensions='512x512'\n",
        "    )\n",
        "\n",
        "    # 2. Classified Image\n",
        "    class_vis = {\n",
        "        'min': 0,\n",
        "        'max': 3,\n",
        "        'palette': ['lightblue', 'white', 'lightgreen', 'darkgreen']\n",
        "    }\n",
        "    mask_task = ee.batch.Export.image.toDrive(\n",
        "        image=classified_image,\n",
        "        description=f'm_{filename}_{year}',\n",
        "        folder='ChangeDetection',\n",
        "        fileNamePrefix=f'm_{filename}_{year}',\n",
        "        region=geometry,\n",
        "        fileFormat='GEOTIFF',\n",
        "        crs='EPSG:3857',\n",
        "        dimensions='512x512'\n",
        "    )\n",
        "\n",
        "    # Start both export tasks\n",
        "    enhanced_rgb_task.start()\n",
        "    mask_task.start()\n",
        "\n",
        "    print(f\"Tasks started for {city} at ({lon}, {lat}).\")"
      ],
      "metadata": {
        "id": "ie-0yo0qt2L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data"
      ],
      "metadata": {
        "id": "vyvVJc9XGBKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RUN"
      ],
      "metadata": {
        "id": "JO8a-E6GQpOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "data = pd.read_csv(io.StringIO('''\n",
        "California,SanFrancisco,2019,2024,\"-122.447559212022,37.7587570417743\",37.75875704,-122.4475592,\"-122.447559212022,37.8087570417743\",\"-122.397559212022,37.8087570417743\",\"-122.397559212022,37.7587570417743\",\"-122.397559212022,37.7087570417743\",\"-122.447559212022,37.7087570417743\",\"-122.497559212022,37.7087570417743\",\"-122.497559212022,37.7587570417743\",\"-122.497559212022,37.8087570417743\"\n",
        "'''), header=None)\n"
      ],
      "metadata": {
        "id": "daEE-znbVPk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coord_list = [4, 7, 8, 9, 10, 11, 12, 13, 14]\n",
        "coord_name = ['C', 'N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW']\n",
        "state = data[0][0]\n",
        "ncities = data.shape[0]\n",
        "# Process each city\n",
        "for j in range(ncities):\n",
        "  cityData = data.iloc[j]\n",
        "  city = cityData[1]\n",
        "  print(city, state)\n",
        "  for i in range(9):\n",
        "      coord = cityData.iloc[coord_list[i]].split(',')\n",
        "      filename = f'{state}_{city}_{coord_name[i]}'\n",
        "      print(filename, end=';')\n",
        "\n",
        "      lon = float(coord[0])\n",
        "      lat = float(coord[1])\n",
        "      print(lon, lat)\n",
        "      # process_point(lon, lat, city, state, '2019', filename)\n",
        "      # process_point(lon, lat, city, state, '2024', filename)\n",
        "      process_point_2(lon, lat, city, state, '2019', filename)\n",
        "      process_point_2(lon, lat, city, state, '2024', filename)\n",
        "  print()\n",
        "\n",
        "print(\"All tasks have been started.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCaj8N-DKj4c",
        "outputId": "8f4ce886-1e10-43a6-e46c-b000b8aa2675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SanFrancisco California\n",
            "California_SanFrancisco_C;-122.447559212022 37.7587570417743\n",
            "Validation Error Matrix: [[0, 1, 0, 0], [0, 6948, 20, 0], [0, 44, 1863, 21], [0, 0, 19, 916]]\n",
            "Validation Overall Accuracy: 0.9893205858421481\n",
            "Training Error Matrix: [[0, 2, 0, 0], [0, 28039, 52, 0], [0, 128, 7358, 74], [0, 0, 77, 3492]]\n",
            "Training Overall Accuracy: 0.9915098669114273\n",
            "Tasks started for SanFrancisco at (-122.447559212022, 37.7587570417743).\n",
            "Validation Error Matrix: [[0, 1, 0, 0], [0, 6840, 21, 0], [0, 25, 1824, 11], [0, 0, 15, 1096]]\n",
            "Validation Overall Accuracy: 0.9925760195260857\n",
            "Training Error Matrix: [[0, 0, 0, 0], [0, 27239, 99, 0], [0, 94, 7327, 69], [0, 0, 59, 4248]]\n",
            "Training Overall Accuracy: 0.9917976236105788\n",
            "Tasks started for SanFrancisco at (-122.447559212022, 37.7587570417743).\n",
            "California_SanFrancisco_N;-122.447559212022 37.8087570417743\n",
            "Validation Error Matrix: [[5261, 1, 0, 0], [0, 2922, 15, 0], [0, 16, 876, 24], [0, 0, 6, 750]]\n",
            "Validation Overall Accuracy: 0.9937189747745923\n",
            "Training Error Matrix: [[20979, 11, 0, 0], [2, 11460, 50, 0], [0, 57, 3752, 79], [0, 0, 24, 2842]]\n",
            "Training Overall Accuracy: 0.9943193397187691\n",
            "Tasks started for SanFrancisco at (-122.447559212022, 37.8087570417743).\n",
            "Validation Error Matrix: [[5135, 0, 0, 0], [0, 2853, 20, 0], [0, 18, 918, 10], [0, 0, 4, 726]]\n",
            "Validation Overall Accuracy: 0.9946303180503924\n",
            "Training Error Matrix: [[20907, 8, 0, 0], [0, 11277, 51, 0], [0, 52, 3823, 58], [0, 0, 23, 3144]]\n",
            "Training Overall Accuracy: 0.99511984342831\n",
            "Tasks started for SanFrancisco at (-122.447559212022, 37.8087570417743).\n",
            "California_SanFrancisco_NE;-122.397559212022 37.8087570417743\n",
            "Validation Error Matrix: [[6568, 1, 0, 0], [1, 2902, 3, 0], [0, 9, 172, 0], [0, 0, 7, 17]]\n",
            "Validation Overall Accuracy: 0.9978305785123966\n",
            "Training Error Matrix: [[25938, 23, 0, 0], [3, 11442, 13, 0], [0, 43, 755, 0], [0, 0, 38, 71]]\n",
            "Training Overall Accuracy: 0.9968689662370193\n",
            "Tasks started for SanFrancisco at (-122.397559212022, 37.8087570417743).\n",
            "Validation Error Matrix: [[6485, 4, 0, 0], [5, 2823, 4, 0], [0, 12, 219, 6], [0, 0, 1, 45]]\n",
            "Validation Overall Accuracy: 0.9966680549770929\n",
            "Training Error Matrix: [[25842, 12, 0, 0], [2, 11627, 8, 0], [0, 51, 791, 7], [0, 0, 5, 193]]\n",
            "Training Overall Accuracy: 0.997794384763091\n",
            "Tasks started for SanFrancisco at (-122.397559212022, 37.8087570417743).\n",
            "California_SanFrancisco_E;-122.397559212022 37.7587570417743\n",
            "Validation Error Matrix: [[2021, 1, 0, 0], [0, 6872, 7, 0], [0, 16, 462, 0], [0, 0, 10, 29]]\n",
            "Validation Overall Accuracy: 0.9963898916967509\n",
            "Training Error Matrix: [[8255, 13, 0, 0], [0, 27578, 32, 0], [0, 63, 1796, 0], [0, 0, 33, 139]]\n",
            "Training Overall Accuracy: 0.9962805666200638\n",
            "Tasks started for SanFrancisco at (-122.397559212022, 37.7587570417743).\n",
            "Validation Error Matrix: [[2047, 2, 0, 0], [0, 6915, 5, 0], [0, 21, 527, 1], [0, 0, 10, 49]]\n",
            "Validation Overall Accuracy: 0.9959277435522607\n",
            "Training Error Matrix: [[8159, 3, 0, 0], [0, 27070, 27, 0], [0, 72, 2150, 0], [0, 0, 39, 226]]\n",
            "Training Overall Accuracy: 0.9962645048481958\n",
            "Tasks started for SanFrancisco at (-122.397559212022, 37.7587570417743).\n",
            "California_SanFrancisco_SE;-122.397559212022 37.7087570417743\n",
            "Validation Error Matrix: [[2472, 1, 0, 0], [0, 5772, 6, 0], [0, 20, 1147, 10], [0, 0, 10, 286]]\n",
            "Validation Overall Accuracy: 0.9951665981077745\n",
            "Training Error Matrix: [[10142, 1, 0, 0], [0, 22940, 28, 0], [0, 82, 4701, 50], [0, 0, 52, 1035]]\n",
            "Training Overall Accuracy: 0.9945427993133663\n",
            "Tasks started for SanFrancisco at (-122.397559212022, 37.7087570417743).\n",
            "Validation Error Matrix: [[2518, 0, 0, 0], [0, 5605, 5, 0], [0, 34, 1137, 7], [0, 0, 8, 423]]\n",
            "Validation Overall Accuracy: 0.9944541439868543\n",
            "Training Error Matrix: [[10084, 0, 0, 0], [0, 22139, 19, 0], [0, 118, 4455, 56], [0, 0, 49, 1690]]\n",
            "Training Overall Accuracy: 0.9937321937321937\n",
            "Tasks started for SanFrancisco at (-122.397559212022, 37.7087570417743).\n",
            "California_SanFrancisco_S;-122.447559212022 37.7087570417743\n",
            "Validation Error Matrix: [[0, 0, 0, 0], [0, 6575, 20, 0], [0, 21, 2237, 17], [0, 0, 14, 890]]\n",
            "Validation Overall Accuracy: 0.992633517495396\n",
            "Training Error Matrix: [[0, 0, 0, 0], [0, 25964, 90, 0], [0, 86, 9219, 75], [0, 0, 83, 3893]]\n",
            "Training Overall Accuracy: 0.9915249936564324\n",
            "Tasks started for SanFrancisco at (-122.447559212022, 37.7087570417743).\n",
            "Validation Error Matrix: [[0, 0, 0, 0], [0, 6411, 25, 0], [0, 21, 2026, 16], [0, 0, 19, 1439]]\n",
            "Validation Overall Accuracy: 0.9918650195842121\n",
            "Training Error Matrix: [[0, 2, 0, 0], [0, 25247, 74, 0], [0, 89, 7946, 78], [0, 0, 66, 5662]]\n",
            "Training Overall Accuracy: 0.9921101011132673\n",
            "Tasks started for SanFrancisco at (-122.447559212022, 37.7087570417743).\n",
            "California_SanFrancisco_SW;-122.497559212022 37.7087570417743\n",
            "Validation Error Matrix: [[4465, 5, 0, 0], [16, 3107, 5, 0], [0, 17, 1099, 22], [0, 0, 3, 1233]]\n",
            "Validation Overall Accuracy: 0.9931809065383073\n",
            "Training Error Matrix: [[17811, 26, 0, 0], [51, 12102, 23, 0], [0, 73, 4166, 89], [0, 0, 33, 5213]]\n",
            "Training Overall Accuracy: 0.9925480587061409\n",
            "Tasks started for SanFrancisco at (-122.497559212022, 37.7087570417743).\n",
            "Validation Error Matrix: [[4324, 85, 0, 0], [299, 3156, 14, 0], [0, 11, 1080, 21], [0, 0, 7, 1218]]\n",
            "Validation Overall Accuracy: 0.9572197748409202\n",
            "Training Error Matrix: [[17443, 320, 0, 0], [1274, 12480, 48, 0], [0, 70, 4507, 75], [0, 0, 20, 4838]]\n",
            "Training Overall Accuracy: 0.9560073037127206\n",
            "Tasks started for SanFrancisco at (-122.497559212022, 37.7087570417743).\n",
            "California_SanFrancisco_W;-122.497559212022 37.7587570417743\n",
            "Validation Error Matrix: [[2588, 1, 0, 0], [0, 5411, 1, 0], [0, 7, 1040, 28], [0, 0, 8, 694]]\n",
            "Validation Overall Accuracy: 0.9953978318674576\n",
            "Training Error Matrix: [[10271, 19, 0, 0], [13, 21557, 13, 0], [0, 56, 3870, 102], [0, 0, 24, 2828]]\n",
            "Training Overall Accuracy: 0.9941423889763373\n",
            "Tasks started for SanFrancisco at (-122.497559212022, 37.7587570417743).\n",
            "Validation Error Matrix: [[2475, 49, 1, 0], [186, 5481, 16, 0], [0, 17, 1045, 16], [0, 0, 13, 650]]\n",
            "Validation Overall Accuracy: 0.9700472409287365\n",
            "Training Error Matrix: [[10114, 187, 0, 0], [703, 21805, 39, 0], [0, 72, 4067, 54], [0, 0, 34, 2685]]\n",
            "Training Overall Accuracy: 0.9726106639839034\n",
            "Tasks started for SanFrancisco at (-122.497559212022, 37.7587570417743).\n",
            "California_SanFrancisco_NW;-122.497559212022 37.8087570417743\n",
            "Validation Error Matrix: [[7164, 6, 0, 0], [0, 1166, 6, 0], [0, 11, 1093, 16], [0, 0, 14, 514]]\n",
            "Validation Overall Accuracy: 0.9946946946946947\n",
            "Training Error Matrix: [[28629, 23, 0, 0], [11, 4566, 49, 0], [0, 38, 4344, 63], [0, 0, 25, 2037]]\n",
            "Training Overall Accuracy: 0.9947467638557245\n",
            "Tasks started for SanFrancisco at (-122.497559212022, 37.8087570417743).\n",
            "Validation Error Matrix: [[7072, 1, 0, 0], [12, 1021, 15, 0], [0, 10, 1122, 11], [0, 0, 15, 655]]\n",
            "Validation Overall Accuracy: 0.9935574793638011\n",
            "Training Error Matrix: [[28737, 13, 0, 0], [23, 3875, 42, 0], [0, 50, 4406, 42], [0, 0, 46, 2611]]\n",
            "Training Overall Accuracy: 0.9945789936002007\n",
            "Tasks started for SanFrancisco at (-122.497559212022, 37.8087570417743).\n",
            "\n",
            "All tasks have been started.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DrTLiJcbTWi",
        "outputId": "f2971795-fa8c-46ae-d409-c57309f6ed5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Error Matrix: [[3485, 10, 0, 0], [2, 4508, 6, 0], [0, 5, 1074, 24], [0, 0, 7, 838]]\n",
            "Validation Overall Accuracy: 0.9945777688522944\n",
            "Training Error Matrix: [[13462, 32, 0, 0], [15, 17569, 27, 0], [0, 31, 4310, 98], [0, 0, 26, 3422]]\n",
            "Training Overall Accuracy: 0.9941270004103406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M8ikh7n2tvAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Code Not Taken"
      ],
      "metadata": {
        "id": "dK1V81GYOIVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Single City"
      ],
      "metadata": {
        "id": "WdkJKFWqRENy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "data = pd.read_csv(io.StringIO('''\n",
        "SanJose,2019,2024,\"-121.899180305122,37.3391025913052\",37.33910259,-121.8991803,\"-121.899180305122,37.3891025913052\",\"-121.849180305122,37.3891025913052\",\"-121.849180305122,37.3391025913052\",\"-121.849180305122,37.2891025913052\",\"-121.899180305122,37.2891025913052\",\"-121.949180305122,37.2891025913052\",\"-121.949180305122,37.3391025913052\",\"-121.949180305122,37.3891025913052\"\n",
        "'''), header=None)\n"
      ],
      "metadata": {
        "id": "EvvKWm1hPG_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coord_list = [3, 6, 7, 8, 9, 10, 11, 12, 13]\n",
        "coord_name = ['C', 'N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW']\n",
        "city='SanJose'\n",
        "# Process each point\n",
        "for i in range(9):\n",
        "    coord = data.iloc[0, coord_list[i]].split(',')\n",
        "    filename = f'{city}_{coord_name[i]}'\n",
        "    lon = float(coord[0])\n",
        "    lat = float(coord[1])\n",
        "\n",
        "    print(filename)\n",
        "    print(lon, lat)\n",
        "    process_point(lon, lat, city, '2019', filename)\n",
        "\n",
        "print(\"All tasks have been started.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHejCVzrBdhZ",
        "outputId": "a7745e3d-5fff-4c5b-dda7-82a8a0ad0068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SanJose_C\n",
            "-121.899180305122 37.3391025913052\n",
            "Tasks started for SanJose at (-121.899180305122, 37.3391025913052).\n",
            "SanJose_N\n",
            "-121.899180305122 37.3891025913052\n",
            "Tasks started for SanJose at (-121.899180305122, 37.3891025913052).\n",
            "SanJose_NE\n",
            "-121.849180305122 37.3891025913052\n",
            "Tasks started for SanJose at (-121.849180305122, 37.3891025913052).\n",
            "SanJose_E\n",
            "-121.849180305122 37.3391025913052\n",
            "Tasks started for SanJose at (-121.849180305122, 37.3391025913052).\n",
            "SanJose_SE\n",
            "-121.849180305122 37.2891025913052\n",
            "Tasks started for SanJose at (-121.849180305122, 37.2891025913052).\n",
            "SanJose_S\n",
            "-121.899180305122 37.2891025913052\n",
            "Tasks started for SanJose at (-121.899180305122, 37.2891025913052).\n",
            "SanJose_SW\n",
            "-121.949180305122 37.2891025913052\n",
            "Tasks started for SanJose at (-121.949180305122, 37.2891025913052).\n",
            "SanJose_W\n",
            "-121.949180305122 37.3391025913052\n",
            "Tasks started for SanJose at (-121.949180305122, 37.3391025913052).\n",
            "SanJose_NW\n",
            "-121.949180305122 37.3891025913052\n",
            "Tasks started for SanJose at (-121.949180305122, 37.3891025913052).\n",
            "All tasks have been started.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7Z3IzDVGQE8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the center and geometry\n",
        "center = ee.Geometry.Point([-122.50, 37.77])\n",
        "geometry = center.buffer(2560).bounds()\n",
        "\n",
        "# Load Sentinel-2 MSI Level-2A as image collection\n",
        "sentinel2 = (ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
        "             .filterBounds(geometry)\n",
        "             .filterDate('2019-07-01', '2019-09-30')\n",
        "             .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 3))\n",
        "             .median())\n",
        "\n",
        "# Calculate NDVI and NDWI\n",
        "ndvi = sentinel2.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
        "ndwi = sentinel2.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
        "swm = sentinel2.expression(\n",
        "    '(B2 + B3) / (B8 + B11)',\n",
        "    {\n",
        "        'B2': sentinel2.select('B2'),\n",
        "        'B3': sentinel2.select('B3'),\n",
        "        'B8': sentinel2.select('B8'),\n",
        "        'B11': sentinel2.select('B11')\n",
        "    }\n",
        ").rename('SWM')\n",
        "\n",
        "# Combine NDVI and NDWI into a single image for sampling\n",
        "feature_image = ndvi.addBands(ndwi)\n",
        "\n",
        "# Define class masks\n",
        "water_mask = swm.gt(1.5)\n",
        "building_mask = ndvi.gt(0.0).And(ndvi.lt(0.4))\n",
        "sparse_veg_mask = ndvi.gte(0.4).And(ndvi.lt(0.7))\n",
        "dense_veg_mask = ndvi.gte(0.7)\n",
        "\n",
        "# Sample points for each class\n",
        "NUM_OF_PIXELS = 50000\n",
        "\n",
        "def sample_points(mask, class_value):\n",
        "    return feature_image.updateMask(mask).sample(\n",
        "        region=geometry,\n",
        "        scale=10,\n",
        "        numPixels=NUM_OF_PIXELS,\n",
        "        geometries=True\n",
        "    ).map(lambda f: f.set('class', class_value))\n",
        "\n",
        "water_points = sample_points(water_mask, 0)\n",
        "building_points = sample_points(building_mask, 1)\n",
        "sparse_veg_points = sample_points(sparse_veg_mask, 2)\n",
        "dense_veg_points = sample_points(dense_veg_mask, 3)\n",
        "\n",
        "# Merge all training points\n",
        "training_points = water_points.merge(building_points).merge(sparse_veg_points).merge(dense_veg_points)\n",
        "\n",
        "# Split the data into training (80%) and validation (20%) sets\n",
        "with_random = training_points.randomColumn()\n",
        "split = 0.8\n",
        "training_data = with_random.filter(ee.Filter.lt('random', split))\n",
        "validation_data = with_random.filter(ee.Filter.gte('random', split))\n",
        "\n",
        "# Train an SVM classifier\n",
        "svm_classifier = ee.Classifier.libsvm().train(\n",
        "    features=training_data,\n",
        "    classProperty='class',\n",
        "    inputProperties=['NDVI', 'NDWI']\n",
        ")\n",
        "\n",
        "# Classify the image\n",
        "classified_image = feature_image.classify(svm_classifier)\n",
        "\n",
        "# Evaluate the classifier using the validation data\n",
        "validation = validation_data.classify(svm_classifier)\n",
        "validation_confusion_matrix = validation.errorMatrix('class', 'classification')\n",
        "print('Validation Error Matrix:', validation_confusion_matrix.getInfo())\n",
        "print('Validation Overall Accuracy:', validation_confusion_matrix.accuracy().getInfo())\n",
        "\n",
        "# Compute training accuracy\n",
        "training_confusion_matrix = svm_classifier.confusionMatrix()\n",
        "print('Training Error Matrix:', training_confusion_matrix.getInfo())\n",
        "print('Training Overall Accuracy:', training_confusion_matrix.accuracy().getInfo())\n",
        "\n",
        "# Visualization (requires exporting or downloading for Colab visualization)\n",
        "# Visualization parameters\n",
        "class_vis = {\n",
        "    'min': 0,\n",
        "    'max': 3,\n",
        "    'palette': ['lightblue', 'white', 'lightgreen', 'darkgreen']\n",
        "}\n",
        "\n",
        "# Export the classified image to Google Drive\n",
        "export_task = ee.batch.Export.image.toDrive(\n",
        "    image=classified_image,\n",
        "    description='ClassifiedImage',\n",
        "    folder='ChangeDetection',\n",
        "    fileNamePrefix='classified_image_test',\n",
        "    region=geometry.getInfo()['coordinates'],\n",
        "    # scale=10,\n",
        "    fileFormat='GEOTIFF',\n",
        "    crs='EPSG:3857',\n",
        "    dimensions='512x512'\n",
        ")\n",
        "export_task.start()\n"
      ],
      "metadata": {
        "id": "Q9Sl1sYgPVV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT Functionless SVM"
      ],
      "metadata": {
        "id": "9z98yn-qRWhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the center and geometry\n",
        "center = ee.Geometry.Point([-122.50, 37.77])\n",
        "geometry = center.buffer(2560).bounds()\n",
        "\n",
        "# Load Sentinel-2 MSI Level-2A as image collection\n",
        "sentinel2 = (ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
        "             .filterBounds(geometry)\n",
        "             .filterDate('2019-07-01', '2019-09-30')\n",
        "             .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 3))\n",
        "             .median())\n",
        "\n",
        "# Calculate NDVI and NDWI\n",
        "ndvi = sentinel2.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
        "ndwi = sentinel2.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
        "swm = sentinel2.expression(\n",
        "    '(B2 + B3) / (B8 + B11)',\n",
        "    {\n",
        "        'B2': sentinel2.select('B2'),\n",
        "        'B3': sentinel2.select('B3'),\n",
        "        'B8': sentinel2.select('B8'),\n",
        "        'B11': sentinel2.select('B11')\n",
        "    }\n",
        ").rename('SWM')\n",
        "\n",
        "# Combine NDVI and NDWI into a single image for sampling\n",
        "feature_image = ndvi.addBands(ndwi)\n",
        "\n",
        "# Define class masks\n",
        "water_mask = swm.gt(1.5)\n",
        "building_mask = ndvi.gt(0.0).And(ndvi.lt(0.4))\n",
        "sparse_veg_mask = ndvi.gte(0.4).And(ndvi.lt(0.7))\n",
        "dense_veg_mask = ndvi.gte(0.7)\n",
        "\n",
        "# Sample points for each class\n",
        "NUM_OF_PIXELS = 50000\n",
        "\n",
        "def sample_points(mask, class_value):\n",
        "    return feature_image.updateMask(mask).sample(\n",
        "        region=geometry,\n",
        "        scale=10,\n",
        "        numPixels=NUM_OF_PIXELS,\n",
        "        geometries=True\n",
        "    ).map(lambda f: f.set('class', class_value))\n",
        "\n",
        "water_points = sample_points(water_mask, 0)\n",
        "building_points = sample_points(building_mask, 1)\n",
        "sparse_veg_points = sample_points(sparse_veg_mask, 2)\n",
        "dense_veg_points = sample_points(dense_veg_mask, 3)\n",
        "\n",
        "# Merge all training points\n",
        "training_points = water_points.merge(building_points).merge(sparse_veg_points).merge(dense_veg_points)\n",
        "\n",
        "# Split the data into training (80%) and validation (20%) sets\n",
        "with_random = training_points.randomColumn()\n",
        "split = 0.8\n",
        "training_data = with_random.filter(ee.Filter.lt('random', split))\n",
        "validation_data = with_random.filter(ee.Filter.gte('random', split))\n",
        "\n",
        "# Train an SVM classifier\n",
        "svm_classifier = ee.Classifier.libsvm().train(\n",
        "    features=training_data,\n",
        "    classProperty='class',\n",
        "    inputProperties=['NDVI', 'NDWI']\n",
        ")\n",
        "\n",
        "# Classify the image\n",
        "classified_image = feature_image.classify(svm_classifier)\n",
        "\n",
        "# Evaluate the classifier using the validation data\n",
        "validation = validation_data.classify(svm_classifier)\n",
        "validation_confusion_matrix = validation.errorMatrix('class', 'classification')\n",
        "print('Validation Error Matrix:', validation_confusion_matrix.getInfo())\n",
        "print('Validation Overall Accuracy:', validation_confusion_matrix.accuracy().getInfo())\n",
        "\n",
        "# Compute training accuracy\n",
        "training_confusion_matrix = svm_classifier.confusionMatrix()\n",
        "print('Training Error Matrix:', training_confusion_matrix.getInfo())\n",
        "print('Training Overall Accuracy:', training_confusion_matrix.accuracy().getInfo())\n",
        "\n",
        "# Visualization (requires exporting or downloading for Colab visualization)\n",
        "# Visualization parameters\n",
        "class_vis = {\n",
        "    'min': 0,\n",
        "    'max': 3,\n",
        "    'palette': ['lightblue', 'white', 'lightgreen', 'darkgreen']\n",
        "}\n",
        "\n",
        "# Export the classified image to Google Drive\n",
        "export_task = ee.batch.Export.image.toDrive(\n",
        "    image=classified_image,\n",
        "    description='ClassifiedImage',\n",
        "    folder='ChangeDetection',\n",
        "    fileNamePrefix='classified_image_test',\n",
        "    region=geometry.getInfo()['coordinates'],\n",
        "    # scale=10,\n",
        "    fileFormat='GEOTIFF',\n",
        "    crs='EPSG:3857',\n",
        "    dimensions='512x512'\n",
        ")\n",
        "export_task.start()\n"
      ],
      "metadata": {
        "id": "znC-l7IHP2re"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}