//var center = ee.Geometry.Point([-78.66638044690248, 35.80269787969758]);
var center = ee.Geometry.Point([-122.50, 37.77]);
//var center = ee.Geometry.Point([-76.60566533391743,35.98033251597695]);
//var center = ee.Geometry.Point([-81.10,34.02]);
//var center = ee.Geometry.Point([-122.17,37.80]);
//var center = ee.Geometry.Point([-73.98, 40.77]);

// Define the bounding box with a buffer radius (2560 meters for 512x512 pixels at 10m resolution)
var geometry = center.buffer(5120).bounds();

// Load Sentinel-2 MSI Level-2A as imageCollection
var sentinel2 = ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED")
  .filterBounds(geometry)
  .filterDate('2019-07-01', '2019-09-30')  // Specify a date range
  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 3))  // Filter low cloud cover
  .median();  // Use median to create a composite image

// Calculate enhanced RGB
var enhancedRGB = sentinel2.select('B4').multiply(2.0)  // Enhance Red
                  .addBands(sentinel2.select('B3').multiply(2.0))  // Enhance Green
                  .addBands(sentinel2.select('B2').multiply(2.0));  // Enhance Blue

var vizParams = {
  bands: ['B4', 'B3', 'B2'],
  min: 0,
  max: 3000,
  gamma: 1
};

// // 2. Calculate NDVI and NDBI
// var ndvi = sentinel2.normalizedDifference(['B8', 'B4']).rename('NDVI');
// var ndbi = sentinel2.normalizedDifference(['B11', 'B8']).rename('NDBI');

// // 3. Prepare the input image with NDVI and NDBI as bands
// var inputImage = ndvi.addBands(ndbi);

// // 4. Create automatic labels based on NDVI > 0.5
// var vegetationMask = ndvi.gt(0.5); // Mask for NDVI > 0.5
// var buildingMask = ndvi.lte(0.5); // Mask for NDVI <= 0.5 (buildings or other)

// // Create a labeled image
// var labeledImage = vegetationMask
//   .multiply(0) // Class 0 for vegetation
//   .add(buildingMask.multiply(1)) // Class 1 for building
//   .rename('class');

// // 5. Sample data from the labeled image
// var training = inputImage.addBands(labeledImage).sample({
//   region: geometry,
//   scale: 10,
//   numPixels: 500, // Limit the number of pixels for training
//   seed: 42 // Random seed for reproducibility
// });

// // 6. Train an SVM classifier
// var svmClassifier = ee.Classifier.libsvm().train({
//   features: training,
//   classProperty: 'class',
//   inputProperties: ['NDVI', 'NDBI']
// });

// // 7. Classify the image
// var classified = inputImage.classify(svmClassifier);

// // 8. Define visualization parameters
// var classificationVis = {
//   min: 0,
//   max: 1,
//   palette: ['green', 'red'] // Vegetation = green, Building = red
// };

// // 9. Display the NDVI and classified layers
// Map.centerObject(geometry, 13);
// Map.addLayer(ndvi.clip(geometry), {min: 0, max: 1, palette: ['white', 'green']}, 'NDVI');
// Map.addLayer(classified.clip(geometry), classificationVis, 'SVM Classification');


//**********************new



// Define region of interest (centered around Raleigh, NC)
//var geometry = center.buffer(2560).bounds();

// Calculate NDVI and NDWI
var ndvi = sentinel2.normalizedDifference(['B8', 'B4']).rename('NDVI');
var ndwi = sentinel2.normalizedDifference(['B3', 'B8']).rename('NDWI');
var swm = sentinel2.expression(
  '(B2 + B3) / (B8 + B11)', 
  {
    'B2': sentinel2.select('B2'), // Blue Band
    'B3': sentinel2.select('B3'), // Green Band
    'B8': sentinel2.select('B8'), // NIR Band
    'B11': sentinel2.select('B11') // SWIR Band
  }
).rename('SWM');



// Combine NDVI and NDWI into a single image for sampling
var featureImage = ndvi.addBands(ndwi);

// Create masks for each class based on criteria
var waterMask = swm.gt(1.5); // Class 0: Water
var buildingMask = ndvi.gt(0.0).and(ndvi.lt(0.4)); // Class 1: Buildings
var sparseVegMask = ndvi.gte(0.4).and(ndvi.lt(0.7)); // Class 2: Sparse vegetation
var denseVegMask = ndvi.gte(0.7); // Class 3: Dense vegetation

var NUM_OF_PIXELS = 70000

// Sample points for each class
var waterPoints = featureImage.updateMask(waterMask).sample({
  region: geometry,
  scale: 10,
  numPixels: NUM_OF_PIXELS, // Adjust the number of points for each class
  geometries: true
}).map(function(feature) {
  return feature.set('class', 0);
});

var buildingPoints = featureImage.updateMask(buildingMask).sample({
  region: geometry,
  scale: 10,
  numPixels: NUM_OF_PIXELS,
  geometries: true
}).map(function(feature) {
  return feature.set('class', 1);
});

var sparseVegPoints = featureImage.updateMask(sparseVegMask).sample({
  region: geometry,
  scale: 10,
  numPixels: NUM_OF_PIXELS,
  geometries: true
}).map(function(feature) {
  return feature.set('class', 2);
});

var denseVegPoints = featureImage.updateMask(denseVegMask).sample({
  region: geometry,
  scale: 10,
  numPixels: NUM_OF_PIXELS,
  geometries: true
}).map(function(feature) {
  return feature.set('class', 3);
});

// Combine all training points into one FeatureCollection
var trainingPoints = waterPoints.merge(buildingPoints).merge(sparseVegPoints).merge(denseVegPoints);

// // Train the SVM classifier
// var svmClassifier = ee.Classifier.libsvm().train({
//   features: trainingPoints,
//   classProperty: 'class',
//   inputProperties: ['NDVI', 'NDWI']
// });

// // Classify the image using the trained SVM model
// var classifiedImage = featureImage.classify(svmClassifier);

// Split the data into training (80%) and validation (20%) sets
var split = 0.8; // Split ratio
var withRandom = trainingPoints.randomColumn();
var trainingData = withRandom.filter(ee.Filter.lt('random', split));
var validationData = withRandom.filter(ee.Filter.gte('random', split));

// Train the SVM classifier
var svmClassifier = ee.Classifier.libsvm().train({
  features: trainingData,
  classProperty: 'class',
  inputProperties: ['NDVI', 'NDWI']
});

// var svmClassifier = ee.Classifier.smileCart(10).train({
//   features: trainingData,
//   classProperty: 'class',
//   inputProperties: ['NDVI', 'NDWI']
// });


// Classify the image using the trained SVM model
var classifiedImage = featureImage.classify(svmClassifier);

// Evaluate the classifier using the validation data
var validation = validationData.classify(svmClassifier);

// Compute the confusion matrix for validation data
var validationConfusionMatrix = validation.errorMatrix('class', 'classification');
print('Validation Error Matrix:', validationConfusionMatrix);
print('Validation Overall Accuracy:', validationConfusionMatrix.accuracy());

// Compute the training confusion matrix and accuracy
var trainingConfusionMatrix = svmClassifier.confusionMatrix();
print('Training Error Matrix:', trainingConfusionMatrix);
print('Training Overall Accuracy:', trainingConfusionMatrix.accuracy());

// Visualization parameters for the classes
var classVis = {
  min: 0,
  max: 3,
  palette: ['lightblue', 'white', 'lightgreen', 'darkgreen'] // Water: blue, Buildings: red, Sparse veg: yellow, Dense veg: green
};

// Display the results
Map.centerObject(geometry, 13);
//Map.addLayer(enhancedRGB.clip(geometry),vizParams,'RGB');
//Map.addLayer(ndvi.clip(geometry), {min: -1, max: 1, palette: ['white', 'green']}, 'NDVI');
Map.addLayer(swm.clip(geometry), {min: -1, max: 3, palette: ['white', 'blue']}, 'NDWI');
Map.addLayer(classifiedImage.clip(geometry), classVis, 'SVM Classified Land Cover');

