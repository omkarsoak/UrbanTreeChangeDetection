{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HhmZP_-qz0C",
        "outputId": "a0dfb88e-e3c3-4664-dca8-78dc962cd1e6"
      },
      "outputs": [],
      "source": [
        "!pip install rasterio\n",
        "!pip install segmentation_models_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvpiVwnyXVhZ",
        "outputId": "75d3f3bd-5a68-4a4b-8d55-b1737b2bc083"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip '/content/drive/MyDrive/BTechProject/ChangeDetectionMergedDividedSplit-tif3.zip' -d '/content/ChangeDetectionMergedDividedSplit-tif'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkJO_FgR6KOk"
      },
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pd9Cl_XWSF4",
        "outputId": "05f52535-8903-4cba-8fd7-0355940f8350"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import rasterio\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "class ChangeDetectionDatasetTIF(Dataset):\n",
        "    def __init__(self, t2019_dir, t2024_dir, sem_2019_dir, sem_2024_dir, mask_dir,\n",
        "                 classes, semantic_classes, transform=None):\n",
        "        self.t2019_dir = t2019_dir\n",
        "        self.t2024_dir = t2024_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.sem_2019_dir = sem_2019_dir\n",
        "        self.sem_2024_dir = sem_2024_dir\n",
        "        self.classes = classes  # Change detection classes\n",
        "        self.semantic_classes = semantic_classes  # Land cover classes\n",
        "        self.transform = transform\n",
        "\n",
        "        # Load all paths\n",
        "        self.t2019_paths = sorted([f for f in os.listdir(t2019_dir) if f.endswith('.tif')])\n",
        "        self.t2024_paths = sorted([f for f in os.listdir(t2024_dir) if f.endswith('.tif')])\n",
        "        self.mask_paths = sorted([f for f in os.listdir(mask_dir) if f.endswith('.tif')])\n",
        "        self.sem2019_paths = sorted([f for f in os.listdir(sem_2019_dir) if f.endswith('.tif')])\n",
        "        self.sem2024_paths = sorted([f for f in os.listdir(sem_2024_dir) if f.endswith('.tif')])\n",
        "\n",
        "        # Verify all paths match\n",
        "        assert len(self.t2019_paths) == len(self.t2024_paths) == len(self.mask_paths) == \\\n",
        "               len(self.sem2019_paths) == len(self.sem2024_paths), \"Mismatched number of images\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.t2019_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Load images using rasterio\n",
        "        with rasterio.open(os.path.join(self.t2019_dir, self.t2019_paths[index])) as src:\n",
        "            img_t2019 = src.read(out_dtype=np.float32) / 255.0\n",
        "        with rasterio.open(os.path.join(self.t2024_dir, self.t2024_paths[index])) as src:\n",
        "            img_t2024 = src.read(out_dtype=np.float32) / 255.0\n",
        "\n",
        "        # Load masks\n",
        "        with rasterio.open(os.path.join(self.mask_dir, self.mask_paths[index])) as src:\n",
        "            cd_mask = src.read(1).astype(np.int64)\n",
        "        with rasterio.open(os.path.join(self.sem_2019_dir, self.sem2019_paths[index])) as src:\n",
        "            sem_mask_2019 = src.read(1).astype(np.int64)\n",
        "        with rasterio.open(os.path.join(self.sem_2024_dir, self.sem2024_paths[index])) as src:\n",
        "            sem_mask_2024 = src.read(1).astype(np.int64)\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        img_t2019 = torch.from_numpy(img_t2019)\n",
        "        img_t2024 = torch.from_numpy(img_t2024)\n",
        "        cd_mask = torch.from_numpy(cd_mask)\n",
        "        sem_mask_2019 = torch.from_numpy(sem_mask_2019)\n",
        "        sem_mask_2024 = torch.from_numpy(sem_mask_2024)\n",
        "\n",
        "        # Apply transforms if any\n",
        "        if self.transform is not None:\n",
        "            img_t2019 = self.transform(img_t2019)\n",
        "            img_t2024 = self.transform(img_t2024)\n",
        "\n",
        "        return img_t2019, img_t2024, sem_mask_2019, sem_mask_2024, cd_mask\n",
        "\n",
        "\n",
        "def describe_loader(loader_type):\n",
        "    \"\"\"Print information about a data loader\"\"\"\n",
        "    img2019, img2024, sem2019, sem2024, cd_mask = next(iter(loader_type))\n",
        "    print(\"Batch size:\", loader_type.batch_size)\n",
        "    print(\"Shapes:\")\n",
        "    print(\"  2019 Image:\", img2019.shape)\n",
        "    print(\"  2024 Image:\", img2024.shape)\n",
        "    print(\"  2019 Semantic Mask:\", sem2019.shape)\n",
        "    print(\"  2024 Semantic Mask:\", sem2024.shape)\n",
        "    print(\"  Change Mask:\", cd_mask.shape)\n",
        "    print(\"Number of images:\", len(loader_type.dataset))\n",
        "    print(\"Classes:\", loader_type.dataset.classes)\n",
        "    print(\"Semantic Classes:\", loader_type.dataset.semantic_classes)\n",
        "    print(\"\\nUnique values:\")\n",
        "    print(\"  Change Mask:\", torch.unique(cd_mask))\n",
        "    print(\"  Semantic Mask 2019:\", torch.unique(sem2019))\n",
        "\n",
        "# Example usage:\n",
        "ROOT_DIRECTORY = \"/content/ChangeDetectionMergedDividedSplit-tif\"\n",
        "SAVING_DIR = '/content/drive/MyDrive/BTechProject'\n",
        "#CLASSES = ['no_change', 'increase_vegetation', 'decrease_vegetation']\n",
        "CLASSES = ['no_change', 'water_building', 'water_sparse', 'water_dense',\n",
        "           'building_water', 'building_sparse', 'building_dense',\n",
        "           'sparse_water', 'sparse_building', 'sparse_dense',\n",
        "           'dense_water', 'dense_building', 'dense_sparse']\n",
        "\n",
        "SEMANTIC_CLASSES = ['water', 'building', 'sparse_vegetation', 'dense_vegetation']\n",
        "# Create datasets\n",
        "train_dataset = ChangeDetectionDatasetTIF(\n",
        "    t2019_dir=f\"{ROOT_DIRECTORY}/train/Images/T2019\",\n",
        "    t2024_dir=f\"{ROOT_DIRECTORY}/train/Images/T2024\",\n",
        "    sem_2019_dir=f\"{ROOT_DIRECTORY}/train/Masks/T2019\",\n",
        "    sem_2024_dir=f\"{ROOT_DIRECTORY}/train/Masks/T2024\",\n",
        "    mask_dir=f\"{ROOT_DIRECTORY}/train/cd2_Output\",\n",
        "    classes=CLASSES,\n",
        "    semantic_classes=SEMANTIC_CLASSES\n",
        ")\n",
        "\n",
        "val_dataset = ChangeDetectionDatasetTIF(\n",
        "    t2019_dir=f\"{ROOT_DIRECTORY}/val/Images/T2019\",\n",
        "    t2024_dir=f\"{ROOT_DIRECTORY}/val/Images/T2024\",\n",
        "    sem_2019_dir=f\"{ROOT_DIRECTORY}/val/Masks/T2019\",\n",
        "    sem_2024_dir=f\"{ROOT_DIRECTORY}/val/Masks/T2024\",\n",
        "    mask_dir=f\"{ROOT_DIRECTORY}/val/cd2_Output\",\n",
        "    classes=CLASSES,\n",
        "    semantic_classes=SEMANTIC_CLASSES\n",
        ")\n",
        "\n",
        "test_dataset = ChangeDetectionDatasetTIF(\n",
        "    t2019_dir=f\"{ROOT_DIRECTORY}/test/Images/T2019\",\n",
        "    t2024_dir=f\"{ROOT_DIRECTORY}/test/Images/T2024\",\n",
        "    sem_2019_dir=f\"{ROOT_DIRECTORY}/test/Masks/T2019\",\n",
        "    sem_2024_dir=f\"{ROOT_DIRECTORY}/test/Masks/T2024\",\n",
        "    mask_dir=f\"{ROOT_DIRECTORY}/test/cd2_Output\",\n",
        "    classes=CLASSES,\n",
        "    semantic_classes=SEMANTIC_CLASSES\n",
        ")\n",
        "\n",
        "# Create dataloaders\n",
        "num_workers = 8\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "print(\"------------Train------------\")\n",
        "describe_loader(train_loader)\n",
        "print(\"------------Val------------\")\n",
        "describe_loader(val_loader)\n",
        "print(\"------------Test------------\")\n",
        "describe_loader(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "In3pg1VeWU31",
        "outputId": "6c742faf-552e-45fe-b10e-19e19fbc16db"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Set up the plot size and remove axes\n",
        "fig, axs = plt.subplots(5, 5, figsize=(10,10))\n",
        "\n",
        "for i in range(5):\n",
        "    j = random.randint(0, len(train_dataset) - 1)\n",
        "    #image1, image2, mask = train_dataset[j]\n",
        "    img_t2019, img_t2024, sem_mask_2019, sem_mask_2024, cd_mask = train_dataset[j]\n",
        "\n",
        "    # Display images\n",
        "    axs[i, 0].imshow(img_t2019.permute(1, 2, 0))\n",
        "    axs[i, 0].set_title(f\"Real 2019\")\n",
        "    axs[i, 0].axis(\"off\")\n",
        "\n",
        "    axs[i, 1].imshow(img_t2024.permute(1, 2, 0))\n",
        "    axs[i, 1].set_title(f\"Real 2024\")\n",
        "    axs[i, 1].axis(\"off\")\n",
        "\n",
        "    axs[i, 2].imshow(sem_mask_2019, cmap=\"turbo\")\n",
        "    print(np.unique(sem_mask_2019))\n",
        "    axs[i, 2].set_title(f\"Sem 2019 Mask\")\n",
        "    axs[i, 2].axis(\"off\")\n",
        "\n",
        "    axs[i, 3].imshow(sem_mask_2024, cmap=\"turbo\")\n",
        "    print(np.unique(sem_mask_2024))\n",
        "    axs[i, 3].set_title(f\"Sem 2024 Mask\")\n",
        "    axs[i, 3].axis(\"off\")\n",
        "\n",
        "    axs[i, 4].imshow(cd_mask, cmap=\"turbo\")\n",
        "    print(np.unique(cd_mask))\n",
        "    axs[i, 4].set_title(f\"CD Mask\")\n",
        "    axs[i, 4].axis(\"off\")\n",
        "\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_IBpxGD6KOo"
      },
      "source": [
        "### Model Definition, Training function, Util functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Dm-pDsWo-Eyy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import segmentation_models_pytorch as smp\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "class Strategy3Model:\n",
        "    \"\"\"Combined CD and LCM model with checkpoint management\"\"\"\n",
        "    def __init__(self, cd_architecture='unet', lcm_architecture='unet',\n",
        "                 cd_encoder='resnet34', lcm_encoder='resnet34',\n",
        "                 input_channels=3, num_classes=13, num_semantic_classes=4):\n",
        "        # Initialize CD model\n",
        "        self.cd_model = self._create_cd_model(\n",
        "            architecture=cd_architecture,\n",
        "            encoder=cd_encoder,\n",
        "            input_channels=input_channels\n",
        "        )\n",
        "        # Initialize LCM model\n",
        "        self.lcm_model = self._create_lcm_model(\n",
        "            architecture=lcm_architecture,\n",
        "            encoder=lcm_encoder,\n",
        "            input_channels=input_channels,\n",
        "            num_semantic_classes=num_semantic_classes\n",
        "        )\n",
        "\n",
        "    def _create_cd_model(self, architecture, encoder, input_channels):\n",
        "        \"\"\"Create binary change detection model\"\"\"\n",
        "        if architecture.lower() == 'unet':\n",
        "            model = smp.Unet(\n",
        "                encoder_name=encoder,\n",
        "                encoder_weights='imagenet',\n",
        "                in_channels=input_channels*2,  # Concatenated images\n",
        "                classes=1,  # Binary output,\n",
        "                encoder_depth=4,  # Reduce depth (def=5)\n",
        "                decoder_channels=(256, 128, 64, 32)  # Reduce channels(def=(256, 128, 64, 32, 16))\n",
        "\n",
        "            )\n",
        "        elif architecture.lower() == 'deeplabv3plus':\n",
        "            model = smp.DeepLabV3Plus(\n",
        "                encoder_name=encoder,\n",
        "                encoder_weights='imagenet',\n",
        "                in_channels=input_channels*2,\n",
        "                classes=1,\n",
        "            )\n",
        "        # Add more architectures as needed\n",
        "        return model\n",
        "\n",
        "    def _create_lcm_model(self, architecture, encoder, input_channels, num_semantic_classes=4):\n",
        "        \"\"\"Create land cover mapping model\"\"\"\n",
        "        if architecture.lower() == 'unet':\n",
        "            model = smp.Unet(\n",
        "                encoder_name=encoder,\n",
        "                encoder_weights='imagenet',\n",
        "                in_channels=input_channels,\n",
        "                classes=num_semantic_classes,  # 4 land cover classes\n",
        "            )\n",
        "        elif architecture.lower() == 'deeplabv3plus':\n",
        "            model = smp.DeepLabV3Plus(\n",
        "                encoder_name=encoder,\n",
        "                encoder_weights='imagenet',\n",
        "                in_channels=input_channels,\n",
        "                classes=num_semantic_classes,\n",
        "            )\n",
        "        # Add more architectures as needed\n",
        "        return model\n",
        "\n",
        "    def to(self, device):\n",
        "        \"\"\"Move models to device\"\"\"\n",
        "        self.cd_model = self.cd_model.to(device)\n",
        "        self.lcm_model = self.lcm_model.to(device)\n",
        "        return self\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Set models to training mode\"\"\"\n",
        "        self.cd_model.train()\n",
        "        self.lcm_model.train()\n",
        "\n",
        "    def eval(self):\n",
        "        \"\"\"Set models to evaluation mode\"\"\"\n",
        "        self.cd_model.eval()\n",
        "        self.lcm_model.eval()\n",
        "\n",
        "def create_semantic_change_mask(binary_pred, lcm_pred_2019, lcm_pred_2024):\n",
        "    \"\"\"Convert binary change + LCM predictions to 13-class semantic change mask.\n",
        "\n",
        "    Optimized version using vectorized operations and pre-computed lookup tables.\n",
        "\n",
        "    Args:\n",
        "        binary_pred: Binary change prediction tensor (B, 1, H, W)\n",
        "        lcm_pred_2019: Land cover prediction tensor for 2019 (B, C, H, W)\n",
        "        lcm_pred_2024: Land cover prediction tensor for 2024 (B, C, H, W)\n",
        "\n",
        "    Returns:\n",
        "        Semantic change mask tensor (B, H, W) with values 0-12\n",
        "    \"\"\"\n",
        "    device = binary_pred.device\n",
        "    batch_size = binary_pred.shape[0]\n",
        "    height = binary_pred.shape[2]\n",
        "    width = binary_pred.shape[3]\n",
        "\n",
        "    # Pre-compute land cover predictions - do this once\n",
        "    lcm_2019 = torch.argmax(lcm_pred_2019, dim=1)  # (B, H, W)\n",
        "    lcm_2024 = torch.argmax(lcm_pred_2024, dim=1)  # (B, H, W)\n",
        "\n",
        "    # Create the change mask - use threshold without squeeze/unsqueeze\n",
        "    change_mask = binary_pred[:, 0] > 0.5  # (B, H, W)\n",
        "\n",
        "    # Initialize output tensor\n",
        "    semantic_mask = torch.zeros((batch_size, height, width), device=device, dtype=torch.long)\n",
        "\n",
        "    # Create transition matrix lookup table - speeds up class mapping\n",
        "    # Format: from_class * num_classes + to_class = semantic_class\n",
        "    num_classes = 4  # Water, Building, Sparse, Dense\n",
        "    transitions = torch.full((num_classes * num_classes,), 0, device=device)\n",
        "\n",
        "    # Populate transition matrix - all transitions not listed default to 0 (no change)\n",
        "    transition_map = {\n",
        "        (0, 1): 1,   # Water → Building\n",
        "        (0, 2): 2,   # Water → Sparse\n",
        "        (0, 3): 3,   # Water → Dense\n",
        "        (1, 0): 4,   # Building → Water\n",
        "        (1, 2): 5,   # Building → Sparse\n",
        "        (1, 3): 6,   # Building → Dense\n",
        "        (2, 0): 7,   # Sparse → Water\n",
        "        (2, 1): 8,   # Sparse → Building\n",
        "        (2, 3): 9,   # Sparse → Dense\n",
        "        (3, 0): 10,  # Dense → Water\n",
        "        (3, 1): 11,  # Dense → Building\n",
        "        (3, 2): 12,  # Dense → Sparse\n",
        "    }\n",
        "\n",
        "    for (from_idx, to_idx), semantic_idx in transition_map.items():\n",
        "        transitions[from_idx * num_classes + to_idx] = semantic_idx\n",
        "\n",
        "    # Vectorized computation of semantic classes\n",
        "    # Only compute for changed pixels to save memory\n",
        "    changed_pixels = change_mask.nonzero(as_tuple=True)\n",
        "    if len(changed_pixels[0]) > 0:\n",
        "        from_classes = lcm_2019[changed_pixels]  # (N,)\n",
        "        to_classes = lcm_2024[changed_pixels]    # (N,)\n",
        "\n",
        "        # Compute transition indices\n",
        "        transition_indices = from_classes * num_classes + to_classes  # (N,)\n",
        "\n",
        "        # Look up semantic classes from transition matrix\n",
        "        semantic_classes = transitions[transition_indices]  # (N,)\n",
        "\n",
        "        # Assign semantic classes to output mask\n",
        "        semantic_mask[changed_pixels] = semantic_classes\n",
        "\n",
        "    return semantic_mask\n",
        "\n",
        "def calculate_class_weights(train_loader, device, num_classes=13):\n",
        "    \"\"\"\n",
        "        method: Weighting method is 'square_balanced'\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize counters on CPU first\n",
        "    class_counts = torch.zeros(num_classes)\n",
        "    total_pixels = 0\n",
        "\n",
        "    print(\"Calculating class weights...\")\n",
        "    # Count frequencies on CPU\n",
        "    for batch in train_loader:\n",
        "        cd_mask = batch[-1]  # Get the last item which is cd_mask\n",
        "        unique_labels = torch.unique(cd_mask)\n",
        "        for label in unique_labels:\n",
        "            if label < num_classes:  # Safety check\n",
        "                class_counts[label] += (cd_mask == label).sum().item()\n",
        "        total_pixels += cd_mask.numel()\n",
        "\n",
        "    class_frequencies = class_counts / total_pixels\n",
        "    # Square root of inverse frequencies (less aggressive balancing)\n",
        "    weights = torch.sqrt(1.0 / class_frequencies)\n",
        "\n",
        "    # Normalize weights to sum to num_classes\n",
        "    weights = weights * (num_classes / weights.sum())\n",
        "\n",
        "    return weights\n",
        "\n",
        "\n",
        "def calculate_metrics(predictions, targets, num_classes):\n",
        "    \"\"\"\n",
        "    Calculate metrics with per-class IoU and unweighted averaging\n",
        "    \"\"\"\n",
        "    # Flatten predictions and targets\n",
        "    pred_flat = predictions.flatten()\n",
        "    target_flat = targets.flatten()\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(target_flat, pred_flat, labels=range(num_classes))\n",
        "\n",
        "    # Calculate metrics for each class\n",
        "    metrics = {}\n",
        "    class_metrics = []\n",
        "\n",
        "    # Per-class calculations\n",
        "    for i in range(num_classes):\n",
        "        tp = cm[i, i]\n",
        "        fp = np.sum(cm[:, i]) - tp\n",
        "        fn = np.sum(cm[i, :]) - tp\n",
        "        tn = np.sum(cm) - tp - fp - fn\n",
        "\n",
        "        # Handle divide by zero\n",
        "        union = tp + fp + fn\n",
        "        if union == 0:\n",
        "            iou = 0\n",
        "        else:\n",
        "            iou = tp / union\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        class_metrics.append({\n",
        "            'class': i,\n",
        "            'iou': iou,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1\n",
        "        })\n",
        "\n",
        "    # Calculate averages - only for classes present in ground truth\n",
        "    # precision, recall and f1 are weighted\n",
        "    present_classes = np.unique(target_flat)\n",
        "    total = np.sum(cm, axis=1)\n",
        "    metrics['miou'] = np.mean([class_metrics[i]['iou'] for i in present_classes])\n",
        "    metrics['precision'] = np.average([m['precision'] for m in class_metrics], weights=total)\n",
        "    metrics['recall'] = np.average([m['recall'] for m in class_metrics] , weights=total)\n",
        "    metrics['f1_score'] = np.average([m['f1'] for m in class_metrics], weights=total)\n",
        "\n",
        "    # Overall accuracy\n",
        "    metrics['accuracy'] = np.sum(np.diag(cm)) / np.sum(cm)\n",
        "\n",
        "    # Kappa calculation\n",
        "    n = np.sum(cm)\n",
        "    sum_po = np.sum(np.diag(cm))\n",
        "    sum_pe = np.sum(np.sum(cm, axis=0) * np.sum(cm, axis=1)) / n\n",
        "    metrics['kappa'] = (sum_po - sum_pe) / (n - sum_pe + 1e-6)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def train_epoch(model, train_loader, cd_criterion, lcm_criterion,\n",
        "                cd_optimizer, lcm_optimizer, device, num_classes=13):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    total_cd_loss = 0\n",
        "    total_lcm_loss = 0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "\n",
        "    for img_2019, img_2024, sem_2019, sem_2024, cd_mask in tqdm(train_loader):\n",
        "        # Move data to device\n",
        "        img_2019 = img_2019.to(device)\n",
        "        img_2024 = img_2024.to(device)\n",
        "        sem_2019 = sem_2019.to(device)\n",
        "        sem_2024 = sem_2024.to(device)\n",
        "        cd_mask = cd_mask.to(device)\n",
        "\n",
        "        # Create binary change mask for CD network\n",
        "        binary_mask = (cd_mask > 0).float().unsqueeze(1)\n",
        "\n",
        "        # Train CD network\n",
        "        cd_optimizer.zero_grad()\n",
        "        cd_logits = model.cd_model(torch.cat([img_2019, img_2024], dim=1))\n",
        "        cd_pred = torch.sigmoid(cd_logits)  # Apply sigmoid for binary prediction\n",
        "        cd_loss = cd_criterion(cd_pred, binary_mask)\n",
        "        cd_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.cd_model.parameters(), max_norm=1.0)\n",
        "        cd_optimizer.step()\n",
        "\n",
        "        # Train LCM network\n",
        "        lcm_optimizer.zero_grad()\n",
        "        lcm_pred_2019 = model.lcm_model(img_2019)\n",
        "        lcm_pred_2024 = model.lcm_model(img_2024)\n",
        "        lcm_loss = (lcm_criterion(lcm_pred_2019, sem_2019) +\n",
        "                   lcm_criterion(lcm_pred_2024, sem_2024)) / 2\n",
        "        lcm_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.lcm_model.parameters(), max_norm=1.0)\n",
        "        lcm_optimizer.step()\n",
        "\n",
        "        # Get semantic predictions for metrics\n",
        "        with torch.no_grad():\n",
        "            semantic_pred = create_semantic_change_mask(cd_pred, lcm_pred_2019, lcm_pred_2024)\n",
        "            all_predictions.append(semantic_pred.cpu())\n",
        "            all_targets.append(cd_mask.cpu())\n",
        "\n",
        "        total_cd_loss += cd_loss.item()\n",
        "        total_lcm_loss += lcm_loss.item()\n",
        "\n",
        "    # Calculate metrics\n",
        "    all_predictions = torch.cat(all_predictions, dim=0)\n",
        "    all_targets = torch.cat(all_targets, dim=0)\n",
        "    metrics = calculate_metrics(all_predictions, all_targets, num_classes=num_classes)\n",
        "\n",
        "    # Average losses\n",
        "    metrics['cd_loss'] = total_cd_loss / len(train_loader)\n",
        "    metrics['lcm_loss'] = total_lcm_loss / len(train_loader)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def validate(model, val_loader, cd_criterion, lcm_criterion, device, num_classes):\n",
        "    \"\"\"Validate model\"\"\"\n",
        "    model.eval()\n",
        "    total_cd_loss = 0\n",
        "    total_lcm_loss = 0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for img_2019, img_2024, sem_2019, sem_2024, cd_mask in val_loader:\n",
        "            img_2019 = img_2019.to(device)\n",
        "            img_2024 = img_2024.to(device)\n",
        "            sem_2019 = sem_2019.to(device)\n",
        "            sem_2024 = sem_2024.to(device)\n",
        "            cd_mask = cd_mask.to(device)\n",
        "\n",
        "            binary_mask = (cd_mask > 0).float().unsqueeze(1)\n",
        "\n",
        "            # CD predictions\n",
        "            cd_pred = model.cd_model(torch.cat([img_2019, img_2024], dim=1))\n",
        "            cd_loss = cd_criterion(cd_pred, binary_mask)\n",
        "\n",
        "            # LCM predictions\n",
        "            lcm_pred_2019 = model.lcm_model(img_2019)\n",
        "            lcm_pred_2024 = model.lcm_model(img_2024)\n",
        "            lcm_loss = (lcm_criterion(lcm_pred_2019, sem_2019) +\n",
        "                       lcm_criterion(lcm_pred_2024, sem_2024)) / 2\n",
        "\n",
        "            # Get semantic predictions\n",
        "            semantic_pred = create_semantic_change_mask(cd_pred, lcm_pred_2019, lcm_pred_2024)\n",
        "            all_predictions.append(semantic_pred.cpu())\n",
        "            all_targets.append(cd_mask.cpu())\n",
        "\n",
        "            total_cd_loss += cd_loss.item()\n",
        "            total_lcm_loss += lcm_loss.item()\n",
        "\n",
        "    # Calculate metrics\n",
        "    all_predictions = torch.cat(all_predictions, dim=0)\n",
        "    all_targets = torch.cat(all_targets, dim=0)\n",
        "    metrics = calculate_metrics(all_predictions, all_targets, num_classes=num_classes)\n",
        "\n",
        "    # Average losses\n",
        "    metrics['cd_loss'] = total_cd_loss / len(val_loader)\n",
        "    metrics['lcm_loss'] = total_lcm_loss / len(val_loader)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def print_metrics_summary(train_metrics, val_metrics, train_total_loss, val_total_loss):\n",
        "    \"\"\"Print a summary of the training/validation metrics\"\"\"\n",
        "    print(\"\\nTraining Metrics:\")\n",
        "    print(f\"  Total Loss: {train_total_loss:.4f}\")\n",
        "    print(f\"  Accuracy: {train_metrics['accuracy']:.4f}\")\n",
        "    print(f\"  Precision: {train_metrics['precision']:.4f}\")\n",
        "    print(f\"  Recall: {train_metrics['recall']:.4f}\")\n",
        "    print(f\"  F1-Score: {train_metrics['f1_score']:.4f}\")\n",
        "    print(f\"  mIoU: {train_metrics['miou']:.4f}\")\n",
        "    print(f\"  Kappa: {train_metrics['kappa']:.4f}\")\n",
        "\n",
        "    print(\"\\nValidation Metrics:\")\n",
        "    print(f\"  Total Loss: {val_total_loss:.4f}\")\n",
        "    print(f\"  Accuracy: {val_metrics['accuracy']:.4f}\")\n",
        "    print(f\"  Precision: {val_metrics['precision']:.4f}\")\n",
        "    print(f\"  Recall: {val_metrics['recall']:.4f}\")\n",
        "    print(f\"  F1-Score: {val_metrics['f1_score']:.4f}\")\n",
        "    print(f\"  mIoU: {val_metrics['miou']:.4f}\")\n",
        "    print(f\"  Kappa: {val_metrics['kappa']:.4f}\")\n",
        "\n",
        "def train_strategy3(model, train_loader, val_loader, num_epochs=50, device='cuda',\n",
        "                   checkpoint_path=None, loss='CE', num_classes=13, num_semantic_classes=4):\n",
        "    \"\"\"Train Strategy 3 model with checkpointing based on validation loss and overall metrics\"\"\"\n",
        "\n",
        "    # Loss functions\n",
        "    cd_criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    class_weights = calculate_class_weights(train_loader, num_classes=num_semantic_classes, device='cuda')  #square_balanced\n",
        "    print(class_weights)\n",
        "    lcm_criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "\n",
        "    # Optimizers\n",
        "    cd_optimizer = optim.AdamW(model.cd_model.parameters(), lr=1e-4, weight_decay=0.01)\n",
        "    lcm_optimizer = optim.AdamW(model.lcm_model.parameters(), lr=1e-4, weight_decay=0.01)\n",
        "\n",
        "    # Learning rate schedulers\n",
        "    cd_scheduler = ReduceLROnPlateau(cd_optimizer, mode='min', factor=0.5, patience=5)\n",
        "    lcm_scheduler = ReduceLROnPlateau(lcm_optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "    # Load checkpoint if exists\n",
        "    start_epoch = 0\n",
        "    best_total_loss = float('inf')\n",
        "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "        #model.load_state_dict(checkpoint['model_state_dict'])  # Load model weights\n",
        "        cd_optimizer.load_state_dict(checkpoint['cd_optimizer'])  # Load optimizer state\n",
        "        lcm_optimizer.load_state_dict(checkpoint['lcm_optimizer'])\n",
        "        cd_scheduler.load_state_dict(checkpoint['cd_scheduler'])  # Load scheduler state\n",
        "        lcm_scheduler.load_state_dict(checkpoint['lcm_scheduler'])\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        best_total_loss = checkpoint.get('best_total_loss', float('inf'))\n",
        "        print(f\"Loaded checkpoint from epoch {start_epoch}\")\n",
        "\n",
        "    history = {\n",
        "        'train': {\n",
        "            'loss': [],  # Combined CD and LCM loss\n",
        "            'accuracy': [],\n",
        "            'precision': [],\n",
        "            'recall': [],\n",
        "            'f1_score': [],\n",
        "            'miou': [],\n",
        "            'kappa': []\n",
        "        },\n",
        "        'val': {\n",
        "            'loss': [],  # Combined CD and LCM loss\n",
        "            'accuracy': [],\n",
        "            'precision': [],\n",
        "            'recall': [],\n",
        "            'f1_score': [],\n",
        "            'miou': [],\n",
        "            'kappa': []\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        # Training\n",
        "        train_metrics = train_epoch(\n",
        "            model, train_loader, cd_criterion, lcm_criterion,\n",
        "            cd_optimizer, lcm_optimizer, device, num_classes\n",
        "        )\n",
        "\n",
        "        # Validation\n",
        "        val_metrics = validate(\n",
        "            model, val_loader, cd_criterion, lcm_criterion,\n",
        "            device, num_classes\n",
        "        )\n",
        "\n",
        "        # Calculate total loss for both phases\n",
        "        train_total_loss = train_metrics['cd_loss'] + train_metrics['lcm_loss']\n",
        "        val_total_loss = val_metrics['cd_loss'] + val_metrics['lcm_loss']\n",
        "\n",
        "        # Update learning rates\n",
        "        cd_scheduler.step(val_metrics['cd_loss'])\n",
        "        lcm_scheduler.step(val_metrics['lcm_loss'])\n",
        "\n",
        "        # Store metrics in history - store overall metrics\n",
        "        for phase in ['train', 'val']:\n",
        "            metrics = train_metrics if phase == 'train' else val_metrics\n",
        "            total_loss = train_total_loss if phase == 'train' else val_total_loss\n",
        "\n",
        "            history[phase]['loss'].append(float(total_loss))\n",
        "            history[phase]['accuracy'].append(float(metrics['accuracy']))\n",
        "            history[phase]['precision'].append(float(metrics['precision']))\n",
        "            history[phase]['recall'].append(float(metrics['recall']))\n",
        "            history[phase]['f1_score'].append(float(metrics['f1_score']))\n",
        "            history[phase]['miou'].append(float(metrics['miou']))\n",
        "            history[phase]['kappa'].append(float(metrics['kappa']))\n",
        "\n",
        "        print_metrics_summary(train_metrics, val_metrics, train_total_loss, val_total_loss)\n",
        "\n",
        "        # Save checkpoint\n",
        "        if checkpoint_path:\n",
        "            metrics = {\n",
        "                'total_loss': val_total_loss,\n",
        "                'accuracy': val_metrics['accuracy'],\n",
        "                'precision': val_metrics['precision'],\n",
        "                'recall': val_metrics['recall'],\n",
        "                'f1_score': val_metrics['f1_score'],\n",
        "                'miou': val_metrics['miou'],\n",
        "                'kappa': val_metrics['kappa']\n",
        "            }\n",
        "\n",
        "            # Best model checkpoint based on total loss\n",
        "            if val_total_loss < best_total_loss:\n",
        "                best_total_loss = val_total_loss\n",
        "                torch.save(\n",
        "                    {\n",
        "                        'epoch': epoch + 1,\n",
        "                        'cd_model': model.cd_model.state_dict(),\n",
        "                        'lcm_model': model.lcm_model.state_dict(),\n",
        "                        'cd_optimizer': cd_optimizer.state_dict(),\n",
        "                        'lcm_optimizer': lcm_optimizer.state_dict(),\n",
        "                        'cd_scheduler': cd_scheduler.state_dict(),\n",
        "                        'lcm_scheduler': lcm_scheduler.state_dict(),\n",
        "                        'best_total_loss': best_total_loss,\n",
        "                        'metrics': metrics,\n",
        "                    },\n",
        "                    checkpoint_path\n",
        "                )\n",
        "                print(f\"Saved new best model with total loss: {best_total_loss:.4f}\")\n",
        "\n",
        "    return model, history\n",
        "\n",
        "import json\n",
        "def save_training_history(history, checkpoint_path, save_path, save_path_bestepoch):\n",
        "    \"\"\"\n",
        "    Save training history and best epoch information to JSON files.\n",
        "\n",
        "    Args:\n",
        "        history (dict): Dictionary containing training and validation metrics\n",
        "        checkpoint_path (str): Path to the model checkpoint file\n",
        "        save_path (str): Path to save the training history\n",
        "        save_path_bestepoch (str): Path to save the best epoch info\n",
        "    \"\"\"\n",
        "    processed_history = {}\n",
        "    for phase, metrics in history.items():\n",
        "        if isinstance(metrics, list):  # Check if metrics is a list\n",
        "            processed_history[phase] = [\n",
        "                {metric: (value.tolist() if hasattr(value, 'tolist') else value)\n",
        "                 for metric, value in entry.items()} if isinstance(entry, dict) else entry\n",
        "                for entry in metrics\n",
        "            ]\n",
        "        else:  # Handle non-list entries\n",
        "            processed_history[phase] = metrics.tolist() if hasattr(metrics, 'tolist') else metrics\n",
        "\n",
        "    # Save processed history to a JSON file\n",
        "    with open(save_path, 'w') as f:\n",
        "        json.dump(processed_history, f, indent=4)\n",
        "\n",
        "    print(f\"Training history saved to: {save_path}\")\n",
        "\n",
        "    # Load checkpoint to get best epoch info\n",
        "    checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
        "    # print(\"\\nCheckpoint contents:\")\n",
        "    # for key in checkpoint.keys():\n",
        "    #     print(f\"- {key}\")\n",
        "\n",
        "    # Extract best epoch information\n",
        "    epoch_data = {\n",
        "        'best_epoch': int(checkpoint['epoch']),\n",
        "        'total_loss': float(checkpoint['metrics']['total_loss']),\n",
        "        'accuracy': float(checkpoint['metrics']['accuracy']),\n",
        "        'precision': float(checkpoint['metrics']['precision']),\n",
        "        'recall': float(checkpoint['metrics']['recall']),\n",
        "        'f1': float(checkpoint['metrics']['f1_score']),\n",
        "        'miou': float(checkpoint['metrics']['miou']),\n",
        "        'kappa': float(checkpoint['metrics']['kappa'])\n",
        "    }\n",
        "\n",
        "    # Save the best epoch info\n",
        "    with open(save_path_bestepoch, 'w') as f:\n",
        "        json.dump(epoch_data, f, indent=4)\n",
        "    print(f\"Best epoch info saved to: {save_path_bestepoch}\")\n",
        "\n",
        "\n",
        "def save_test_metrics(history, save_path):\n",
        "    # Convert tensors or arrays in the history to lists for JSON serialization\n",
        "    processed_history = {}\n",
        "    for phase, metrics in history.items():\n",
        "        if isinstance(metrics, list):  # Check if metrics is a list\n",
        "            processed_history[phase] = [\n",
        "                {metric: (value.tolist() if hasattr(value, 'tolist') else value)\n",
        "                 for metric, value in entry.items()} if isinstance(entry, dict) else entry\n",
        "                for entry in metrics\n",
        "            ]\n",
        "        else:  # Handle non-list entries\n",
        "            processed_history[phase] = metrics.tolist() if hasattr(metrics, 'tolist') else metrics\n",
        "\n",
        "    # Save processed history to a JSON file\n",
        "    with open(save_path, 'w') as f:\n",
        "        json.dump(processed_history, f, indent=4)\n",
        "\n",
        "    print(f\"Testing history saved to: {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnCy0xzp6KOs"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "te9aeCs6Wfye"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_classes=13   #Change Detection classes (3 for cd1, 13 for cd2)\n",
        "num_semantic_classes=4  #Semantic Segmentation LCM classes (4 for both)\n",
        "num_epochs = 100\n",
        "weighting_method = 'square_balanced'\n",
        "loss = 'CE' #'CE'\n",
        "checkpoint_path = f'{SAVING_DIR}/best_Strat3_{num_epochs}_epochs.pt'  #'models/strategy3_model.pt'\n",
        "\n",
        "# Create model\n",
        "model = Strategy3Model(\n",
        "    cd_architecture='unet',\n",
        "    lcm_architecture='unet',\n",
        "    cd_encoder='resnet34',\n",
        "    lcm_encoder='resnet34',\n",
        "    input_channels=3,\n",
        "    num_classes=num_classes,\n",
        "    num_semantic_classes=num_semantic_classes\n",
        ").to(device)\n",
        "\n",
        "# Train model\n",
        "model2, history = train_strategy3(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=num_epochs,\n",
        "    device=device,\n",
        "    checkpoint_path=checkpoint_path,\n",
        "    weighting_method=weighting_method,\n",
        "    loss=loss,\n",
        "    num_classes=num_classes,\n",
        "    num_semantic_classes=num_semantic_classes\n",
        ")\n",
        "\n",
        "save_path = f'{SAVING_DIR}/strat3_train_history.json'\n",
        "save_path_bestepoch = f'{SAVING_DIR}/strat3_bestepoch.json'\n",
        "save_training_history(history, checkpoint_path, save_path, save_path_bestepoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTc8qrAS6KOt"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o3qWl8Yaj7Q0",
        "outputId": "82185483-8682-4367-c13d-a9ae36ff3b6a"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "def visualize_predictions(model, img_2019, img_2024, true_mask, seg_mask_2019, seg_mask_2024):\n",
        "    \"\"\"\n",
        "    Visualize model predictions in a single row\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Remove batch dimension if present\n",
        "        if img_2019.dim() == 4:\n",
        "            img_2019 = img_2019.squeeze(0)\n",
        "        if img_2024.dim() == 4:\n",
        "            img_2024 = img_2024.squeeze(0)\n",
        "        if true_mask.dim() == 4:\n",
        "            true_mask = true_mask.squeeze(0)\n",
        "        if seg_mask_2019.dim() == 4:\n",
        "            seg_mask_2019 = seg_mask_2019.squeeze(0)\n",
        "        if seg_mask_2024.dim() == 4:\n",
        "            seg_mask_2024 = seg_mask_2024.squeeze(0)\n",
        "\n",
        "        # Get predictions\n",
        "        cd_pred = model.cd_model(torch.cat([img_2019.unsqueeze(0), img_2024.unsqueeze(0)], dim=1))\n",
        "        lcm_pred_2019 = model.lcm_model(img_2019.unsqueeze(0))\n",
        "        lcm_pred_2024 = model.lcm_model(img_2024.unsqueeze(0))\n",
        "        semantic_pred = create_semantic_change_mask(cd_pred, lcm_pred_2019, lcm_pred_2024)\n",
        "        semantic_pred = semantic_pred.squeeze(0)\n",
        "\n",
        "    # Create single row visualization\n",
        "    fig, axes = plt.subplots(1, 9, figsize=(24, 3))\n",
        "\n",
        "    # Plot images without titles\n",
        "    # Original images\n",
        "    axes[0].imshow(img_2019.cpu().permute(1,2,0))\n",
        "    axes[0].set_title('Image2019')\n",
        "    axes[1].imshow(img_2024.cpu().permute(1,2,0))\n",
        "    axes[1].set_title('Image2024')\n",
        "\n",
        "    # Binary change detection\n",
        "    axes[2].imshow(torch.sigmoid(cd_pred).cpu().squeeze(), cmap='gray')\n",
        "    axes[2].set_title('BinaryCD')\n",
        "\n",
        "    # Ground truth segmentation masks\n",
        "    axes[3].imshow(seg_mask_2019.cpu(), cmap='tab10')\n",
        "    axes[3].set_title('GTSemMask2019')\n",
        "    axes[4].imshow(seg_mask_2024.cpu(), cmap='tab10')\n",
        "    axes[4].set_title('GTSemMask2024')\n",
        "\n",
        "    # Predicted segmentation masks\n",
        "    axes[5].imshow(torch.argmax(lcm_pred_2019, dim=1).squeeze(0).cpu(), cmap='tab10')\n",
        "    axes[5].set_title('PredSemMask2019')\n",
        "    axes[6].imshow(torch.argmax(lcm_pred_2024, dim=1).squeeze(0).cpu(), cmap='tab10')\n",
        "    axes[6].set_title('PredSemMask2024')\n",
        "    # Change detection\n",
        "    axes[7].imshow(true_mask.cpu(), cmap='tab10')\n",
        "    axes[7].set_title('GTChangeMask')\n",
        "    axes[8].imshow(semantic_pred.cpu(), cmap='tab10')\n",
        "    axes[8].set_title('PredChangeMask')\n",
        "\n",
        "    # Remove axes and padding\n",
        "    for ax in axes:\n",
        "        ax.axis('off')\n",
        "    plt.subplots_adjust(wspace=0.05, hspace=0)\n",
        "\n",
        "    return fig\n",
        "\n",
        "def test_strategy3(model, test_loader, device, num_samples_to_plot=5, \n",
        "                   checkpoint_path='best_model.pt', num_classes=13, num_semantic_classes=4):\n",
        "    \"\"\"\n",
        "    Evaluate model and display metrics for both semantic segmentation and change detection\n",
        "    \"\"\"\n",
        "    # Load checkpoint - modified to load separate models\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    print(f\"Loading checkpoint from {checkpoint_path}\")\n",
        "\n",
        "    # Load the separate models\n",
        "    try:\n",
        "        model.cd_model.load_state_dict(checkpoint['cd_model'])\n",
        "        model.lcm_model.load_state_dict(checkpoint['lcm_model'])\n",
        "        print(\"Successfully loaded both CD and LCM models\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading models: {e}\")\n",
        "        return\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize metric storage\n",
        "    change_predictions = []\n",
        "    change_targets = []\n",
        "    seg_predictions_2019 = []\n",
        "    seg_targets_2019 = []\n",
        "    seg_predictions_2024 = []\n",
        "    seg_targets_2024 = []\n",
        "\n",
        "    # Store samples for visualization\n",
        "    stored_samples = []\n",
        "    total_samples = len(test_loader.dataset)\n",
        "    random_indices = set(random.sample(range(total_samples), num_samples_to_plot))\n",
        "    current_idx = 0\n",
        "\n",
        "    print(\"Testing model...\")\n",
        "    with torch.no_grad():\n",
        "        for img_2019, img_2024, sem_2019, sem_2024, cd_mask in tqdm(test_loader):\n",
        "            # Move to device\n",
        "            img_2019 = img_2019.to(device)\n",
        "            img_2024 = img_2024.to(device)\n",
        "            sem_2019 = sem_2019.to(device)\n",
        "            sem_2024 = sem_2024.to(device)\n",
        "            cd_mask = cd_mask.to(device)\n",
        "\n",
        "            # Get predictions\n",
        "            cd_pred = model.cd_model(torch.cat([img_2019, img_2024], dim=1))\n",
        "            lcm_pred_2019 = model.lcm_model(img_2019)\n",
        "            lcm_pred_2024 = model.lcm_model(img_2024)\n",
        "            semantic_pred = create_semantic_change_mask(cd_pred, lcm_pred_2019, lcm_pred_2024)\n",
        "\n",
        "            # Get semantic segmentation predictions\n",
        "            seg_pred_2019 = torch.argmax(lcm_pred_2019, dim=1)\n",
        "            seg_pred_2024 = torch.argmax(lcm_pred_2024, dim=1)\n",
        "\n",
        "            # Append predictions and targets for later metric calculation\n",
        "            change_predictions.append(semantic_pred.cpu())\n",
        "            change_targets.append(cd_mask.cpu())\n",
        "            seg_predictions_2019.append(seg_pred_2019.cpu())\n",
        "            seg_targets_2019.append(sem_2019.cpu())\n",
        "            seg_predictions_2024.append(seg_pred_2024.cpu())\n",
        "            seg_targets_2024.append(sem_2024.cpu())\n",
        "\n",
        "            # Store random samples\n",
        "            batch_size = img_2019.size(0)\n",
        "            for i in range(batch_size):\n",
        "                if current_idx + i in random_indices:\n",
        "                    stored_samples.append({\n",
        "                        'img_2019': img_2019[i],\n",
        "                        'img_2024': img_2024[i],\n",
        "                        'cd_pred': cd_pred[i],\n",
        "                        'lcm_pred_2019': lcm_pred_2019[i],\n",
        "                        'lcm_pred_2024': lcm_pred_2024[i],\n",
        "                        'semantic_pred': semantic_pred[i],\n",
        "                        'true_mask': cd_mask[i],\n",
        "                        'seg_mask_2019': sem_2019[i],\n",
        "                        'seg_mask_2024': sem_2024[i]\n",
        "                    })\n",
        "            current_idx += batch_size\n",
        "\n",
        "    # Calculate metrics\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Semantic Segmentation Metrics:\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # 2019 Segmentation Metrics\n",
        "    seg_preds_2019 = torch.cat(seg_predictions_2019, dim=0).numpy()\n",
        "    seg_targets_2019 = torch.cat(seg_targets_2019, dim=0).numpy()\n",
        "    metrics_seg_2019 = calculate_metrics(seg_preds_2019, seg_targets_2019, num_classes=num_semantic_classes)\n",
        "\n",
        "    print(\"\\n2019 Segmentation:\")\n",
        "    print(f\"Accuracy: {metrics_seg_2019['accuracy']:.4f}\")\n",
        "    print(f\"Mean IoU: {metrics_seg_2019['miou']:.4f}\")\n",
        "    print(f\"F1 Score: {metrics_seg_2019['f1_score']:.4f}\")\n",
        "    print(f\"Precision: {metrics_seg_2019['precision']:.4f}\")\n",
        "    print(f\"Recall: {metrics_seg_2019['recall']:.4f}\")\n",
        "    print(f\"Kappa: {metrics_seg_2019['kappa']:.4f}\")\n",
        "\n",
        "    # 2024 Segmentation Metrics\n",
        "    seg_preds_2024 = torch.cat(seg_predictions_2024, dim=0).numpy()\n",
        "    seg_targets_2024 = torch.cat(seg_targets_2024, dim=0).numpy()\n",
        "    metrics_seg_2024 = calculate_metrics(seg_preds_2024, seg_targets_2024, num_classes=num_semantic_classes)\n",
        "\n",
        "    print(\"\\n2024 Segmentation:\")\n",
        "    print(f\"Accuracy: {metrics_seg_2024['accuracy']:.4f}\")\n",
        "    print(f\"Mean IoU: {metrics_seg_2024['miou']:.4f}\")\n",
        "    print(f\"F1 Score: {metrics_seg_2024['f1_score']:.4f}\")\n",
        "    print(f\"Precision: {metrics_seg_2024['precision']:.4f}\")\n",
        "    print(f\"Recall: {metrics_seg_2024['recall']:.4f}\")\n",
        "    print(f\"Kappa: {metrics_seg_2024['kappa']:.4f}\")\n",
        "\n",
        "    # Average Segmentation Metrics\n",
        "    print(\"\\nAverage Segmentation:\")\n",
        "    avg_seg_metrics = {\n",
        "        'accuracy': (metrics_seg_2019['accuracy'] + metrics_seg_2024['accuracy']) / 2,\n",
        "        'miou': (metrics_seg_2019['miou'] + metrics_seg_2024['miou']) / 2,\n",
        "        'f1_score': (metrics_seg_2019['f1_score'] + metrics_seg_2024['f1_score']) / 2,\n",
        "        'precision': (metrics_seg_2019['precision'] + metrics_seg_2024['precision']) / 2,\n",
        "        'recall': (metrics_seg_2019['recall'] + metrics_seg_2024['recall']) / 2,\n",
        "        'kappa': (metrics_seg_2019['kappa'] + metrics_seg_2024['kappa']) / 2\n",
        "    }\n",
        "    print(f\"Accuracy: {avg_seg_metrics['accuracy']:.4f}\")\n",
        "    print(f\"Mean IoU: {avg_seg_metrics['miou']:.4f}\")\n",
        "    print(f\"F1 Score: {avg_seg_metrics['f1_score']:.4f}\")\n",
        "    print(f\"Precision: {avg_seg_metrics['precision']:.4f}\")\n",
        "    print(f\"Recall: {avg_seg_metrics['recall']:.4f}\")\n",
        "    print(f\"Kappa: {avg_seg_metrics['kappa']:.4f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Change Detection Metrics:\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Change Detection Metrics\n",
        "    change_preds = torch.cat(change_predictions, dim=0).numpy()\n",
        "    change_targets = torch.cat(change_targets, dim=0).numpy()\n",
        "    metrics_change = calculate_metrics(change_preds, change_targets, num_classes=num_classes)\n",
        "\n",
        "    print(f\"Accuracy: {metrics_change['accuracy']:.4f}\")\n",
        "    print(f\"Mean IoU: {metrics_change['miou']:.4f}\")\n",
        "    print(f\"F1 Score: {metrics_change['f1_score']:.4f}\")\n",
        "    print(f\"Precision: {metrics_change['precision']:.4f}\")\n",
        "    print(f\"Recall: {metrics_change['recall']:.4f}\")\n",
        "    print(f\"Kappa: {metrics_change['kappa']:.4f}\")\n",
        "\n",
        "    # Plot stored samples\n",
        "    print(\"\\nPlotting random samples...\")\n",
        "    for sample in stored_samples:\n",
        "        fig = visualize_predictions(\n",
        "            model,\n",
        "            sample['img_2019'],\n",
        "            sample['img_2024'],\n",
        "            sample['true_mask'],\n",
        "            sample['seg_mask_2019'],\n",
        "            sample['seg_mask_2024']\n",
        "        )\n",
        "        plt.show()\n",
        "        plt.close(fig)\n",
        "\n",
        "    return {\n",
        "        'segmentation_2019': metrics_seg_2019,\n",
        "        'segmentation_2024': metrics_seg_2024,\n",
        "        'segmentation_avg': avg_seg_metrics,\n",
        "        'change_detection': metrics_change\n",
        "    }\n",
        "\n",
        "### Test model\n",
        "test_metrics = test_strategy3(model, test_loader, device,\n",
        "                                  num_samples_to_plot=5,\n",
        "                                  checkpoint_path=checkpoint_path,\n",
        "                                  num_classes=num_classes,\n",
        "                                  num_semantic_classes=num_semantic_classes)\n",
        "\n",
        "save_test_metrics(test_metrics, save_path=f'{SAVING_DIR}/strat3_test_metrics.json')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
