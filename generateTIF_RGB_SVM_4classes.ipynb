{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Code to Generate TIF from Google Earth Engine\n",
        "### Requirements: \n",
        "- Google Earth Engine Project\n",
        "- Google Drive access (to store the accuracy metrics in a csv)\n",
        "- Google drive access (to store the generated TIFs)\n",
        "- A `coordinates.xlsx` file - to copy the coordinates from "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iVsWd1M7VIS"
      },
      "source": [
        "### Initialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yJoUC6vZ6Rar"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import csv\n",
        "import os\n",
        "\n",
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize the library.\n",
        "ee.Initialize(project='omkarsoak-ee')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wm6FJlGjYcdX",
        "outputId": "3aa8ee86-337c-480f-e9c5-6b9d2fcb3a58"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "csv_filename = '/content/drive/My Drive/BTechProject/Eur_new_classification_results1.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4q8Elxgt69h"
      },
      "source": [
        "### COMBINED RGB + MASK SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ie-0yo0qt2L7"
      },
      "outputs": [],
      "source": [
        "def process_point_svm(lon, lat, city, state, year, filename):\n",
        "    # Define the center point\n",
        "    center = ee.Geometry.Point([lon, lat])\n",
        "\n",
        "    # Define the bounding box with a buffer radius (2560 meters for 512x512 pixels at 10m resolution)\n",
        "    geometry = center.buffer(2560).bounds()\n",
        "\n",
        "    # Load Sentinel-2 MSI Level-2A as ImageCollection\n",
        "    sentinel2 = (ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
        "                 .filterBounds(geometry)\n",
        "                 .filterDate(f'{year}-07-01', f'{year}-09-30')\n",
        "                 .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 3))\n",
        "                 .median())\n",
        "\n",
        "    # Calculate indices and masks\n",
        "    ndvi = sentinel2.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
        "    # ndwi = sentinel2.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
        "    swm = sentinel2.expression(\n",
        "        '(B2 + B3) / (B8 + B11)',\n",
        "        {\n",
        "            'B2': sentinel2.select('B2'),\n",
        "            'B3': sentinel2.select('B3'),\n",
        "            'B8': sentinel2.select('B8'),\n",
        "            'B11': sentinel2.select('B11')\n",
        "        }\n",
        "    ).rename('SWM')\n",
        "\n",
        "    # Combine NDVI and NDWI into a single image for sampling\n",
        "    feature_image = ndvi.addBands(swm)\n",
        "\n",
        "    # Define class masks\n",
        "    water_mask = swm.gt(1.5)\n",
        "    building_mask = ndvi.gt(0.0).And(ndvi.lt(0.4))\n",
        "    veg_mask = ndvi.gte(0.4)\n",
        "    # dense_veg_mask = ndvi.gte(0.7)\n",
        "\n",
        "    # Sample points for each class\n",
        "    NUM_OF_PIXELS = 70000\n",
        "\n",
        "    def sample_points(mask, class_value):\n",
        "        return feature_image.updateMask(mask).sample(\n",
        "            region=geometry,\n",
        "            scale=10,\n",
        "            numPixels=NUM_OF_PIXELS,\n",
        "            geometries=True\n",
        "        ).map(lambda f: f.set('class', class_value))\n",
        "\n",
        "    water_points = sample_points(water_mask, 0)\n",
        "    building_points = sample_points(building_mask, 1)\n",
        "    veg_points = sample_points(veg_mask, 2)\n",
        "    # dense_veg_points = sample_points(dense_veg_mask, 3)\n",
        "\n",
        "    # Merge all training points\n",
        "    training_points = water_points.merge(building_points).merge(veg_points)\n",
        "\n",
        "    # Split the data into training (80%) and validation (20%) sets\n",
        "    with_random = training_points.randomColumn()\n",
        "    split = 0.8\n",
        "    training_data = with_random.filter(ee.Filter.lt('random', split))\n",
        "    validation_data = with_random.filter(ee.Filter.gte('random', split))\n",
        "\n",
        "    # Train an SVM classifier\n",
        "    svm_classifier = ee.Classifier.libsvm().train(\n",
        "        features=training_data,\n",
        "        classProperty='class',\n",
        "        inputProperties=['NDVI', 'SWM']\n",
        "    )\n",
        "\n",
        "    # Classify the image\n",
        "    classified_image = feature_image.classify(svm_classifier)\n",
        "    # classified_image = classified_image.toUint16()\n",
        "\n",
        "    # # Evaluate the classifier using the validation data\n",
        "    # validation = validation_data.classify(svm_classifier)\n",
        "    # validation_confusion_matrix = validation.errorMatrix('class', 'classification')\n",
        "    # print('Validation Error Matrix:', validation_confusion_matrix.getInfo())\n",
        "    # print('Validation Overall Accuracy:', validation_confusion_matrix.accuracy().getInfo())\n",
        "\n",
        "    # # Compute training accuracy\n",
        "    # training_confusion_matrix = svm_classifier.confusionMatrix()\n",
        "    # print('Training Error Matrix:', training_confusion_matrix.getInfo())\n",
        "    # print('Training Overall Accuracy:', training_confusion_matrix.accuracy().getInfo())\n",
        "\n",
        "\n",
        "    # Evaluate the classifier using the validation data\n",
        "    validation = validation_data.classify(svm_classifier)\n",
        "    validation_confusion_matrix = validation.errorMatrix('class', 'classification')\n",
        "    validation_accuracy = validation_confusion_matrix.accuracy().getInfo()\n",
        "\n",
        "    # Compute training accuracy\n",
        "    training_confusion_matrix = svm_classifier.confusionMatrix()\n",
        "    training_accuracy = training_confusion_matrix.accuracy().getInfo()\n",
        "\n",
        "    # # Save results to CSV\n",
        "    # csv_filename = \"classification_results.csv\"\n",
        "    header = [\"City\", \"State\", \"Year\", \"Filename\",\n",
        "              \"Training Accuracy\", \"Training Confusion Matrix\",\n",
        "              \"Validation Accuracy\", \"Validation Confusion Matrix\"]\n",
        "\n",
        "    data = [\n",
        "        city, state, year, filename,\n",
        "        training_accuracy, training_confusion_matrix.getInfo(),\n",
        "        validation_accuracy, validation_confusion_matrix.getInfo()\n",
        "    ]\n",
        "\n",
        "    # Write to CSV (append if file exists, otherwise create)\n",
        "    try:\n",
        "        with open(csv_filename, 'a', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            if file.tell() == 0:  # File is empty, write header\n",
        "                writer.writerow(header)\n",
        "            writer.writerow(data)\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing to CSV: {e}\")\n",
        "\n",
        "    # print(f\"Results saved to {csv_filename}.\")\n",
        "\n",
        "    # try:\n",
        "    #   file_exists = os.path.isfile(csv_filename)\n",
        "    #   with open(csv_filename, 'a', newline='') as file:\n",
        "    #       writer = csv.writer(file)\n",
        "    #       if not file_exists:  # If the file doesn't exist, write the header\n",
        "    #           writer.writerow(header)\n",
        "    #       writer.writerow(data)\n",
        "    # except Exception as e:\n",
        "    #   print(f\"Error writing to CSV: {e}\")\n",
        "\n",
        "    print(f\"Results saved to {csv_filename}.\")\n",
        "\n",
        "    # Enhanced RGB export\n",
        "    enhanced_rgb = sentinel2.select(['B4', 'B3', 'B2']).multiply(2.0)\n",
        "    viz_params = {\n",
        "        'bands': ['B4', 'B3', 'B2'],\n",
        "        'min': 0,\n",
        "        'max': 3000,\n",
        "        'gamma': 1\n",
        "    }\n",
        "\n",
        "    # Export tasks\n",
        "    # 1. Enhanced RGB\n",
        "    enhanced_rgb_task = ee.batch.Export.image.toDrive(\n",
        "        image=enhanced_rgb.uint16().clip(geometry).visualize(**viz_params),\n",
        "        description=f'EnhancedRGB_{filename}_{year}',\n",
        "        folder='ChangeDetectionEur',\n",
        "        fileNamePrefix=f'{filename}_{year}',\n",
        "        region=geometry,\n",
        "        fileFormat='GEOTIFF',\n",
        "        crs='EPSG:3857',\n",
        "        dimensions='512x512'\n",
        "    )\n",
        "\n",
        "    # 2. Classified Image\n",
        "    class_vis = {\n",
        "        'min': 0,\n",
        "        'max': 2,\n",
        "        'palette': ['lightblue', 'white', 'lightgreen']\n",
        "    }\n",
        "    mask_task = ee.batch.Export.image.toDrive(\n",
        "        image=classified_image.uint16(),\n",
        "        description=f'm_{filename}_{year}',\n",
        "        folder='ChangeDetectionEur',\n",
        "        fileNamePrefix=f'm_{filename}_{year}',\n",
        "        region=geometry,\n",
        "        fileFormat='GEOTIFF',\n",
        "        crs='EPSG:3857',\n",
        "        dimensions='512x512'\n",
        "    )\n",
        "\n",
        "    # Start both export tasks\n",
        "    enhanced_rgb_task.start()\n",
        "    mask_task.start()\n",
        "\n",
        "    print(f\"Tasks started for {city} at ({lon}, {lat}).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import data from csv\n",
        "- directly copy paste into a cell\n",
        "- just do `data = pd.read_csv(...`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yqA8Agp_YF8I"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "data = pd.read_csv(io.StringIO('''\n",
        "Netherlands,Rotterdam,2019,2024,\"4.47777963162828,51.9222407862643\",51.92224079,4.477779632,\"4.47777963162828,51.9722407862643\",\"4.52777963162828,51.9722407862643\",\"4.52777963162828,51.9222407862643\",\"4.52777963162828,51.8722407862643\",\"4.47777963162828,51.8722407862643\",\"4.42777963162828,51.8722407862643\",\"4.42777963162828,51.9222407862643\",\"4.42777963162828,51.9722407862643\"\n",
        "Norway,Oslo,2019,2024,\"10.7954092160319,59.9271445180858\",59.92714452,10.79540922,\"10.7954092160319,59.9771445180858\",\"10.8454092160319,59.9771445180858\",\"10.8454092160319,59.9271445180858\",\"10.8454092160319,59.8771445180858\",\"10.7954092160319,59.8771445180858\",\"10.7454092160319,59.8771445180858\",\"10.7454092160319,59.9271445180858\",\"10.7454092160319,59.9771445180858\"\n",
        "Poland,Wroclaw,2019,2024,\"17.0313825224446,51.110014588585\",51.11001459,17.03138252,\"17.0313825224446,51.160014588585\",\"17.0813825224446,51.160014588585\",\"17.0813825224446,51.110014588585\",\"17.0813825224446,51.060014588585\",\"17.0313825224446,51.060014588585\",\"16.9813825224446,51.060014588585\",\"16.9813825224446,51.110014588585\",\"16.9813825224446,51.160014588585\"\n",
        "Poland,Krakow,2019,2024,\"19.9567179575101,50.0588340571982\",50.05883406,19.95671796,\"19.9567179575101,50.1088340571982\",\"20.0067179575101,50.1088340571982\",\"20.0067179575101,50.0588340571982\",\"20.0067179575101,50.0088340571982\",\"19.9567179575101,50.0088340571982\",\"19.9067179575101,50.0088340571982\",\"19.9067179575101,50.0588340571982\",\"19.9067179575101,50.1088340571982\"\n",
        "Poland,Lodz,2019,2024,\"19.4643562223554,51.7648092131436\",51.76480921,19.46435622,\"19.4643562223554,51.8148092131436\",\"19.5143562223554,51.8148092131436\",\"19.5143562223554,51.7648092131436\",\"19.5143562223554,51.7148092131436\",\"19.4643562223554,51.7148092131436\",\"19.4143562223554,51.7148092131436\",\"19.4143562223554,51.7648092131436\",\"19.4143562223554,51.8148092131436\"\n",
        "Poland,Poznan,2019,2024,\"16.914742312342,52.4049821958422\",52.4049822,16.91474231,\"16.914742312342,52.4549821958422\",\"16.964742312342,52.4549821958422\",\"16.964742312342,52.4049821958422\",\"16.964742312342,52.3549821958422\",\"16.914742312342,52.3549821958422\",\"16.864742312342,52.3549821958422\",\"16.864742312342,52.4049821958422\",\"16.864742312342,52.4549821958422\"\n",
        "Poland,Warsaw,2019,2024,\"21.0112859757535,52.232466557807\",52.23246656,21.01128598,\"21.0112859757535,52.282466557807\",\"21.0612859757535,52.282466557807\",\"21.0612859757535,52.232466557807\",\"21.0612859757535,52.182466557807\",\"21.0112859757535,52.182466557807\",\"20.9612859757535,52.182466557807\",\"20.9612859757535,52.232466557807\",\"20.9612859757535,52.282466557807\"\n",
        "Portugal,Lisbon,2019,2024,\"-9.17003829572333,38.7550284336539\",38.75502843,-9.170038296,\"-9.17003829572333,38.8050284336539\",\"-9.12003829572333,38.8050284336539\",\"-9.12003829572333,38.7550284336539\",\"-9.12003829572333,38.7050284336539\",\"-9.17003829572333,38.7050284336539\",\"-9.22003829572333,38.7050284336539\",\"-9.22003829572333,38.7550284336539\",\"-9.22003829572333,38.8050284336539\"\n",
        "Romania,Bucharest,2019,2024,\"26.0903292835383,44.4279852258696\",44.42798523,26.09032928,\"26.0903292835383,44.4779852258696\",\"26.1403292835383,44.4779852258696\",\"26.1403292835383,44.4279852258696\",\"26.1403292835383,44.3779852258696\",\"26.0903292835383,44.3779852258696\",\"26.0403292835383,44.3779852258696\",\"26.0403292835383,44.4279852258696\",\"26.0403292835383,44.4779852258696\"\n",
        "'''), header=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXXCR7FbpiwC",
        "outputId": "f347ff65-3dcb-4040-ceef-ac07c4f4832e"
      },
      "outputs": [],
      "source": [
        "coord_list = [4, 7, 8, 9, 10, 11, 12, 13, 14]\n",
        "coord_name = ['C', 'N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW']\n",
        "ncities = data.shape[0]\n",
        "\n",
        "# Process each city\n",
        "for j in range(ncities):\n",
        "    cityData = data.iloc[j]\n",
        "    city = cityData[1]\n",
        "    state = cityData[0]\n",
        "    print(city, state)\n",
        "\n",
        "    for i in range(9):\n",
        "        try:\n",
        "            coord = cityData.iloc[coord_list[i]].split(',')\n",
        "            filename = f'{state}_{city}_{coord_name[i]}'\n",
        "            print(filename)\n",
        "\n",
        "            lon = float(coord[0])\n",
        "            lat = float(coord[1])\n",
        "            process_point_svm(lon, lat, city, state, '2019', filename)\n",
        "            process_point_svm(lon, lat, city, state, '2024', filename)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {state}, {city}, {coord_name[i]}: {e}\")\n",
        "            print(f\"Exception details: {type(e)._name_} - {e}\")\n",
        "    print()\n",
        "\n",
        "print(\"All tasks have been started.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run (without Error handling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bCaj8N-DKj4c",
        "outputId": "37786203-c747-488c-a7a6-2809b227e426"
      },
      "outputs": [],
      "source": [
        "coord_list = [4, 7, 8, 9, 10, 11, 12, 13, 14]\n",
        "coord_name = ['C', 'N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW']\n",
        "ncities = data.shape[0]\n",
        "# Process each city\n",
        "for j in range(ncities):\n",
        "  cityData = data.iloc[j]\n",
        "  city = cityData[1]\n",
        "  state = cityData[0]\n",
        "  # print(cityData)\n",
        "  print(city, state)\n",
        "  for i in range(9):\n",
        "      coord = cityData.iloc[coord_list[i]].split(',')\n",
        "      filename = f'{state}_{city}_{coord_name[i]}'\n",
        "      print(filename, end=';')\n",
        "\n",
        "      lon = float(coord[0])\n",
        "      lat = float(coord[1])\n",
        "      print(lon, lat)\n",
        "      # process_point(lon, lat, city, state, '2019', filename)\n",
        "      # process_point(lon, lat, city, state, '2024', filename)\n",
        "      process_point_svm(lon, lat, city, state, '2019', filename)\n",
        "      process_point_svm(lon, lat, city, state, '2024', filename)\n",
        "  print()\n",
        "\n",
        "print(\"All tasks have been started.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
