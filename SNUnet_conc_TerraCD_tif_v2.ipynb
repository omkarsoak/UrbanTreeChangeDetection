{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FHV3km-tCqoU",
        "outputId": "11fc4ebc-c906-48ba-d915-5411c3173eb2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip '/content/drive/MyDrive/BTechProject/ChangeDetectionMergedDividedSplit-tif3.zip' -d '/content/ChangeDetectionMergedDividedSplit-tif'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMowMJXZChmE"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgNN7EKOVJiY",
        "outputId": "c2d6b7fd-3bd3-44a3-95f3-2088556eb7a3"
      },
      "outputs": [],
      "source": [
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRKZrxCtChmG",
        "outputId": "30a3cbc0-fd5a-444e-d109-fe87d4fbbc9d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import rasterio\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "class ChangeDetectionDatasetTIF(Dataset):\n",
        "    def __init__(self, t2019_dir, t2024_dir, mask_dir,classes, transform=None):\n",
        "        self.t2019_dir = t2019_dir\n",
        "        self.t2024_dir = t2024_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.classes = classes  # Change detection classes\n",
        "        self.transform = transform\n",
        "\n",
        "        # Load all paths\n",
        "        self.t2019_paths = sorted([f for f in os.listdir(t2019_dir) if f.endswith('.tif')])\n",
        "        self.t2024_paths = sorted([f for f in os.listdir(t2024_dir) if f.endswith('.tif')])\n",
        "        self.mask_paths = sorted([f for f in os.listdir(mask_dir) if f.endswith('.tif')])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.t2019_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Load images using rasterio\n",
        "        with rasterio.open(os.path.join(self.t2019_dir, self.t2019_paths[index])) as src:\n",
        "            img_t2019 = src.read(out_dtype=np.float32) / 255.0\n",
        "        with rasterio.open(os.path.join(self.t2024_dir, self.t2024_paths[index])) as src:\n",
        "            img_t2024 = src.read(out_dtype=np.float32) / 255.0\n",
        "        # Load masks\n",
        "        with rasterio.open(os.path.join(self.mask_dir, self.mask_paths[index])) as src:\n",
        "            cd_mask = src.read(1).astype(np.int64)\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        img_t2019 = torch.from_numpy(img_t2019)\n",
        "        img_t2024 = torch.from_numpy(img_t2024)\n",
        "        cd_mask = torch.from_numpy(cd_mask)\n",
        "\n",
        "        # Apply transforms if any\n",
        "        if self.transform is not None:\n",
        "            img_t2019 = self.transform(img_t2019)\n",
        "            img_t2024 = self.transform(img_t2024)\n",
        "\n",
        "        return img_t2019, img_t2024, cd_mask\n",
        "\n",
        "def describe_loader(loader_type):\n",
        "    img2019, img2024, cd_mask = next(iter(loader_type))\n",
        "    print(\"Batch size:\", loader_type.batch_size)\n",
        "    print(\"2019 Image Shape:\", img2019.shape)\n",
        "    print(\"2024 Image Shape:\", img2024.shape)\n",
        "    print(\"Change Mask Shape:\", cd_mask.shape)\n",
        "    print(\"Number of images:\", len(loader_type.dataset))\n",
        "    print(\"Classes:\", loader_type.dataset.classes)\n",
        "    print(\"Unique CD values:\", torch.unique(cd_mask))\n",
        "\n",
        "# Example usage:\n",
        "ROOT_DIRECTORY = \"ChangeDetectionMergedDividedSplit-tif\"\n",
        "SAVING_DIR = \"/content/drive/MyDrive/BTechProject\"\n",
        "CD_DIR = \"cd2_Output\"\n",
        "#CLASSES = ['no_change','vegetation_increase','vegetation_decrease']\n",
        "CLASSES = ['no_change', 'water_building', 'water_sparse', 'water_dense',\n",
        "           'building_water', 'building_sparse', 'building_dense',\n",
        "           'sparse_water', 'sparse_building', 'sparse_dense',\n",
        "           'dense_water', 'dense_building', 'dense_sparse']\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = ChangeDetectionDatasetTIF(\n",
        "    t2019_dir=f\"{ROOT_DIRECTORY}/train/Images/T2019\",\n",
        "    t2024_dir=f\"{ROOT_DIRECTORY}/train/Images/T2024\",\n",
        "    mask_dir=f\"{ROOT_DIRECTORY}/train/{CD_DIR}\",\n",
        "    classes=CLASSES\n",
        ")\n",
        "\n",
        "val_dataset = ChangeDetectionDatasetTIF(\n",
        "    t2019_dir=f\"{ROOT_DIRECTORY}/val/Images/T2019\",\n",
        "    t2024_dir=f\"{ROOT_DIRECTORY}/val/Images/T2024\",\n",
        "    mask_dir=f\"{ROOT_DIRECTORY}/val/{CD_DIR}\",\n",
        "    classes=CLASSES\n",
        ")\n",
        "\n",
        "test_dataset = ChangeDetectionDatasetTIF(\n",
        "    t2019_dir=f\"{ROOT_DIRECTORY}/test/Images/T2019\",\n",
        "    t2024_dir=f\"{ROOT_DIRECTORY}/test/Images/T2024\",\n",
        "    mask_dir=f\"{ROOT_DIRECTORY}/test/{CD_DIR}\",\n",
        "    classes=CLASSES\n",
        ")\n",
        "\n",
        "# Create dataloaders\n",
        "num_workers = 8\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=num_workers, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,num_workers=num_workers, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "print(\"------------Train-----------\")\n",
        "describe_loader(train_loader)\n",
        "print(\"------------Val------------\")\n",
        "describe_loader(val_loader)\n",
        "print(\"------------Test------------\")\n",
        "describe_loader(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpBgPG9nChmH"
      },
      "source": [
        "## Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "id": "EkAWjfmNChmH",
        "outputId": "17007af8-008a-4a98-a517-b2249861f5be"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Set up the plot size and remove axes\n",
        "fig, axs = plt.subplots(5, 3, figsize=(10,10))\n",
        "\n",
        "for i in range(5):\n",
        "    j = random.randint(0, len(train_dataset) - 1)\n",
        "    image1, image2, mask = train_dataset[j]\n",
        "\n",
        "    # Display images\n",
        "    axs[i, 0].imshow(image1.permute(1, 2, 0))\n",
        "    axs[i, 0].set_title(f\"Real 2019\")\n",
        "    axs[i, 0].axis(\"off\")\n",
        "\n",
        "    axs[i, 1].imshow(image2.permute(1, 2, 0))\n",
        "    axs[i, 1].set_title(f\"Real 2024\")\n",
        "    axs[i, 1].axis(\"off\")\n",
        "\n",
        "    axs[i, 2].imshow(mask, cmap=\"turbo\")\n",
        "    print(np.unique(mask))\n",
        "    axs[i, 2].set_title(f\"CD Mask\")\n",
        "    axs[i, 2].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKI0wDXtChmI"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g7C2m2w0E3Rb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.modules.padding import ReplicationPad2d\n",
        "import torch.optim as optim\n",
        "\n",
        "class conv_block_nested(nn.Module):\n",
        "    def __init__(self, in_ch, mid_ch, out_ch):\n",
        "        super(conv_block_nested, self).__init__()\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_ch, mid_ch, kernel_size=3, padding=1, bias=True)\n",
        "        self.bn1 = nn.BatchNorm2d(mid_ch)\n",
        "        self.conv2 = nn.Conv2d(mid_ch, out_ch, kernel_size=3, padding=1, bias=True)\n",
        "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        identity = x\n",
        "        x = self.bn1(x)\n",
        "        x = self.activation(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        output = self.activation(x + identity)\n",
        "        return output\n",
        "\n",
        "class up(nn.Module):\n",
        "    def __init__(self, in_ch, bilinear=True):\n",
        "        super(up, self).__init__()\n",
        "        self.up = nn.Upsample(scale_factor=2,\n",
        "                            mode='bilinear',\n",
        "                            align_corners=True) if bilinear else \\\n",
        "                 nn.ConvTranspose2d(in_ch, in_ch, 2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.up(x)\n",
        "        return x\n",
        "\n",
        "class Siam_NestedUNet_Conc(nn.Module):\n",
        "    def __init__(self, in_ch=3, out_ch=3):\n",
        "        super(Siam_NestedUNet_Conc, self).__init__()\n",
        "        torch.nn.Module.dump_patches = True\n",
        "        n1 = 32     # Initial number of channels\n",
        "        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Encoder path for both images\n",
        "        self.conv0_0 = conv_block_nested(in_ch, filters[0], filters[0])\n",
        "        self.conv1_0 = conv_block_nested(filters[0], filters[1], filters[1])\n",
        "        self.Up1_0 = up(filters[1])\n",
        "        self.conv2_0 = conv_block_nested(filters[1], filters[2], filters[2])\n",
        "        self.Up2_0 = up(filters[2])\n",
        "        self.conv3_0 = conv_block_nested(filters[2], filters[3], filters[3])\n",
        "        self.Up3_0 = up(filters[3])\n",
        "        self.conv4_0 = conv_block_nested(filters[3], filters[4], filters[4])\n",
        "        self.Up4_0 = up(filters[4])\n",
        "\n",
        "        # Nested dense connections with batch norm\n",
        "        self.conv0_1 = conv_block_nested(filters[0] * 2 + filters[1], filters[0], filters[0])\n",
        "        self.conv1_1 = conv_block_nested(filters[1] * 2 + filters[2], filters[1], filters[1])\n",
        "        self.Up1_1 = up(filters[1])\n",
        "        self.conv2_1 = conv_block_nested(filters[2] * 2 + filters[3], filters[2], filters[2])\n",
        "        self.Up2_1 = up(filters[2])\n",
        "        self.conv3_1 = conv_block_nested(filters[3] * 2 + filters[4], filters[3], filters[3])\n",
        "        self.Up3_1 = up(filters[3])\n",
        "\n",
        "        self.conv0_2 = conv_block_nested(filters[0] * 3 + filters[1], filters[0], filters[0])\n",
        "        self.conv1_2 = conv_block_nested(filters[1] * 3 + filters[2], filters[1], filters[1])\n",
        "        self.Up1_2 = up(filters[1])\n",
        "        self.conv2_2 = conv_block_nested(filters[2] * 3 + filters[3], filters[2], filters[2])\n",
        "        self.Up2_2 = up(filters[2])\n",
        "\n",
        "        self.conv0_3 = conv_block_nested(filters[0] * 4 + filters[1], filters[0], filters[0])\n",
        "        self.conv1_3 = conv_block_nested(filters[1] * 4 + filters[2], filters[1], filters[1])\n",
        "        self.Up1_3 = up(filters[1])\n",
        "\n",
        "        self.conv0_4 = conv_block_nested(filters[0] * 5 + filters[1], filters[0], filters[0])\n",
        "\n",
        "        # Add batch normalization to deep supervision outputs\n",
        "        self.final1 = nn.Sequential(\n",
        "            nn.Conv2d(filters[0], filters[0] // 2, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(filters[0] // 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(filters[0] // 2, out_ch, kernel_size=1)\n",
        "        )\n",
        "\n",
        "        self.final2 = nn.Sequential(\n",
        "            nn.Conv2d(filters[0], filters[0] // 2, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(filters[0] // 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(filters[0] // 2, out_ch, kernel_size=1)\n",
        "        )\n",
        "\n",
        "        self.final3 = nn.Sequential(\n",
        "            nn.Conv2d(filters[0], filters[0] // 2, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(filters[0] // 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(filters[0] // 2, out_ch, kernel_size=1)\n",
        "        )\n",
        "\n",
        "        self.final4 = nn.Sequential(\n",
        "            nn.Conv2d(filters[0], filters[0] // 2, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(filters[0] // 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(filters[0] // 2, out_ch, kernel_size=1)\n",
        "        )\n",
        "\n",
        "        # Final combination layer with better feature extraction\n",
        "        self.conv_final = nn.Sequential(\n",
        "            nn.Conv2d(out_ch * 4, filters[0], kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(filters[0]),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(filters[0], filters[0] // 2, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(filters[0] // 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(filters[0] // 2, out_ch, kernel_size=1)\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                # Use Xavier/Glorot initialization for final layers\n",
        "                if m.kernel_size[0] == 1:\n",
        "                    nn.init.xavier_uniform_(m.weight)\n",
        "                else:\n",
        "                    nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, xA, xB):\n",
        "        # Encoder Path A\n",
        "        x0_0A = self.conv0_0(xA)\n",
        "        x1_0A = self.conv1_0(self.pool(x0_0A))\n",
        "        x2_0A = self.conv2_0(self.pool(x1_0A))\n",
        "        x3_0A = self.conv3_0(self.pool(x2_0A))\n",
        "\n",
        "        # Encoder Path B\n",
        "        x0_0B = self.conv0_0(xB)\n",
        "        x1_0B = self.conv1_0(self.pool(x0_0B))\n",
        "        x2_0B = self.conv2_0(self.pool(x1_0B))\n",
        "        x3_0B = self.conv3_0(self.pool(x2_0B))\n",
        "        x4_0B = self.conv4_0(self.pool(x3_0B))\n",
        "\n",
        "        # Nested Dense Connections and Decoder Path\n",
        "        x0_1 = self.conv0_1(torch.cat([x0_0A, x0_0B, self.Up1_0(x1_0B)], 1))\n",
        "        x1_1 = self.conv1_1(torch.cat([x1_0A, x1_0B, self.Up2_0(x2_0B)], 1))\n",
        "        x0_2 = self.conv0_2(torch.cat([x0_0A, x0_0B, x0_1, self.Up1_1(x1_1)], 1))\n",
        "\n",
        "        x2_1 = self.conv2_1(torch.cat([x2_0A, x2_0B, self.Up3_0(x3_0B)], 1))\n",
        "        x1_2 = self.conv1_2(torch.cat([x1_0A, x1_0B, x1_1, self.Up2_1(x2_1)], 1))\n",
        "        x0_3 = self.conv0_3(torch.cat([x0_0A, x0_0B, x0_1, x0_2, self.Up1_2(x1_2)], 1))\n",
        "\n",
        "        x3_1 = self.conv3_1(torch.cat([x3_0A, x3_0B, self.Up4_0(x4_0B)], 1))\n",
        "        x2_2 = self.conv2_2(torch.cat([x2_0A, x2_0B, x2_1, self.Up3_1(x3_1)], 1))\n",
        "        x1_3 = self.conv1_3(torch.cat([x1_0A, x1_0B, x1_1, x1_2, self.Up2_2(x2_2)], 1))\n",
        "        x0_4 = self.conv0_4(torch.cat([x0_0A, x0_0B, x0_1, x0_2, x0_3, self.Up1_3(x1_3)], 1))\n",
        "\n",
        "        # Get outputs at different scales\n",
        "        output1 = self.final1(x0_1)\n",
        "        output2 = self.final2(x0_2)\n",
        "        output3 = self.final3(x0_3)\n",
        "        output4 = self.final4(x0_4)\n",
        "\n",
        "        # Combine outputs\n",
        "        output = self.conv_final(torch.cat([output1, output2, output3, output4], 1))\n",
        "\n",
        "        # Return logits without softmax for CrossEntropyLoss\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0-zY8rUE3Rc"
      },
      "source": [
        "## Util Functions and Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "u4Mk8d2vUXwH"
      },
      "outputs": [],
      "source": [
        "def calculate_effective_weights(train_loader, device, num_classes=3, method='square_balanced'):\n",
        "    \"\"\"Calculate class weights with different strategies to handle class imbalance\n",
        "\n",
        "    Args:\n",
        "        train_loader: DataLoader containing training data\n",
        "        device: torch device\n",
        "        num_classes: number of classes (default: 3)\n",
        "        method: weighting strategy ('balanced', 'square_balanced', or 'custom')\n",
        "    \"\"\"\n",
        "    class_counts = torch.zeros(num_classes)\n",
        "    total_pixels = 0\n",
        "\n",
        "    # Count class frequencies\n",
        "    for _, _, labels in train_loader:\n",
        "        labels = labels.to(device)\n",
        "        for i in range(num_classes):\n",
        "            class_counts[i] += (labels == i).sum().item()\n",
        "        total_pixels += labels.numel()\n",
        "\n",
        "    class_frequencies = class_counts / total_pixels\n",
        "\n",
        "    if method == 'balanced':\n",
        "        # Standard balanced weighting (inverse frequency)\n",
        "        weights = 1.0 / class_frequencies\n",
        "\n",
        "    elif method == 'square_balanced':\n",
        "        # Square root of inverse frequencies (less aggressive balancing)\n",
        "        weights = torch.sqrt(1.0 / class_frequencies)\n",
        "\n",
        "    elif method == 'custom':\n",
        "        # Custom weighting that maintains some natural class distribution\n",
        "        # Adjust these factors based on your domain knowledge\n",
        "        base_weights = 1.0 / class_frequencies\n",
        "        adjustment_factors = torch.tensor([0.7, 1.2, 1.2])  # Reduce weight of class 0, increase others\n",
        "        weights = base_weights * adjustment_factors\n",
        "\n",
        "    # Normalize weights to sum to num_classes\n",
        "    weights = weights * (num_classes / weights.sum())\n",
        "\n",
        "    return weights, class_frequencies\n",
        "\n",
        "# Define Focal Loss\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, weight=None, gamma=2.0):\n",
        "        super().__init__()\n",
        "        self.weight = weight\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        ce_loss = F.cross_entropy(input, target, reduction='none', weight=self.weight)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
        "        return focal_loss\n",
        "\n",
        "class MulticlassBCLLoss(nn.Module):\n",
        "    \"\"\"Multiclass Batch-balanced Contrastive Loss for 3-class change detection\"\"\"\n",
        "\n",
        "    def __init__(self, margin=2.0, ignore_index=255):\n",
        "        super().__init__()\n",
        "        self.margin = margin\n",
        "        self.ignore_index = ignore_index\n",
        "        self.eps = 1e-4\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            pred: Model predictions (B, C, H, W) where C is number of classes\n",
        "            target: Ground truth labels (B, H, W) with values [0, 1, 2]\n",
        "                   0: no change\n",
        "                   1: first type of change\n",
        "                   2: second type of change\n",
        "        \"\"\"\n",
        "        # Apply softmax to get probabilities\n",
        "        pred = torch.softmax(pred, dim=1)\n",
        "\n",
        "        # Convert predictions and target to correct shape\n",
        "        pred = pred.permute(0, 2, 3, 1).reshape(-1, pred.size(1))  # (N, C)\n",
        "        target = target.reshape(-1)  # (N,)\n",
        "\n",
        "        # Create mask for valid pixels\n",
        "        mask = (target != self.ignore_index).float()\n",
        "\n",
        "        # Initialize loss\n",
        "        total_loss = 0.0\n",
        "\n",
        "        # Handle each class\n",
        "        for class_idx in range(3):\n",
        "            # Create binary target for current class\n",
        "            class_target = (target == class_idx).float() * mask\n",
        "\n",
        "            # Get prediction probability for current class\n",
        "            class_pred = pred[:, class_idx]\n",
        "\n",
        "            # Count pixels\n",
        "            n_class = class_target.sum() + self.eps\n",
        "            n_others = (mask.sum() - n_class) + self.eps\n",
        "\n",
        "            # Calculate loss for current class\n",
        "            # For pixels of current class: penalize predictions below margin\n",
        "            class_loss = torch.sum(\n",
        "                class_target * torch.pow(torch.clamp(self.margin - class_pred, min=0.), 2)\n",
        "            ) / n_class\n",
        "\n",
        "            # For pixels of other classes: penalize high predictions\n",
        "            other_loss = torch.sum(\n",
        "                (1 - class_target) * torch.pow(class_pred, 2) * mask\n",
        "            ) / n_others\n",
        "\n",
        "            total_loss += (class_loss + other_loss) / 3\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "    def _calculate_margin_loss(self, pred, target, mask, class_idx):\n",
        "        \"\"\"Helper function to calculate margin-based loss for one class\"\"\"\n",
        "        # Binary target for current class\n",
        "        class_target = (target == class_idx).float() * mask\n",
        "\n",
        "        # Get prediction probability\n",
        "        class_pred = pred[:, class_idx]\n",
        "\n",
        "        # Count pixels\n",
        "        n_class = class_target.sum() + self.eps\n",
        "        n_others = (mask.sum() - n_class) + self.eps\n",
        "\n",
        "        # Calculate losses\n",
        "        positive_loss = torch.sum(\n",
        "            class_target * torch.pow(torch.clamp(self.margin - class_pred, min=0.), 2)\n",
        "        ) / n_class\n",
        "\n",
        "        negative_loss = torch.sum(\n",
        "            (1 - class_target) * torch.pow(class_pred, 2) * mask\n",
        "        ) / n_others\n",
        "\n",
        "        return positive_loss + negative_loss\n",
        "\n",
        "# def calculate_metrics(outputs, labels):\n",
        "#     \"\"\"\n",
        "#     Calculate comprehensive metrics for change detection using confusion matrix.\n",
        "#     Returns only overall metrics for simpler interpretation.\n",
        "\n",
        "#     Args:\n",
        "#         outputs (torch.Tensor): Model outputs (N, C, H, W)\n",
        "#         labels (torch.Tensor): Ground truth labels (N, H, W)\n",
        "\n",
        "#     Returns:\n",
        "#         dict: Dictionary of overall performance metrics\n",
        "#     \"\"\"\n",
        "#     # Get predicted classes\n",
        "#     preds = torch.argmax(outputs, dim=1)\n",
        "#     num_classes = outputs.size(1)\n",
        "\n",
        "#     # Create confusion matrix\n",
        "#     num_samples = labels.numel()\n",
        "#     confusion_matrix = torch.zeros((num_classes, num_classes), device=outputs.device)\n",
        "#     indices = num_classes * labels.long() + preds.long()\n",
        "#     confusion_matrix = confusion_matrix.view(-1).index_add_(\n",
        "#         0, indices.view(-1), torch.ones(num_samples, device=outputs.device)\n",
        "#     ).view(num_classes, num_classes)\n",
        "\n",
        "#     # Move to CPU for numpy operations\n",
        "#     cm = confusion_matrix.cpu().numpy()\n",
        "\n",
        "#     # True positives, false positives, false negatives for each class\n",
        "#     tp = np.diag(cm)\n",
        "#     fp = np.sum(cm, axis=0) - tp\n",
        "#     fn = np.sum(cm, axis=1) - tp\n",
        "\n",
        "#     # Overall accuracy\n",
        "#     accuracy = np.sum(tp) / np.sum(cm)\n",
        "\n",
        "#     # Per-class precision, recall, F1 to calculate weighted averages\n",
        "#     precision = tp / (tp + fp + 1e-6)\n",
        "#     recall = tp / (tp + fn + 1e-6)\n",
        "#     f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
        "\n",
        "#     # Weighted averages using class frequencies\n",
        "#     weights = np.sum(cm, axis=1)\n",
        "#     weighted_precision = np.average(precision, weights=weights)\n",
        "#     weighted_recall = np.average(recall, weights=weights)\n",
        "#     weighted_f1 = np.average(f1, weights=weights)\n",
        "\n",
        "#     # Calculate Kappa\n",
        "#     n = np.sum(cm)\n",
        "#     sum_po = np.sum(np.diag(cm))\n",
        "#     sum_pe = np.sum(np.sum(cm, axis=0) * np.sum(cm, axis=1)) / n\n",
        "#     kappa = (sum_po - sum_pe) / (n - sum_pe + 1e-6)\n",
        "\n",
        "#     # Mean IoU\n",
        "#     iou_per_class = tp / (tp + fp + fn + 1e-6)\n",
        "#     miou = np.mean(iou_per_class)\n",
        "\n",
        "#     metrics = {\n",
        "#         'accuracy': float(accuracy),\n",
        "#         'precision': float(weighted_precision),\n",
        "#         'recall': float(weighted_recall),\n",
        "#         'f1_score': float(weighted_f1),\n",
        "#         'miou': float(miou),\n",
        "#         'kappa': float(kappa)\n",
        "#     }\n",
        "\n",
        "#     return metrics\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "def calculate_metrics(outputs, labels, num_classes=3):\n",
        "    \"\"\"\n",
        "    Calculate comprehensive metrics for change detection using a single confusion matrix\n",
        "\n",
        "    Args:\n",
        "        outputs (torch.Tensor or np.array): Model outputs or predictions\n",
        "        labels (torch.Tensor or np.array): Ground truth class labels\n",
        "        num_classes (int): Number of classes in the dataset\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of performance metrics\n",
        "    \"\"\"\n",
        "    # Convert to numpy if inputs are torch tensors\n",
        "    if torch.is_tensor(outputs):\n",
        "        # For model outputs, get predictions first\n",
        "        predictions = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "    else:\n",
        "        predictions = outputs\n",
        "\n",
        "    if torch.is_tensor(labels):\n",
        "        labels = labels.cpu().numpy()\n",
        "\n",
        "    # Flatten predictions and targets\n",
        "    pred_flat = predictions.flatten()\n",
        "    target_flat = labels.flatten()\n",
        "\n",
        "    # Compute confusion matrix once\n",
        "    cm = confusion_matrix(target_flat, pred_flat, labels=list(range(num_classes)))\n",
        "    # Flatten predictions and targets\n",
        "\n",
        "    # pred_flat = predictions.flatten()\n",
        "    # target_flat = targets.flatten()\n",
        "\n",
        "    # # Compute confusion matrix once\n",
        "    # cm = confusion_matrix(target_flat, pred_flat)\n",
        "\n",
        "    # Calculate metrics from confusion matrix\n",
        "    metrics = {}\n",
        "\n",
        "    # True positives, false positives, false negatives for each class\n",
        "    tp = np.diag(cm)\n",
        "    fp = np.sum(cm, axis=0) - tp\n",
        "    fn = np.sum(cm, axis=1) - tp\n",
        "\n",
        "    # Overall accuracy from confusion matrix\n",
        "    metrics['accuracy'] = np.sum(tp) / np.sum(cm)\n",
        "\n",
        "    # Per-class precision, recall, F1\n",
        "    precision = tp / (tp + fp + 1e-6)\n",
        "    recall = tp / (tp + fn + 1e-6)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
        "\n",
        "    # Weighted averages\n",
        "    #total = np.sum(cm, axis=1)\n",
        "    metrics['precision'] = np.average(precision,) #weights=total)\n",
        "    metrics['recall'] = np.average(recall,)# weights=total)\n",
        "    metrics['f1_score'] = np.average(f1,) #weights=total)\n",
        "\n",
        "    # Calculate Kappa directly from confusion matrix\n",
        "    n = np.sum(cm)\n",
        "    sum_po = np.sum(np.diag(cm))\n",
        "    sum_pe = np.sum(np.sum(cm, axis=0) * np.sum(cm, axis=1)) / n\n",
        "    metrics['kappa'] = (sum_po - sum_pe) / (n - sum_pe + 1e-6)\n",
        "\n",
        "    # IoU from confusion matrix\n",
        "    iou_per_class = tp / (tp + fp + fn + 1e-6)\n",
        "    metrics['miou'] = np.mean(iou_per_class)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def train_model_balanced(model, train_loader, val_loader, num_epochs=50, num_classes=3, device='cuda',\n",
        "                         weighting_method='square_balanced', loss='CE',\n",
        "                         checkpoint_path='/content/drive/MyDrive/best_model_multiclass.pt'):\n",
        "    \"\"\"\n",
        "    Training function with simplified metrics tracking.\n",
        "    \"\"\"\n",
        "    start_epoch = 0\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    # Initialize history dictionary\n",
        "    def init_phase_metrics():\n",
        "        return {\n",
        "            'loss': [],\n",
        "            'accuracy': [],\n",
        "            'precision': [],\n",
        "            'recall': [],\n",
        "            'f1_score': [],\n",
        "            'miou': [],\n",
        "            'kappa': []\n",
        "        }\n",
        "\n",
        "    history = {\n",
        "        'train': init_phase_metrics(),\n",
        "        'val': init_phase_metrics()\n",
        "    }\n",
        "\n",
        "    # Load checkpoint if exists\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        print(f\"Loading checkpoint from {checkpoint_path}\")\n",
        "        try:\n",
        "            checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            start_epoch = checkpoint['epoch']\n",
        "            best_val_loss = checkpoint['best_val_loss']\n",
        "            print(f\"Resuming from epoch {start_epoch} with best val loss: {best_val_loss:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading checkpoint: {e}\")\n",
        "            print(\"Starting training from scratch\")\n",
        "\n",
        "    # Setup model, optimizer, criterion\n",
        "    class_weights, _ = calculate_effective_weights(train_loader, device, num_classes=num_classes, method=weighting_method)\n",
        "    print(class_weights)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "    model.to(device)\n",
        "\n",
        "    def process_epoch(phase, data_loader):\n",
        "        if phase == 'train':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "\n",
        "        running_metrics = {\n",
        "            'loss': 0.0,\n",
        "            'accuracy': 0.0,\n",
        "            'precision': 0.0,\n",
        "            'recall': 0.0,\n",
        "            'f1_score': 0.0,\n",
        "            'miou': 0.0,\n",
        "            'kappa': 0.0\n",
        "        }\n",
        "        samples_count = 0\n",
        "\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "            for inputs1, inputs2, labels in data_loader:\n",
        "                inputs1, inputs2, labels = inputs1.to(device), inputs2.to(device), labels.to(device)\n",
        "                batch_size = inputs1.size(0)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                outputs = model(inputs1, inputs2)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                    optimizer.step()\n",
        "\n",
        "                # Calculate metrics\n",
        "                metrics = calculate_metrics(outputs, labels, num_classes=num_classes)\n",
        "                metrics['loss'] = loss.item()\n",
        "\n",
        "                # Update running metrics\n",
        "                for key in running_metrics:\n",
        "                    running_metrics[key] += metrics[key] * batch_size\n",
        "                samples_count += batch_size\n",
        "\n",
        "        # Calculate epoch metrics\n",
        "        epoch_metrics = {key: value / samples_count for key, value in running_metrics.items()}\n",
        "\n",
        "        # Store metrics in history\n",
        "        for key in history[phase]:\n",
        "            history[phase][key].append(epoch_metrics[key])\n",
        "\n",
        "        return epoch_metrics\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        print(f'\\nEpoch {epoch + 1}/{num_epochs}:')\n",
        "\n",
        "        # Training phase\n",
        "        train_metrics = process_epoch('train', train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        val_metrics = process_epoch('val', val_loader)\n",
        "\n",
        "        # Print metrics\n",
        "        def print_metrics(phase, metrics):\n",
        "            print(f'\\n{phase.capitalize()} Metrics:')\n",
        "            print(f'  Loss: {metrics[\"loss\"]:.4f}')\n",
        "            print(f'  Accuracy: {metrics[\"accuracy\"]:.4f}')\n",
        "            print(f'  Precision: {metrics[\"precision\"]:.4f}')\n",
        "            print(f'  Recall: {metrics[\"recall\"]:.4f}')\n",
        "            print(f'  F1-score: {metrics[\"f1_score\"]:.4f}')\n",
        "            print(f'  mIoU: {metrics[\"miou\"]:.4f}')\n",
        "            print(f'  Kappa: {metrics[\"kappa\"]:.4f}')\n",
        "\n",
        "        print_metrics('train', train_metrics)\n",
        "        print_metrics('val', val_metrics)\n",
        "\n",
        "        # Update learning rate scheduler\n",
        "        scheduler.step(val_metrics['loss'])\n",
        "\n",
        "        # Save checkpoint if it's the best model\n",
        "        if val_metrics['loss'] < best_val_loss:\n",
        "            best_val_loss = val_metrics['loss']\n",
        "            checkpoint = {\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'best_val_loss': best_val_loss,\n",
        "                'metrics': val_metrics,\n",
        "                'history': history\n",
        "            }\n",
        "            torch.save(checkpoint, checkpoint_path)\n",
        "            print(f'\\nSaved new best model with validation loss: {val_metrics[\"loss\"]:.4f}')\n",
        "\n",
        "    return model, history\n",
        "\n",
        "import json\n",
        "\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def save_training_files(history, checkpoint_path, history_filename, bestepoch_filename):\n",
        "    \"\"\"Save training history and best epoch info to separate JSON files\"\"\"\n",
        "\n",
        "    def convert_to_serializable(value):\n",
        "        \"\"\"Recursively convert numpy/torch types to basic Python types\"\"\"\n",
        "        if isinstance(value, (np.ndarray, torch.Tensor)):\n",
        "            return value.tolist()\n",
        "        elif isinstance(value, dict):\n",
        "            return {k: convert_to_serializable(v) for k, v in value.items()}\n",
        "        elif isinstance(value, list):\n",
        "            return [convert_to_serializable(item) for item in value]\n",
        "        return value\n",
        "\n",
        "    history_data = {\n",
        "        phase: {\n",
        "            metric: convert_to_serializable(values)\n",
        "            for metric, values in metrics.items()\n",
        "        }\n",
        "        for phase, metrics in history.items()\n",
        "    }\n",
        "\n",
        "    with open(history_filename, 'w') as f:\n",
        "        json.dump(history_data, f, indent=4)\n",
        "\n",
        "    # Load checkpoint without weights_only flag\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    # print(\"\\nCheckpoint contents:\")\n",
        "    # for key in checkpoint.keys():\n",
        "    #     print(f\"- {key}\")\n",
        "\n",
        "    # Convert metrics to basic Python types\n",
        "    epoch_data = {\n",
        "        'best_epoch': checkpoint['epoch'],\n",
        "        'best_val_loss': checkpoint['best_val_loss'],\n",
        "        'val_metrics': convert_to_serializable(checkpoint['metrics'])\n",
        "    }\n",
        "\n",
        "    with open(bestepoch_filename, 'w') as f:\n",
        "        json.dump(epoch_data, f, indent=4)\n",
        "\n",
        "    print(f\"\\nSaved training history to: {history_filename}\")\n",
        "    print(f\"Saved best epoch info to: {bestepoch_filename}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2RI6l8bUXwH"
      },
      "source": [
        "## Model Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EayeD9l0u2V",
        "outputId": "dcabdf15-de5c-4889-ba24-2aba5ebed816"
      },
      "outputs": [],
      "source": [
        "# Initialize and train the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_name = 'snunet_conc'\n",
        "strategy = 'st2' #change detection strategy {1,2,3,4}\n",
        "num_classes = 13  #num classes in change mask\n",
        "num_epochs = 2\n",
        "weighting_method = 'square_balanced' #'custom'\n",
        "loss = 'CE' #'focal' #'bcl'\n",
        "checkpoint_path = f'{SAVING_DIR}/best_{strategy}_{model_name}-{num_classes}_classes_{num_epochs}.pt'\n",
        "\n",
        "model = Siam_NestedUNet_Conc(in_ch=3, out_ch=num_classes).to(device)\n",
        "model2, history = train_model_balanced(model, train_loader, val_loader,\n",
        "                                      num_epochs=num_epochs, num_classes=num_classes,\n",
        "                                      device=device,\n",
        "                                      weighting_method=weighting_method,loss=loss,\n",
        "                                      checkpoint_path=checkpoint_path)\n",
        "\n",
        "\n",
        "history_filename = f\"{SAVING_DIR}/{strategy}_{model_name}-{num_classes}_classes_{num_epochs}_history.json\"\n",
        "bestepoch_filename = f\"{SAVING_DIR}/{strategy}_{model_name}-{num_classes}_classes_{num_epochs}_best_epoch.json\"\n",
        "save_training_files(history=history,checkpoint_path=checkpoint_path,\n",
        "                    history_filename=history_filename,bestepoch_filename=bestepoch_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa0RAqCdChmI"
      },
      "source": [
        "## Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i6ngPdKERbCE",
        "outputId": "beaa54e4-8736-4aeb-ed62-3329a1c1e832"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "import random\n",
        "\n",
        "\n",
        "def test_model(model, test_loader, loss='CE', device='cuda',\n",
        "               num_classes=3, weighting_method='square_balanced'):\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"Loaded checkpoint from {checkpoint_path}\")\n",
        "    model.eval()\n",
        "\n",
        "    # Calculate class weights\n",
        "    class_weights, _ = calculate_effective_weights(test_loader, device,\n",
        "                                                   num_classes=num_classes,\n",
        "                                                   method=weighting_method)\n",
        "    print(f\"Class weights: {class_weights}\")\n",
        "\n",
        "    # Select loss function\n",
        "    if loss.lower() == 'focal':\n",
        "        focal_gamma = 2.0\n",
        "        criterion = FocalLoss(weight=class_weights.to(device), gamma=focal_gamma)\n",
        "    elif loss.lower() == 'bcl':\n",
        "        criterion = MulticlassBCLLoss(margin=2.0).to(device)\n",
        "        print(\"Using Batch-balanced Contrastive Loss\")\n",
        "    else:  # 'CE'\n",
        "        criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "\n",
        "    # For visualization and metrics\n",
        "    random_samples = []\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    # Collect predictions and labels for comprehensive metrics\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs1, inputs2, labels in test_loader:\n",
        "            inputs1, inputs2, labels = inputs1.to(device), inputs2.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs1, inputs2)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Accumulate loss\n",
        "            total_loss += loss.item() * inputs1.size(0)\n",
        "            total_samples += inputs1.size(0)\n",
        "\n",
        "            # Get predictions\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            # Store predictions and labels\n",
        "            all_predictions.append(preds.cpu().numpy())\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "\n",
        "            # Store random samples for visualization\n",
        "            if len(random_samples) < 5:\n",
        "                for i in range(min(inputs1.size(0), 5 - len(random_samples))):\n",
        "                    if random.random() < 0.2:  # 20% chance to select each sample\n",
        "                        random_samples.append({\n",
        "                            'image1': inputs1[i].cpu(),\n",
        "                            'image2': inputs2[i].cpu(),\n",
        "                            'label': labels[i].cpu(),\n",
        "                            'pred': preds[i].cpu(),\n",
        "                            'probabilities': torch.softmax(outputs[i], dim=0).cpu()\n",
        "                        })\n",
        "\n",
        "    # Concatenate predictions and labels\n",
        "    all_predictions = np.concatenate(all_predictions)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "\n",
        "    # Calculate metrics\n",
        "    test_metrics = calculate_metrics(all_predictions, all_labels, num_classes)\n",
        "\n",
        "    # Add loss to metrics\n",
        "    test_metrics['loss'] = total_loss / total_samples\n",
        "\n",
        "    # Make sure we have exactly 5 samples\n",
        "    while len(random_samples) < 5:\n",
        "        random_samples.append(random_samples[-1] if random_samples else {\n",
        "            'image1': torch.zeros(3, 64, 64),\n",
        "            'image2': torch.zeros(3, 64, 64),\n",
        "            'label': torch.zeros(64, 64),\n",
        "            'pred': torch.zeros(64, 64),\n",
        "            'probabilities': torch.zeros(3, 64, 64)\n",
        "        })\n",
        "\n",
        "    return random_samples, test_metrics\n",
        "\n",
        "def visualize_results(random_samples, num_classes=3):\n",
        "    # Extract samples and metrics\n",
        "    # random_samples = random_samples_and_metrics[0]\n",
        "    # test_metrics = random_samples_and_metrics[1]\n",
        "\n",
        "    # Create a figure with subplots\n",
        "    fig, axes = plt.subplots(5, 4, figsize=(25, 25))\n",
        "    plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
        "\n",
        "    for idx, sample in enumerate(random_samples):\n",
        "        # Normalize and convert images for display\n",
        "        img1 = sample['image1'].numpy().transpose(1, 2, 0)\n",
        "        img2 = sample['image2'].numpy().transpose(1, 2, 0)\n",
        "        img1 = (img1 - img1.min()) / (img1.max() - img1.min())\n",
        "        img2 = (img2 - img2.min()) / (img2.max() - img2.min())\n",
        "\n",
        "        # Get masks\n",
        "        pred_mask = sample['pred'].numpy()\n",
        "        true_mask = sample['label'].numpy()\n",
        "\n",
        "        # Plot images and masks\n",
        "        axes[idx, 0].imshow(img1)\n",
        "        axes[idx, 0].set_title('Image 1')\n",
        "        axes[idx, 0].axis('off')\n",
        "\n",
        "        axes[idx, 1].imshow(img2)\n",
        "        axes[idx, 1].set_title('Image 2')\n",
        "        axes[idx, 1].axis('off')\n",
        "\n",
        "        # Plot predicted mask\n",
        "        pred_plot = axes[idx, 2].imshow(pred_mask, cmap='tab10', vmin=0, vmax=num_classes-1)\n",
        "        axes[idx, 2].set_title('Predicted Change')\n",
        "        axes[idx, 2].axis('off')\n",
        "\n",
        "        # Plot ground truth mask\n",
        "        true_plot = axes[idx, 3].imshow(true_mask, cmap='tab10', vmin=0, vmax=num_classes-1)\n",
        "        axes[idx, 3].set_title('Ground Truth')\n",
        "        axes[idx, 3].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def save_test_metrics(test_metrics, save_dir, model_name, strategy, num_epochs):\n",
        "    \"\"\"Save test metrics to JSON\"\"\"\n",
        "    metrics_file = os.path.join(save_dir, f\"{strategy}_{model_name}-{num_classes}_classes_{num_epochs}_test_metrics.json\")\n",
        "\n",
        "    # Use the pre-computed metrics directly\n",
        "    with open(metrics_file, 'w') as f:\n",
        "        json.dump(test_metrics, f, indent=4)\n",
        "\n",
        "    print(f\"\\nSaved test metrics to: {metrics_file}\")\n",
        "\n",
        "# Test the model\n",
        "random_samples, test_metrics = test_model(model, test_loader, loss=loss, device=device, num_classes=num_classes)\n",
        "\n",
        "# Save test metrics\n",
        "save_test_metrics(test_metrics=test_metrics,\n",
        "                  save_dir=SAVING_DIR,\n",
        "                  model_name=model_name,\n",
        "                  strategy=strategy,\n",
        "                  num_epochs=num_epochs)\n",
        "\n",
        "# Visualize results\n",
        "visualize_results(random_samples,num_classes=num_classes)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 5939633,
          "sourceId": 9710583,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30787,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
