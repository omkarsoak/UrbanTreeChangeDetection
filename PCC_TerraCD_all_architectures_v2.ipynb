{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf0k2MH8WKrI",
        "outputId": "50221ad6-b3e3-473e-c84f-5f7b276ceb54"
      },
      "outputs": [],
      "source": [
        "!pip install segmentation_models_pytorch\n",
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvpiVwnyXVhZ",
        "outputId": "d8306ade-123c-4684-f988-ae42ead9d660"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip '/content/drive/MyDrive/BTechProject/ChangeDetectionMergedDividedSplit-tif3.zip' -d '/content/ChangeDetectionMergedDividedSplit-tif'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4IfevbpNPeU"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pd9Cl_XWSF4",
        "outputId": "dbcf67c3-ce3d-480a-a035-a83d2a36a317"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import rasterio\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "class ChangeDetectionDatasetTIF(Dataset):\n",
        "    def __init__(self, t2019_dir, t2024_dir, sem_2019_dir, sem_2024_dir, mask_dir,\n",
        "                 classes, semantic_classes, transform=None):\n",
        "        self.t2019_dir = t2019_dir\n",
        "        self.t2024_dir = t2024_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.sem_2019_dir = sem_2019_dir\n",
        "        self.sem_2024_dir = sem_2024_dir\n",
        "        self.classes = classes  # Change detection classes\n",
        "        self.semantic_classes = semantic_classes  # Land cover classes\n",
        "        self.transform = transform\n",
        "\n",
        "        # Load all paths\n",
        "        self.t2019_paths = sorted([f for f in os.listdir(t2019_dir) if f.endswith('.tif')])\n",
        "        self.t2024_paths = sorted([f for f in os.listdir(t2024_dir) if f.endswith('.tif')])\n",
        "        self.mask_paths = sorted([f for f in os.listdir(mask_dir) if f.endswith('.tif')])\n",
        "        self.sem2019_paths = sorted([f for f in os.listdir(sem_2019_dir) if f.endswith('.tif')])\n",
        "        self.sem2024_paths = sorted([f for f in os.listdir(sem_2024_dir) if f.endswith('.tif')])\n",
        "\n",
        "        # Verify all paths match\n",
        "        assert len(self.t2019_paths) == len(self.t2024_paths) == len(self.mask_paths) == \\\n",
        "               len(self.sem2019_paths) == len(self.sem2024_paths), \"Mismatched number of images\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.t2019_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Load images using rasterio\n",
        "        with rasterio.open(os.path.join(self.t2019_dir, self.t2019_paths[index])) as src:\n",
        "            img_t2019 = src.read(out_dtype=np.float32) / 255.0\n",
        "        with rasterio.open(os.path.join(self.t2024_dir, self.t2024_paths[index])) as src:\n",
        "            img_t2024 = src.read(out_dtype=np.float32) / 255.0\n",
        "\n",
        "        # Load masks\n",
        "        with rasterio.open(os.path.join(self.mask_dir, self.mask_paths[index])) as src:\n",
        "            cd_mask = src.read(1).astype(np.int64)\n",
        "        with rasterio.open(os.path.join(self.sem_2019_dir, self.sem2019_paths[index])) as src:\n",
        "            sem_mask_2019 = src.read(1).astype(np.int64)\n",
        "        with rasterio.open(os.path.join(self.sem_2024_dir, self.sem2024_paths[index])) as src:\n",
        "            sem_mask_2024 = src.read(1).astype(np.int64)\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        img_t2019 = torch.from_numpy(img_t2019)\n",
        "        img_t2024 = torch.from_numpy(img_t2024)\n",
        "        cd_mask = torch.from_numpy(cd_mask)\n",
        "        sem_mask_2019 = torch.from_numpy(sem_mask_2019)\n",
        "        sem_mask_2024 = torch.from_numpy(sem_mask_2024)\n",
        "\n",
        "        # Apply transforms if any\n",
        "        if self.transform is not None:\n",
        "            img_t2019 = self.transform(img_t2019)\n",
        "            img_t2024 = self.transform(img_t2024)\n",
        "\n",
        "        # Return dictionary format\n",
        "        return {\n",
        "            'img_t2019': img_t2019,\n",
        "            'img_t2024': img_t2024,\n",
        "            'cd_mask': cd_mask,\n",
        "            'sem_mask_2019': sem_mask_2019,\n",
        "            'sem_mask_2024': sem_mask_2024\n",
        "        }\n",
        "\n",
        "\n",
        "def describe_loader(loader_type):\n",
        "    \"\"\"Print information about a data loader\"\"\"\n",
        "    sample = next(iter(loader_type))\n",
        "    print(\"Batch size:\", loader_type.batch_size)\n",
        "    print(\"Shapes:\")\n",
        "    print(\"  Image 2019:\", sample['img_t2019'].shape)\n",
        "    print(\"  Image 2024:\", sample['img_t2024'].shape)\n",
        "    print(\"  Change Mask:\", sample['cd_mask'].shape)\n",
        "    print(\"  Semantic Mask 2019:\", sample['sem_mask_2019'].shape)\n",
        "    print(\"  Semantic Mask 2024:\", sample['sem_mask_2024'].shape)\n",
        "    print(\"Number of images:\", len(loader_type.dataset))\n",
        "    print(\"Change Classes:\", loader_type.dataset.classes)\n",
        "    print(\"Semantic Classes:\", loader_type.dataset.semantic_classes)\n",
        "\n",
        "    # Print value ranges\n",
        "    print(\"\\nValue ranges:\")\n",
        "    #print(\"  Images:\", torch.min(sample['img_t2019']).item(), \"to\", torch.max(sample['img_t2019']).item())\n",
        "    print(\"  Change Mask:\", torch.unique(sample['cd_mask']))\n",
        "    print(\"  Semantic Mask:\", torch.unique(sample['sem_mask_2019']))\n",
        "\n",
        "# Example usage:\n",
        "ROOT_DIRECTORY = \"ChangeDetectionMergedDividedSplit-tif\"\n",
        "SAVING_DIR = '/content/drive/MyDrive/BTechProject'\n",
        "CD_DIR = \"cd1_Output\"\n",
        "CLASSES = ['no_change', 'increase_vegetation', 'decrease_vegetation']\n",
        "# CLASSES = ['no_change', 'water_building', 'water_sparse', 'water_dense',\n",
        "#            'building_water', 'building_sparse', 'building_dense',\n",
        "#            'sparse_water', 'sparse_building', 'sparse_dense',\n",
        "#            'dense_water', 'dense_building', 'dense_sparse']\n",
        "\n",
        "SEMANTIC_CLASSES = ['water', 'building', 'sparse_vegetation', 'dense_vegetation']\n",
        "# Create datasets\n",
        "train_dataset = ChangeDetectionDatasetTIF(\n",
        "    t2019_dir=f\"{ROOT_DIRECTORY}/train/Images/T2019\",\n",
        "    t2024_dir=f\"{ROOT_DIRECTORY}/train/Images/T2024\",\n",
        "    sem_2019_dir=f\"{ROOT_DIRECTORY}/train/Masks/T2019\",\n",
        "    sem_2024_dir=f\"{ROOT_DIRECTORY}/train/Masks/T2024\",\n",
        "    mask_dir=f\"{ROOT_DIRECTORY}/train/{CD_DIR}\",\n",
        "    classes=CLASSES,\n",
        "    semantic_classes=SEMANTIC_CLASSES\n",
        ")\n",
        "\n",
        "val_dataset = ChangeDetectionDatasetTIF(\n",
        "    t2019_dir=f\"{ROOT_DIRECTORY}/val/Images/T2019\",\n",
        "    t2024_dir=f\"{ROOT_DIRECTORY}/val/Images/T2024\",\n",
        "    sem_2019_dir=f\"{ROOT_DIRECTORY}/val/Masks/T2019\",\n",
        "    sem_2024_dir=f\"{ROOT_DIRECTORY}/val/Masks/T2024\",\n",
        "    mask_dir=f\"{ROOT_DIRECTORY}/val/{CD_DIR}\",\n",
        "    classes=CLASSES,\n",
        "    semantic_classes=SEMANTIC_CLASSES\n",
        ")\n",
        "\n",
        "test_dataset = ChangeDetectionDatasetTIF(\n",
        "    t2019_dir=f\"{ROOT_DIRECTORY}/test/Images/T2019\",\n",
        "    t2024_dir=f\"{ROOT_DIRECTORY}/test/Images/T2024\",\n",
        "    sem_2019_dir=f\"{ROOT_DIRECTORY}/test/Masks/T2019\",\n",
        "    sem_2024_dir=f\"{ROOT_DIRECTORY}/test/Masks/T2024\",\n",
        "    mask_dir=f\"{ROOT_DIRECTORY}/test/{CD_DIR}\",\n",
        "    classes=CLASSES,\n",
        "    semantic_classes=SEMANTIC_CLASSES\n",
        ")\n",
        "\n",
        "# Create dataloaders\n",
        "num_workers = 4\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "print(\"------------Train------------\")\n",
        "describe_loader(train_loader)\n",
        "print(\"------------Val------------\")\n",
        "describe_loader(val_loader)\n",
        "print(\"------------Test------------\")\n",
        "describe_loader(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1jyjRVWNPeW"
      },
      "source": [
        "## Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "In3pg1VeWU31"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "def visualize_samples(loader, num_samples=3):\n",
        "    dataset = loader.dataset\n",
        "    fig, axes = plt.subplots(num_samples, 5, figsize=(15, 3 * num_samples))  # Reduced figure size\n",
        "\n",
        "    # Randomly select indices for samples\n",
        "    indices = random.sample(range(len(dataset)), num_samples)\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        sample = dataset[idx]\n",
        "\n",
        "        # Plot 2019 image\n",
        "        axes[i, 0].imshow(sample['img_t2019'].permute(1, 2, 0))\n",
        "        axes[i, 0].set_title('Image 2019', fontsize=8)\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        # Plot 2024 image\n",
        "        axes[i, 1].imshow(sample['img_t2024'].permute(1, 2, 0))\n",
        "        axes[i, 1].set_title('Image 2024', fontsize=8)\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "        # Plot change detection mask\n",
        "        im_cd = axes[i, 2].imshow(sample['cd_mask'], cmap='turbo')\n",
        "        axes[i, 2].set_title('Change Mask', fontsize=8)\n",
        "        axes[i, 2].axis('off')\n",
        "\n",
        "        # Plot semantic masks\n",
        "        im_sem_2019 = axes[i, 3].imshow(sample['sem_mask_2019'], cmap='viridis', vmin=0, vmax=3)\n",
        "        axes[i, 3].set_title('Semantic Mask 2019', fontsize=8)\n",
        "        axes[i, 3].axis('off')\n",
        "\n",
        "        im_sem_2024 = axes[i, 4].imshow(sample['sem_mask_2024'], cmap='viridis', vmin=0, vmax=3)\n",
        "        axes[i, 4].set_title('Semantic Mask 2024', fontsize=8)\n",
        "        axes[i, 4].axis('off')\n",
        "\n",
        "        # Print unique values\n",
        "        print(f\"\\nSample {i} - {dataset.t2019_paths[idx]}:\")\n",
        "        print(f\"Change mask values: {torch.unique(sample['cd_mask'])}\")\n",
        "        print(f\"Semantic mask 2019 values: {torch.unique(sample['sem_mask_2019'])}\")\n",
        "        print(f\"Semantic mask 2024 values: {torch.unique(sample['sem_mask_2024'])}\")\n",
        "\n",
        "    plt.tight_layout(pad=1.0, h_pad=1.0, w_pad=1.0)  # Adjust subplot spacing\n",
        "    plt.show()\n",
        "\n",
        "# Visualize training, validation, and test samples\n",
        "print(\"\\nVisualizing training samples...\")\n",
        "visualize_samples(train_loader)\n",
        "\n",
        "print(\"\\nVisualizing validation samples...\")\n",
        "visualize_samples(val_loader)\n",
        "\n",
        "print(\"\\nVisualizing test samples...\")\n",
        "visualize_samples(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRhGqyAbNPeW"
      },
      "source": [
        "## Model definition, Util functions and Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eWfdhybEWX-4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import segmentation_models_pytorch as smp\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "class ChangeDetectionModel(nn.Module):\n",
        "    def __init__(self, architecture='unet', encoder='resnet34', input_channels=3, num_semantic_classes=4, num_classes=3):\n",
        "        super().__init__()\n",
        "        # Semantic segmentation models for each timestamp\n",
        "        if architecture.lower() == 'unet':\n",
        "            self.sem_model = smp.Unet(\n",
        "                encoder_name=encoder,\n",
        "                encoder_weights=\"imagenet\",\n",
        "                in_channels=input_channels,\n",
        "                classes=num_semantic_classes,\n",
        "            )\n",
        "        elif architecture.lower() == 'linknet':\n",
        "            self.sem_model = smp.Linknet(\n",
        "                encoder_name=encoder,\n",
        "                encoder_weights=\"imagenet\",\n",
        "                in_channels=input_channels,\n",
        "                classes=num_semantic_classes,\n",
        "            )\n",
        "        elif architecture.lower() == 'pspnet':\n",
        "            self.sem_model = smp.PSPNet(\n",
        "                encoder_name=encoder,\n",
        "                encoder_weights=\"imagenet\",\n",
        "                in_channels=input_channels,\n",
        "                classes=num_semantic_classes,\n",
        "            )\n",
        "        elif architecture.lower() == 'deeplabv3plus':\n",
        "            self.sem_model = smp.DeepLabV3Plus(\n",
        "                encoder_name=encoder,\n",
        "                encoder_weights=\"imagenet\",\n",
        "                in_channels=input_channels,\n",
        "                classes=num_semantic_classes,\n",
        "            )\n",
        "\n",
        "        self.change_head = nn.Sequential(\n",
        "            nn.Conv2d(num_semantic_classes*2, 64, kernel_size=3, padding=1),  # Update input channels\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, num_classes, kernel_size=1),  # Update output channels\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        # Get semantic features for both timestamps\n",
        "        sem_feat1 = self.sem_model(x1)\n",
        "        sem_feat2 = self.sem_model(x2)\n",
        "\n",
        "        # Concatenate semantic features\n",
        "        combined_feat = torch.cat([sem_feat1, sem_feat2], dim=1)\n",
        "\n",
        "        # Get change detection output\n",
        "        change_out = self.change_head(combined_feat)\n",
        "\n",
        "        return sem_feat1, sem_feat2, change_out\n",
        "\n",
        "\n",
        "def calculate_metrics(predictions, targets, num_classes):\n",
        "    \"\"\"\n",
        "    Calculate comprehensive metrics for change detection using a single confusion matrix\n",
        "\n",
        "    Args:\n",
        "        predictions (np.array): Predicted class labels\n",
        "        targets (np.array): Ground truth class labels\n",
        "        num_classes (int): Number of classes in the dataset\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of performance metrics\n",
        "    \"\"\"\n",
        "    # Flatten predictions and targets\n",
        "    pred_flat = predictions.flatten()\n",
        "    target_flat = targets.flatten()\n",
        "\n",
        "    # Compute confusion matrix once\n",
        "    cm = confusion_matrix(target_flat, pred_flat)\n",
        "\n",
        "    # Calculate metrics from confusion matrix\n",
        "    metrics = {}\n",
        "\n",
        "    # True positives, false positives, false negatives for each class\n",
        "    tp = np.diag(cm)\n",
        "    fp = np.sum(cm, axis=0) - tp\n",
        "    fn = np.sum(cm, axis=1) - tp\n",
        "\n",
        "    # Overall accuracy from confusion matrix\n",
        "    metrics['accuracy'] = np.sum(tp) / np.sum(cm)\n",
        "\n",
        "    # Per-class precision, recall, F1\n",
        "    precision = tp / (tp + fp + 1e-6)\n",
        "    recall = tp / (tp + fn + 1e-6)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
        "\n",
        "    #### To get Weighted averages - uncomment `total` and `weights` arguments\n",
        "    #total = np.sum(cm, axis=1)\n",
        "    metrics['precision'] = np.average(precision,)# weights=total)\n",
        "    metrics['recall'] = np.average(recall,)# weights=total)\n",
        "    metrics['f1_score'] = np.average(f1,)# weights=total)\n",
        "\n",
        "    # Calculate Kappa directly from confusion matrix\n",
        "    n = np.sum(cm)\n",
        "    sum_po = np.sum(np.diag(cm))\n",
        "    sum_pe = np.sum(np.sum(cm, axis=0) * np.sum(cm, axis=1)) / n\n",
        "    metrics['kappa'] = (sum_po - sum_pe) / (n - sum_pe + 1e-6)\n",
        "\n",
        "    # IoU from confusion matrix\n",
        "    iou_per_class = tp / (tp + fp + fn + 1e-6)\n",
        "    metrics['miou'] = np.mean(iou_per_class)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def calculate_effective_weights(train_loader, num_classes=3, device='cuda'):\n",
        "    class_counts = torch.zeros(num_classes)\n",
        "    total_pixels = 0\n",
        "\n",
        "    # Count class frequencies\n",
        "    for batch in train_loader:\n",
        "        labels = batch['cd_mask'].to(device)\n",
        "        for i in range(num_classes):\n",
        "            class_counts[i] += (labels == i).sum().item()\n",
        "        total_pixels += labels.numel()\n",
        "\n",
        "    # Avoid division by zero\n",
        "    class_counts = torch.where(class_counts == 0, torch.ones_like(class_counts), class_counts)\n",
        "\n",
        "    class_frequencies = class_counts / total_pixels\n",
        "    weights = torch.sqrt(1.0 / class_frequencies)\n",
        "    weights = weights * (num_classes / weights.sum())\n",
        "\n",
        "    return weights\n",
        "\n",
        "\n",
        "def train_model_pcc(model, train_loader, val_loader, num_epochs, device,\n",
        "                   checkpoint_path, loss='CE', num_classes=3):\n",
        "    \"\"\"Train the PCC model with optimized metrics calculation\"\"\"\n",
        "        # Try to load checkpoint if it exists\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        print(f\"Loading checkpoint from {checkpoint_path}\")\n",
        "        try:\n",
        "            checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            start_epoch = checkpoint['epoch']\n",
        "            best_val_loss = checkpoint['val_loss']  # Load best validation loss\n",
        "            print(f\"Resuming from epoch {start_epoch} with best val loss: {best_val_loss:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading checkpoint: {e}\")\n",
        "            print(\"Starting training from scratch\")\n",
        "            start_epoch = 0\n",
        "            best_val_loss = float('inf')\n",
        "    else:\n",
        "        print(\"No checkpoint found. Starting training from scratch\")\n",
        "        start_epoch = 0\n",
        "        best_val_loss = float('inf')\n",
        "\n",
        "    # Initialize loss functions based on weighting method and loss type\n",
        "    sem_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    class_weights = calculate_effective_weights(train_loader,num_classes=num_classes,device='cuda')\n",
        "    print(class_weights)\n",
        "    change_criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    history = {'train_loss': [], 'val_loss': [], 'val_metrics': []}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
        "\n",
        "        for batch in progress_bar:\n",
        "            img_t2019 = batch['img_t2019'].to(device)\n",
        "            img_t2024 = batch['img_t2024'].to(device)\n",
        "            sem_mask_2019 = batch['sem_mask_2019'].to(device)\n",
        "            sem_mask_2024 = batch['sem_mask_2024'].to(device)\n",
        "            cd_mask = batch['cd_mask'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            sem_out1, sem_out2, change_out = model(img_t2019, img_t2024)\n",
        "\n",
        "            sem_loss = (sem_criterion(sem_out1, sem_mask_2019) +\n",
        "                       sem_criterion(sem_out2, sem_mask_2024)) / 2\n",
        "            change_loss = change_criterion(change_out, cd_mask)\n",
        "            loss = sem_loss + change_loss\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_metrics_list = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                img_t2019 = batch['img_t2019'].to(device)\n",
        "                img_t2024 = batch['img_t2024'].to(device)\n",
        "                sem_mask_2019 = batch['sem_mask_2019'].to(device)\n",
        "                sem_mask_2024 = batch['sem_mask_2024'].to(device)\n",
        "                cd_mask = batch['cd_mask'].to(device)\n",
        "\n",
        "                sem_out1, sem_out2, change_out = model(img_t2019, img_t2024)\n",
        "\n",
        "                sem_loss = (sem_criterion(sem_out1, sem_mask_2019) +\n",
        "                           sem_criterion(sem_out2, sem_mask_2024)) / 2\n",
        "                change_loss = change_criterion(change_out, cd_mask)\n",
        "                loss = sem_loss + change_loss\n",
        "\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                # Calculate metrics for this batch\n",
        "                preds = torch.argmax(change_out, dim=1).cpu().numpy()\n",
        "                targets = cd_mask.cpu().numpy()\n",
        "                batch_metrics = calculate_metrics(preds, targets, num_classes)\n",
        "                val_metrics_list.append(batch_metrics)\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "        val_metrics = {}\n",
        "        for key in val_metrics_list[0].keys():\n",
        "          val_metrics[key] = np.mean([m[key] for m in val_metrics_list])\n",
        "\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save({\n",
        "                'epoch': epoch+1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'val_loss': float(best_val_loss),\n",
        "                'train_loss': float(avg_train_loss),\n",
        "                'val_accuracy': float(val_metrics['accuracy']),\n",
        "                'val_kappa': float(val_metrics['kappa']),\n",
        "                'val_miou': float(val_metrics['miou']),\n",
        "                'val_f1_score': float(val_metrics['f1_score']),\n",
        "            }, checkpoint_path)\n",
        "            print(f\"Saved best model checkpoint to {checkpoint_path}\")\n",
        "\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "        history['val_loss'].append(avg_val_loss)\n",
        "        history['val_metrics'].append(val_metrics)\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
        "        print(f\"Val Loss: {avg_val_loss:.4f}\")\n",
        "        print(f\"Metrics - Accuracy: {val_metrics['accuracy']:.4f}, \"\n",
        "              f\"Kappa: {val_metrics['kappa']:.4f}, \"\n",
        "              f\"mIoU: {val_metrics['miou']:.4f}, \"\n",
        "              f\"F1 score: {val_metrics['f1_score']:.4f}, \")\n",
        "\n",
        "    return model, history\n",
        "\n",
        "\n",
        "def save_training_history(history, checkpoint_path, save_path, save_path_bestepoch):\n",
        "    # Convert tensors or arrays in the history to lists for JSON serialization\n",
        "    processed_history = {}\n",
        "    for phase, metrics in history.items():\n",
        "        if isinstance(metrics, list):  # Check if metrics is a list\n",
        "            processed_history[phase] = [\n",
        "                {metric: (value.tolist() if hasattr(value, 'tolist') else value)\n",
        "                 for metric, value in entry.items()} if isinstance(entry, dict) else entry\n",
        "                for entry in metrics\n",
        "            ]\n",
        "        else:  # Handle non-list entries\n",
        "            processed_history[phase] = metrics.tolist() if hasattr(metrics, 'tolist') else metrics\n",
        "\n",
        "    # Save processed history to a JSON file\n",
        "    with open(save_path, 'w') as f:\n",
        "        json.dump(processed_history, f, indent=4)\n",
        "\n",
        "    print(f\"Training history saved to: {save_path}\")\n",
        "\n",
        "    # Load checkpoint and inspect contents\n",
        "    checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
        "    # print(\"\\nCheckpoint contents:\")\n",
        "    # for key in checkpoint.keys():\n",
        "    #     print(f\"- {key}\")\n",
        "\n",
        "    epoch_data = {\n",
        "        'best_epoch': checkpoint['epoch'],\n",
        "        'train_loss': checkpoint['train_loss'],\n",
        "        'val_loss': checkpoint['val_loss'],\n",
        "        'val_accuracy': checkpoint['val_accuracy'],\n",
        "        'val_kappa': checkpoint['val_kappa'],\n",
        "        'val_miou': checkpoint['val_miou'],\n",
        "        'val_f1_score': checkpoint['val_f1_score']\n",
        "    }\n",
        "\n",
        "    # Save the best epoch info\n",
        "    with open(save_path_bestepoch, 'w') as f:\n",
        "        json.dump(epoch_data, f, indent=4)\n",
        "    print(f\"Best epoch info saved to: {save_path_bestepoch}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tdcbuw0zNPeX"
      },
      "source": [
        "## Model train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "te9aeCs6Wfye"
      },
      "outputs": [],
      "source": [
        "# Initialize model and device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "architecture = 'unet'  # 'unet' or 'linknet', 'pspnet', 'deeplabv3plus'\n",
        "num_classes = 3   # Change Detection classes (3 for cd1, 13 for cd2)\n",
        "num_semantic_classes = 4   # Semantic segmentation LCM classes (4 for both)\n",
        "num_epochs = 100\n",
        "loss = 'CE'\n",
        "checkpoint_path = f'{SAVING_DIR}/best_{architecture}-{num_classes}_classes_{num_epochs}_epochs.pt'\n",
        "\n",
        "# Create model\n",
        "model = ChangeDetectionModel(\n",
        "    architecture=architecture,encoder='resnet34',\n",
        "    input_channels=3,num_classes=num_classes,\n",
        "    num_semantic_classes=num_semantic_classes\n",
        ").to(device)\n",
        "\n",
        "# Train model\n",
        "model2, history = train_model_pcc(model=model,train_loader=train_loader,val_loader=val_loader,\n",
        "                                 num_epochs=num_epochs,device=device,checkpoint_path=checkpoint_path,\n",
        "                                 loss=loss,num_classes=num_classes)\n",
        "\n",
        "#Save model files\n",
        "save_history_path=f'{SAVING_DIR}/PCC_{architecture}-{num_classes}_classes_{num_epochs}_history.json'\n",
        "save_bestepoch_path=f'{SAVING_DIR}/PCC_{architecture}-{num_classes}_classes_{num_epochs}_best_epoch.json'\n",
        "save_training_history(history, checkpoint_path=checkpoint_path,\n",
        "                      save_path=save_history_path, save_path_bestepoch=save_bestepoch_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjKzi6PQNPeX"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gW1MIW1bWjbV",
        "outputId": "9620c376-1726-4377-ae35-f5cc19fbe3bb"
      },
      "outputs": [],
      "source": [
        "def plot_results_pcc(img1, img2, sem_pred1, sem_pred2, sem_gt1, sem_gt2,\n",
        "                    change_pred, change_gt):\n",
        "    \"\"\"Plot the results from the PCC model in notebook cells\"\"\"\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "\n",
        "    # Plot images\n",
        "    axes[0, 0].imshow(img1.cpu().permute(1, 2, 0))\n",
        "    axes[0, 0].set_title('Image 2019')\n",
        "    axes[0, 1].imshow(img2.cpu().permute(1, 2, 0))\n",
        "    axes[0, 1].set_title('Image 2024')\n",
        "\n",
        "    # Plot semantic predictions and ground truth\n",
        "    axes[0, 2].imshow(sem_pred1.cpu())\n",
        "    axes[0, 2].set_title('Semantic Pred 2019')\n",
        "    axes[0, 3].imshow(sem_pred2.cpu())\n",
        "    axes[0, 3].set_title('Semantic Pred 2024')\n",
        "\n",
        "    axes[1, 0].imshow(sem_gt1.cpu())\n",
        "    axes[1, 0].set_title('Semantic GT 2019')\n",
        "    axes[1, 1].imshow(sem_gt2.cpu())\n",
        "    axes[1, 1].set_title('Semantic GT 2024')\n",
        "\n",
        "    # Plot change detection results\n",
        "    axes[1, 2].imshow(change_pred.cpu())\n",
        "    axes[1, 2].set_title('Change Prediction')\n",
        "    axes[1, 3].imshow(change_gt.cpu())\n",
        "    axes[1, 3].set_title('Change GT')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def test_model_pcc(model, test_loader, checkpoint_path, device, num_samples_to_plot=5, num_classes=3):\n",
        "    \"\"\"Test the PCC model with enhanced metrics for both change detection and semantic segmentation\"\"\"\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"Loaded checkpoint from {checkpoint_path}\")\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize metric trackers\n",
        "    cd_metrics = []  # Change detection metrics\n",
        "    sem_2019_metrics = []  # Semantic segmentation 2019 metrics\n",
        "    sem_2024_metrics = []  # Semantic segmentation 2024 metrics\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc='Testing'):\n",
        "            img_t2019 = batch['img_t2019'].to(device)\n",
        "            img_t2024 = batch['img_t2024'].to(device)\n",
        "            sem_mask_2019 = batch['sem_mask_2019'].to(device)\n",
        "            sem_mask_2024 = batch['sem_mask_2024'].to(device)\n",
        "            cd_mask = batch['cd_mask'].to(device)\n",
        "\n",
        "            sem_out1, sem_out2, change_out = model(img_t2019, img_t2024)\n",
        "\n",
        "            # Get predictions\n",
        "            sem_pred1 = torch.argmax(sem_out1, dim=1)\n",
        "            sem_pred2 = torch.argmax(sem_out2, dim=1)\n",
        "            change_pred = torch.argmax(change_out, dim=1)\n",
        "\n",
        "            # Calculate metrics for all tasks\n",
        "            batch_cd_metrics = calculate_metrics(change_pred.cpu().numpy(),\n",
        "                                              cd_mask.cpu().numpy(),\n",
        "                                              num_classes)\n",
        "\n",
        "            batch_sem_2019_metrics = calculate_metrics(sem_pred1.cpu().numpy(),\n",
        "                                                     sem_mask_2019.cpu().numpy(),\n",
        "                                                     num_classes)\n",
        "\n",
        "            batch_sem_2024_metrics = calculate_metrics(sem_pred2.cpu().numpy(),\n",
        "                                                     sem_mask_2024.cpu().numpy(),\n",
        "                                                     num_classes)\n",
        "\n",
        "            cd_metrics.append(batch_cd_metrics)\n",
        "            sem_2019_metrics.append(batch_sem_2019_metrics)\n",
        "            sem_2024_metrics.append(batch_sem_2024_metrics)\n",
        "\n",
        "            # Store predictions for plotting\n",
        "            all_predictions.append({\n",
        "                'img_t2019': img_t2019.cpu(),\n",
        "                'img_t2024': img_t2024.cpu(),\n",
        "                'sem_pred1': sem_pred1.cpu(),\n",
        "                'sem_pred2': sem_pred2.cpu(),\n",
        "                'sem_mask_2019': sem_mask_2019.cpu(),\n",
        "                'sem_mask_2024': sem_mask_2024.cpu(),\n",
        "                'change_pred': change_pred.cpu(),\n",
        "                'cd_mask': cd_mask.cpu()\n",
        "            })\n",
        "\n",
        "    # Aggregate metrics\n",
        "    def aggregate_metrics(metrics_list):\n",
        "        final_metrics = {}\n",
        "        for key in metrics_list[0].keys():\n",
        "            final_metrics[key] = np.mean([m[key] for m in metrics_list])\n",
        "        return final_metrics\n",
        "\n",
        "    final_cd_metrics = aggregate_metrics(cd_metrics)\n",
        "    final_sem_2019_metrics = aggregate_metrics(sem_2019_metrics)\n",
        "    final_sem_2024_metrics = aggregate_metrics(sem_2024_metrics)\n",
        "\n",
        "    # Calculate average semantic segmentation metrics\n",
        "    avg_sem_metrics = {}\n",
        "    for key in final_sem_2019_metrics.keys():\n",
        "        avg_sem_metrics[key] = (final_sem_2019_metrics[key] + final_sem_2024_metrics[key]) / 2\n",
        "\n",
        "    # Print detailed metrics\n",
        "    print(\"\\n=== Change Detection Metrics ===\")\n",
        "    print(f\"Overall Accuracy: {final_cd_metrics['accuracy']:.4f}\")\n",
        "    print(f\"Kappa Score: {final_cd_metrics['kappa']:.4f}\")\n",
        "    print(f\"mIoU: {final_cd_metrics['miou']:.4f}\")\n",
        "    print(f\"F1 score: {final_cd_metrics['f1_score']:.4f}\")\n",
        "\n",
        "    print(\"\\n=== 2019 Semantic Segmentation Metrics ===\")\n",
        "    print(f\"Overall Accuracy: {final_sem_2019_metrics['accuracy']:.4f}\")\n",
        "    print(f\"Kappa Score: {final_sem_2019_metrics['kappa']:.4f}\")\n",
        "    print(f\"mIoU: {final_sem_2019_metrics['miou']:.4f}\")\n",
        "    print(f\"F1 score: {final_sem_2019_metrics['f1_score']:.4f}\")\n",
        "\n",
        "    print(\"\\n=== 2024 Semantic Segmentation Metrics ===\")\n",
        "    print(f\"Overall Accuracy: {final_sem_2024_metrics['accuracy']:.4f}\")\n",
        "    print(f\"Kappa Score: {final_sem_2024_metrics['kappa']:.4f}\")\n",
        "    print(f\"mIoU: {final_sem_2024_metrics['miou']:.4f}\")\n",
        "    print(f\"F1 score: {final_sem_2024_metrics['f1_score']:.4f}\")\n",
        "\n",
        "    print(\"\\n=== Average Semantic Segmentation Metrics ===\")\n",
        "    print(f\"Overall Accuracy: {avg_sem_metrics['accuracy']:.4f}\")\n",
        "    print(f\"Kappa Score: {avg_sem_metrics['kappa']:.4f}\")\n",
        "    print(f\"mIoU: {avg_sem_metrics['miou']:.4f}\")\n",
        "    print(f\"F1 score: {avg_sem_metrics['f1_score']:.4f}\")\n",
        "\n",
        "    # Plot random samples\n",
        "    total_samples = len(all_predictions)\n",
        "    random_indices = np.random.choice(total_samples, num_samples_to_plot, replace=False)\n",
        "\n",
        "    print(f\"\\nPlotting {num_samples_to_plot} random samples...\")\n",
        "    for idx in random_indices:\n",
        "        batch = all_predictions[idx]\n",
        "        plot_results_pcc(\n",
        "            batch['img_t2019'][0],\n",
        "            batch['img_t2024'][0],\n",
        "            batch['sem_pred1'][0],\n",
        "            batch['sem_pred2'][0],\n",
        "            batch['sem_mask_2019'][0],\n",
        "            batch['sem_mask_2024'][0],\n",
        "            batch['change_pred'][0],\n",
        "            batch['cd_mask'][0]\n",
        "        )\n",
        "\n",
        "    return {\n",
        "        'change_detection': final_cd_metrics,\n",
        "        'semantic_2019': final_sem_2019_metrics,\n",
        "        'semantic_2024': final_sem_2024_metrics,\n",
        "        'semantic_average': avg_sem_metrics\n",
        "    }\n",
        "\n",
        "\n",
        "def save_test_metrics(history, save_path):\n",
        "    # Convert tensors or arrays in the history to lists for JSON serialization\n",
        "    processed_history = {}\n",
        "    for phase, metrics in history.items():\n",
        "        if isinstance(metrics, list):  # Check if metrics is a list\n",
        "            processed_history[phase] = [\n",
        "                {metric: (value.tolist() if hasattr(value, 'tolist') else value)\n",
        "                 for metric, value in entry.items()} if isinstance(entry, dict) else entry\n",
        "                for entry in metrics\n",
        "            ]\n",
        "        else:  # Handle non-list entries\n",
        "            processed_history[phase] = metrics.tolist() if hasattr(metrics, 'tolist') else metrics\n",
        "\n",
        "    # Save processed history to a JSON file\n",
        "    with open(save_path, 'w') as f:\n",
        "        json.dump(processed_history, f, indent=4)\n",
        "\n",
        "    print(f\"Training history saved to: {save_path}\")\n",
        "\n",
        "test_metrics = test_model_pcc(model, test_loader, checkpoint_path=checkpoint_path,\n",
        "                              device=device, num_samples_to_plot=3,num_classes=num_classes)\n",
        "\n",
        "save_path = f'{SAVING_DIR}/PCC_{architecture}-{num_classes}_classes_{num_epochs}_test_metrics.json'\n",
        "save_test_metrics(test_metrics,save_path=save_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
