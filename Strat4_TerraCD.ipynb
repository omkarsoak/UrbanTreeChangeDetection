{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxvyTZt1PVqN",
        "outputId": "2eb042a9-8b02-44fd-abfe-06271b30c764"
      },
      "outputs": [],
      "source": [
        "# !pip install rasterio\n",
        "# !pip install segmentation_models_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H4mk5aSPdQ1",
        "outputId": "0c8d5854-157e-4eab-8104-ec16dd8fd0d2"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !unzip '/content/drive/MyDrive/BTechProject/ChangeDetectionMergedDividedSplit-tif3-reduced.zip' -d '/content/ChangeDetectionMergedDividedSplit-tif-reduced'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparamters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ROOT_DIRECTORY = \"ChangeDetectionMergedDividedSplit-tif\"\n",
        "SAVING_DIR = \"/content/drive/MyDrive/BTechProject\"\n",
        "CD_DIR = \"cd2_Output\"   #FOR STRATEGY4 ALWAYS USE cd2_Output\n",
        "\n",
        "if CD_DIR == \"cd1_Output\":\n",
        "    CLASSES = ['no_change','vegetation_increase','vegetation_decrease']\n",
        "elif CD_DIR == \"cd2_Output\":\n",
        "    # CLASSES = ['no_change', 'water_building', 'water_sparse', 'water_dense',\n",
        "    #            'building_water', 'building_sparse', 'building_dense',\n",
        "    #            'sparse_water', 'sparse_building', 'sparse_dense',\n",
        "    #            'dense_water', 'dense_building', 'dense_sparse']\n",
        "    CLASSES = [\n",
        "    'no_change','water_built', 'water_bare', 'water_sparse', 'water_trees',\n",
        "    'water_crops', 'built_water', 'built_bare', 'built_sparse', 'built_trees',\n",
        "    'built_crops',  'bare_water',  'bare_built',  'bare_sparse',  'bare_trees',\n",
        "    'bare_crops',  'sparse_water',  'sparse_built',  'sparse_bare',\n",
        "    'sparse_trees',  'sparse_crops',  'trees_water',  'trees_built',\n",
        "    'trees_bare',  'trees_sparse',  'trees_crops',  'crops_water',\n",
        "    'crops_built', 'crops_bare',  'crops_sparse',  'crops_trees']\n",
        "\n",
        "\n",
        "# SEMANTIC_CLASSES = ['water', 'building', 'sparse_vegetation', 'dense_vegetation']\n",
        "SEMANTIC_CLASSES = ['water', 'built', 'bare', 'sparse', 'trees', 'crops', 'others']\n",
        "\n",
        "NUM_WORKERS = 8\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 100\n",
        "MODEL_NAME = 'strat4'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFuZ-azTPhHc",
        "outputId": "4b7f58df-1a00-4e22-b306-78fd0dc54d59"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import rasterio\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "class ChangeDetectionDatasetTIF(Dataset):\n",
        "    def __init__(self, t2019_dir, t2024_dir, sem_2019_dir, sem_2024_dir, mask_dir,\n",
        "                 classes, semantic_classes, transform=None):\n",
        "        self.t2019_dir = t2019_dir\n",
        "        self.t2024_dir = t2024_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.sem_2019_dir = sem_2019_dir\n",
        "        self.sem_2024_dir = sem_2024_dir\n",
        "        self.classes = classes  # Change detection classes\n",
        "        self.semantic_classes = semantic_classes  # Land cover classes\n",
        "        self.transform = transform\n",
        "\n",
        "        # Load all paths\n",
        "        self.t2019_paths = sorted([f for f in os.listdir(t2019_dir) if f.endswith('.tif')])\n",
        "        self.t2024_paths = sorted([f for f in os.listdir(t2024_dir) if f.endswith('.tif')])\n",
        "        self.mask_paths = sorted([f for f in os.listdir(mask_dir) if f.endswith('.tif')])\n",
        "        self.sem2019_paths = sorted([f for f in os.listdir(sem_2019_dir) if f.endswith('.tif')])\n",
        "        self.sem2024_paths = sorted([f for f in os.listdir(sem_2024_dir) if f.endswith('.tif')])\n",
        "\n",
        "        # Verify all paths match\n",
        "        assert len(self.t2019_paths) == len(self.t2024_paths) == len(self.mask_paths) == \\\n",
        "               len(self.sem2019_paths) == len(self.sem2024_paths), \"Mismatched number of images\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.t2019_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Load images using rasterio\n",
        "        with rasterio.open(os.path.join(self.t2019_dir, self.t2019_paths[index])) as src:\n",
        "            img_t2019 = src.read(out_dtype=np.float32) / 255.0\n",
        "        with rasterio.open(os.path.join(self.t2024_dir, self.t2024_paths[index])) as src:\n",
        "            img_t2024 = src.read(out_dtype=np.float32) / 255.0\n",
        "\n",
        "        # Load masks\n",
        "        with rasterio.open(os.path.join(self.mask_dir, self.mask_paths[index])) as src:\n",
        "            cd_mask = src.read(1).astype(np.int64)\n",
        "        with rasterio.open(os.path.join(self.sem_2019_dir, self.sem2019_paths[index])) as src:\n",
        "            sem_mask_2019 = src.read(1).astype(np.int64)\n",
        "        with rasterio.open(os.path.join(self.sem_2024_dir, self.sem2024_paths[index])) as src:\n",
        "            sem_mask_2024 = src.read(1).astype(np.int64)\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        img_t2019 = torch.from_numpy(img_t2019)\n",
        "        img_t2024 = torch.from_numpy(img_t2024)\n",
        "        cd_mask = torch.from_numpy(cd_mask)\n",
        "        sem_mask_2019 = torch.from_numpy(sem_mask_2019)\n",
        "        sem_mask_2024 = torch.from_numpy(sem_mask_2024)\n",
        "\n",
        "        # Apply transforms if any\n",
        "        if self.transform is not None:\n",
        "            img_t2019 = self.transform(img_t2019)\n",
        "            img_t2024 = self.transform(img_t2024)\n",
        "\n",
        "        return img_t2019, img_t2024, sem_mask_2019, sem_mask_2024, cd_mask\n",
        "\n",
        "\n",
        "def describe_loader(loader_type):\n",
        "    \"\"\"Print information about a data loader\"\"\"\n",
        "    img2019, img2024, sem2019, sem2024, cd_mask = next(iter(loader_type))\n",
        "    print(\"Batch size:\", loader_type.batch_size)\n",
        "    print(\"Shapes:\")\n",
        "    print(\"  2019 Image:\", img2019.shape)\n",
        "    print(\"  2024 Image:\", img2024.shape)\n",
        "    print(\"  2019 Semantic Mask:\", sem2019.shape)\n",
        "    print(\"  2024 Semantic Mask:\", sem2024.shape)\n",
        "    print(\"  Change Mask:\", cd_mask.shape)\n",
        "    print(\"Number of images:\", len(loader_type.dataset))\n",
        "    print(\"Classes:\", loader_type.dataset.classes)\n",
        "    print(\"Semantic Classes:\", loader_type.dataset.semantic_classes)\n",
        "    print(\"\\nUnique values:\")\n",
        "    print(\"  Change Mask:\", torch.unique(cd_mask))\n",
        "    print(\"  Semantic Mask 2019:\", torch.unique(sem2019))\n",
        "\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = ChangeDetectionDatasetTIF(\n",
        "    t2019_dir=f\"{ROOT_DIRECTORY}/train/Images/T2019\",\n",
        "    t2024_dir=f\"{ROOT_DIRECTORY}/train/Images/T2024\",\n",
        "    sem_2019_dir=f\"{ROOT_DIRECTORY}/train/Masks/T2019\",\n",
        "    sem_2024_dir=f\"{ROOT_DIRECTORY}/train/Masks/T2024\",\n",
        "    mask_dir=f\"{ROOT_DIRECTORY}/train/{CD_DIR}\",\n",
        "    classes=CLASSES,\n",
        "    semantic_classes=SEMANTIC_CLASSES\n",
        ")\n",
        "\n",
        "val_dataset = ChangeDetectionDatasetTIF(\n",
        "    t2019_dir=f\"{ROOT_DIRECTORY}/val/Images/T2019\",\n",
        "    t2024_dir=f\"{ROOT_DIRECTORY}/val/Images/T2024\",\n",
        "    sem_2019_dir=f\"{ROOT_DIRECTORY}/val/Masks/T2019\",\n",
        "    sem_2024_dir=f\"{ROOT_DIRECTORY}/val/Masks/T2024\",\n",
        "    mask_dir=f\"{ROOT_DIRECTORY}/val/{CD_DIR}\",\n",
        "    classes=CLASSES,\n",
        "    semantic_classes=SEMANTIC_CLASSES\n",
        ")\n",
        "\n",
        "test_dataset = ChangeDetectionDatasetTIF(\n",
        "    t2019_dir=f\"{ROOT_DIRECTORY}/test/Images/T2019\",\n",
        "    t2024_dir=f\"{ROOT_DIRECTORY}/test/Images/T2024\",\n",
        "    sem_2019_dir=f\"{ROOT_DIRECTORY}/test/Masks/T2019\",\n",
        "    sem_2024_dir=f\"{ROOT_DIRECTORY}/test/Masks/T2024\",\n",
        "    mask_dir=f\"{ROOT_DIRECTORY}/test/{CD_DIR}\",\n",
        "    classes=CLASSES,\n",
        "    semantic_classes=SEMANTIC_CLASSES\n",
        ")\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "print(\"------------Train------------\")\n",
        "describe_loader(train_loader)\n",
        "print(\"------------Val------------\")\n",
        "describe_loader(val_loader)\n",
        "print(\"------------Test------------\")\n",
        "describe_loader(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s3a58s2iPkRh",
        "outputId": "a507008f-2b22-4069-9b07-08c28b6091fd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Set up the plot size and remove axes\n",
        "fig, axs = plt.subplots(5, 5, figsize=(10,10))\n",
        "\n",
        "for i in range(5):\n",
        "    j = random.randint(0, len(train_dataset) - 1)\n",
        "    #image1, image2, mask = train_dataset[j]\n",
        "    img_t2019, img_t2024, sem_mask_2019, sem_mask_2024, cd_mask = train_dataset[j]\n",
        "\n",
        "    # Display images\n",
        "    axs[i, 0].imshow(img_t2019.permute(1, 2, 0))\n",
        "    axs[i, 0].set_title(f\"Real 2019\")\n",
        "    axs[i, 0].axis(\"off\")\n",
        "\n",
        "    axs[i, 1].imshow(img_t2024.permute(1, 2, 0))\n",
        "    axs[i, 1].set_title(f\"Real 2024\")\n",
        "    axs[i, 1].axis(\"off\")\n",
        "\n",
        "    axs[i, 2].imshow(sem_mask_2019, cmap=\"turbo\")\n",
        "    print(np.unique(sem_mask_2019))\n",
        "    axs[i, 2].set_title(f\"Sem 2019 Mask\")\n",
        "    axs[i, 2].axis(\"off\")\n",
        "\n",
        "    axs[i, 3].imshow(sem_mask_2024, cmap=\"turbo\")\n",
        "    print(np.unique(sem_mask_2024))\n",
        "    axs[i, 3].set_title(f\"Sem 2024 Mask\")\n",
        "    axs[i, 3].axis(\"off\")\n",
        "\n",
        "    axs[i, 4].imshow(cd_mask, cmap=\"turbo\")\n",
        "    print(np.unique(cd_mask))\n",
        "    axs[i, 4].set_title(f\"CD Mask\")\n",
        "    axs[i, 4].axis(\"off\")\n",
        "\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9qr-erRmUp9"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHdqUDWdmQ8c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MultiTaskChangeDetectionModel(nn.Module):\n",
        "    def __init__(self, input_channels, num_semantic_classes, num_cd_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        # Shared Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            # Initial block\n",
        "            nn.Conv2d(input_channels, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            # Second block\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        # Land Cover Mapping Decoder (shared weights)\n",
        "        self.lcm_decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, num_semantic_classes, kernel_size=4, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        # Change Detection Decoder\n",
        "        self.cd_decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, num_cd_classes, kernel_size=4, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        # Ensure input images are the same size\n",
        "        assert x1.shape == x2.shape, \"Input images must have the same dimensions\"\n",
        "\n",
        "        # Encode both images\n",
        "        enc1 = self.encoder(x1)\n",
        "        enc2 = self.encoder(x2)\n",
        "\n",
        "        # Land Cover Mapping for both time periods\n",
        "        lcm1 = self.lcm_decoder(enc1)\n",
        "        lcm2 = self.lcm_decoder(enc2)\n",
        "\n",
        "        # Change Detection (using difference of encodings)\n",
        "        cd_input = torch.abs(enc1 - enc2)  # Or torch.cat([enc1, enc2], dim=1)\n",
        "        cd_output = self.cd_decoder(cd_input)\n",
        "\n",
        "        return lcm1, lcm2, cd_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC3reRPxjQUF"
      },
      "source": [
        "## Util Functions and Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cVTE-hCjP2B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def calculate_metrics(predictions, targets, num_classes):\n",
        "    \"\"\"\n",
        "    Calculate metrics with per-class IoU and unweighted averaging\n",
        "\n",
        "    Args:\n",
        "        predictions: numpy array of predictions\n",
        "        targets: numpy array of target labels\n",
        "        num_classes: number of classes\n",
        "    \"\"\"\n",
        "    # Flatten predictions and targets\n",
        "    pred_flat = predictions.flatten()\n",
        "    target_flat = targets.flatten()\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(target_flat, pred_flat, labels=range(num_classes))\n",
        "\n",
        "    # Calculate metrics for each class\n",
        "    metrics = {}\n",
        "    class_metrics = []\n",
        "\n",
        "    # Per-class calculations\n",
        "    for i in range(num_classes):\n",
        "        tp = cm[i, i]\n",
        "        fp = np.sum(cm[:, i]) - tp\n",
        "        fn = np.sum(cm[i, :]) - tp\n",
        "        tn = np.sum(cm) - tp - fp - fn\n",
        "\n",
        "        # Handle divide by zero\n",
        "        union = tp + fp + fn\n",
        "        if union == 0:\n",
        "            iou = 0\n",
        "        else:\n",
        "            iou = tp / union\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        class_metrics.append({\n",
        "            'class': i,\n",
        "            'iou': iou,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1\n",
        "        })\n",
        "\n",
        "    # Calculate averages - only for classes present in ground truth\n",
        "    # precision, recall and f1 are weighted\n",
        "    present_classes = np.unique(target_flat)\n",
        "    total = np.sum(cm, axis=1)\n",
        "    metrics['miou'] = np.mean([class_metrics[i]['iou'] for i in present_classes])\n",
        "    metrics['precision'] = np.average([m['precision'] for m in class_metrics], weights=total)\n",
        "    metrics['recall'] = np.average([m['recall'] for m in class_metrics], weights=total)\n",
        "    metrics['f1_score'] = np.average([m['f1'] for m in class_metrics], weights=total)\n",
        "\n",
        "    # Overall accuracy\n",
        "    metrics['accuracy'] = np.sum(np.diag(cm)) / np.sum(cm)\n",
        "\n",
        "    # Kappa calculation\n",
        "    n = np.sum(cm)\n",
        "    sum_po = np.sum(np.diag(cm))\n",
        "    sum_pe = np.sum(np.sum(cm, axis=0) * np.sum(cm, axis=1)) / n\n",
        "    metrics['kappa'] = (sum_po - sum_pe) / (n - sum_pe + 1e-6)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def stage_one_training(model, train_loader, val_loader, device, checkpoint_path, numepochs=50):\n",
        "    \"\"\"\n",
        "    Stage 1: Train only the LCM branches\n",
        "    \"\"\"\n",
        "    print(\"\\nStarting Stage 1: Training LCM branches...\")\n",
        "\n",
        "    # Optimization setup\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "\n",
        "    # Initialize tracking variables\n",
        "    best_val_loss = float('inf')\n",
        "    history = {'train_loss': [], 'val_loss': [], 'val_metrics': []}\n",
        "\n",
        "    # Try to load checkpoint if it exists\n",
        "    start_epoch = 0\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        print(f\"Loading checkpoint from {checkpoint_path}\")\n",
        "        try:\n",
        "            checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            start_epoch = checkpoint['epoch']\n",
        "            best_val_loss = checkpoint.get('val_loss', float('inf'))\n",
        "            print(f\"Resuming from epoch {start_epoch} with best val loss: {best_val_loss:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading checkpoint: {e}\")\n",
        "            print(\"Starting training from scratch\")\n",
        "\n",
        "    for epoch in range(start_epoch, numepochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{numepochs}\")\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for data in tqdm(train_loader, desc='Training'):\n",
        "            # Move all tensors to device\n",
        "            img1, img2, mask1, mask2, _ = [x.to(device) for x in data]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass - only LCM branches\n",
        "            lcm1_out, lcm2_out, _ = model(img1, img2)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = (criterion(lcm1_out, mask1) + criterion(lcm2_out, mask2)) / 2\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # Clear memory\n",
        "            del lcm1_out, lcm2_out\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        all_metrics_lcm1 = []\n",
        "        all_metrics_lcm2 = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data in tqdm(val_loader, desc='Validation'):\n",
        "                # Move all tensors to device\n",
        "                img1, img2, mask1, mask2, _ = [x.to(device) for x in data]\n",
        "\n",
        "                # Forward pass\n",
        "                lcm1_out, lcm2_out, _ = model(img1, img2)\n",
        "\n",
        "                # Calculate loss\n",
        "                loss = (criterion(lcm1_out, mask1) + criterion(lcm2_out, mask2)) / 2\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                # Calculate metrics\n",
        "                lcm1_preds = torch.argmax(lcm1_out, dim=1)\n",
        "                lcm2_preds = torch.argmax(lcm2_out, dim=1)\n",
        "\n",
        "                metrics_lcm1 = calculate_metrics(lcm1_preds.cpu().numpy(),\n",
        "                                              mask1.cpu().numpy(),\n",
        "                                              num_classes=4)  # 4 semantic classes\n",
        "                metrics_lcm2 = calculate_metrics(lcm2_preds.cpu().numpy(),\n",
        "                                              mask2.cpu().numpy(),\n",
        "                                              num_classes=4)\n",
        "\n",
        "                all_metrics_lcm1.append(metrics_lcm1)\n",
        "                all_metrics_lcm2.append(metrics_lcm2)\n",
        "\n",
        "                # Clear memory\n",
        "                del lcm1_out, lcm2_out, lcm1_preds, lcm2_preds\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "        # Calculate average metrics\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "        # Aggregate metrics\n",
        "        val_metrics = {\n",
        "            'lcm1': {key: np.mean([m[key] for m in all_metrics_lcm1])\n",
        "                    for key in all_metrics_lcm1[0].keys()},\n",
        "            'lcm2': {key: np.mean([m[key] for m in all_metrics_lcm2])\n",
        "                    for key in all_metrics_lcm2[0].keys()}\n",
        "        }\n",
        "\n",
        "        # Save best model based on validation loss\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'val_loss': best_val_loss,\n",
        "                'train_loss': avg_train_loss,\n",
        "                'val_metrics': val_metrics\n",
        "            }, checkpoint_path)\n",
        "            print(f\"Saved new best model with validation loss: {best_val_loss:.4f}\")\n",
        "\n",
        "        # Update learning rate based on val loss\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        # Store metrics\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "        history['val_loss'].append(avg_val_loss)\n",
        "        history['val_metrics'].append(val_metrics)\n",
        "\n",
        "        # Print epoch results\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
        "        print(f\"Val Loss: {avg_val_loss:.4f}\")\n",
        "        print(f\"LCM 2019 - mIoU: {val_metrics['lcm1']['miou']:.4f}, Accuracy: {val_metrics['lcm1']['accuracy']:.4f}\")\n",
        "        print(f\"LCM 2024 - mIoU: {val_metrics['lcm2']['miou']:.4f}, Accuracy: {val_metrics['lcm2']['accuracy']:.4f}\")\n",
        "\n",
        "    return model, history\n",
        "\n",
        "def stage_two_training(model, train_loader, val_loader, device, checkpoint_path, numepochs=50):\n",
        "    \"\"\"\n",
        "    Stage 2: Train the full model end-to-end with fixed LCM weights\n",
        "    \"\"\"\n",
        "    print(\"\\nStarting Stage 2: Training CD branch...\")\n",
        "\n",
        "    # Freeze encoder and LCM decoder weights\n",
        "    for param in model.encoder.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model.lcm_decoder.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Optimization setup\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "\n",
        "    # Initialize tracking variables\n",
        "    best_val_loss = float('inf')\n",
        "    history = {'train_loss': [], 'val_loss': [], 'val_metrics': []}\n",
        "\n",
        "    # Try to load checkpoint if it exists\n",
        "    start_epoch = 0\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        print(f\"Loading checkpoint from {checkpoint_path}\")\n",
        "        try:\n",
        "            checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            start_epoch = checkpoint['epoch']\n",
        "            best_val_loss = checkpoint.get('val_loss', float('inf'))\n",
        "            print(f\"Resuming from epoch {start_epoch} with best val loss: {best_val_loss:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading checkpoint: {e}\")\n",
        "            print(\"Starting training from scratch\")\n",
        "\n",
        "    for epoch in range(start_epoch, numepochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{numepochs}\")\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for data in tqdm(train_loader, desc='Training'):\n",
        "            # Move all tensors to device\n",
        "            img1, img2, _, _, cd_mask = [x.to(device) for x in data]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            _, _, cd_out = model(img1, img2)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(cd_out, cd_mask)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # Clear memory\n",
        "            del cd_out\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        all_metrics_cd = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data in tqdm(val_loader, desc='Validation'):\n",
        "                # Move all tensors to device\n",
        "                img1, img2, _, _, cd_mask = [x.to(device) for x in data]\n",
        "\n",
        "                # Forward pass\n",
        "                _, _, cd_out = model(img1, img2)\n",
        "\n",
        "                # Calculate loss\n",
        "                loss = criterion(cd_out, cd_mask)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                # Move tensors to CPU and convert to numpy\n",
        "                cd_preds = torch.argmax(cd_out, dim=1).cpu().numpy()\n",
        "                cd_mask_np = cd_mask.cpu().numpy()\n",
        "\n",
        "                metrics = calculate_metrics(cd_preds,\n",
        "                                         cd_mask_np,\n",
        "                                         num_classes=13)  # 13 change classes\n",
        "                all_metrics_cd.append(metrics)\n",
        "\n",
        "                # Clear memory\n",
        "                del cd_out, cd_preds\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "        # Calculate average metrics\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        val_metrics = {key: np.mean([m[key] for m in all_metrics_cd])\n",
        "                      for key in all_metrics_cd[0].keys()}\n",
        "\n",
        "        # Save best model based on validation loss\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'val_loss': best_val_loss,\n",
        "                'train_loss': avg_train_loss,\n",
        "                'val_metrics': val_metrics\n",
        "            }, checkpoint_path)\n",
        "            print(f\"Saved new best model with validation loss: {best_val_loss:.4f}\")\n",
        "\n",
        "        # Update learning rate based on val loss\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        # Store metrics\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "        history['val_loss'].append(avg_val_loss)\n",
        "        history['val_metrics'].append(val_metrics)\n",
        "\n",
        "        # Print epoch results\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
        "        print(f\"Val Loss: {avg_val_loss:.4f}\")\n",
        "        print(f\"CD Metrics - mIoU: {val_metrics['miou']:.4f}, Accuracy: {val_metrics['accuracy']:.4f}\")\n",
        "\n",
        "    return model, history\n",
        "\n",
        "\n",
        "import json\n",
        "def save_training_history(stage1_history, stage2_history, checkpoint_path, \n",
        "                          save_path_stage1, save_path_stage2, save_path_bestepoch):\n",
        "    \"\"\"\n",
        "    Save training history and best epoch information to JSON files.\n",
        "\n",
        "    Args:\n",
        "        history (dict): Dictionary containing training and validation metrics\n",
        "        checkpoint_path (str): Path to the model checkpoint file\n",
        "        save_path (str): Path to save the training history\n",
        "        save_path_bestepoch (str): Path to save the best epoch info\n",
        "    \"\"\"\n",
        "    processed_history = {}\n",
        "    for phase, metrics in stage1_history.items():\n",
        "        if isinstance(metrics, list):  # Check if metrics is a list\n",
        "            processed_history[phase] = [\n",
        "                {metric: (value.tolist() if hasattr(value, 'tolist') else value)\n",
        "                 for metric, value in entry.items()} if isinstance(entry, dict) else entry\n",
        "                for entry in metrics\n",
        "            ]\n",
        "        else:  # Handle non-list entries\n",
        "            processed_history[phase] = metrics.tolist() if hasattr(metrics, 'tolist') else metrics\n",
        "\n",
        "    # Save processed history to a JSON file\n",
        "    with open(save_path_stage1, 'w') as f:\n",
        "        json.dump(processed_history, f, indent=4)\n",
        "\n",
        "    print(f\"Training history saved to: {save_path_stage1}\")\n",
        "\n",
        "    processed_history2 = {}\n",
        "    for phase, metrics in stage2_history.items():\n",
        "        if isinstance(metrics, list):  # Check if metrics is a list\n",
        "            processed_history2[phase] = [\n",
        "                {metric: (value.tolist() if hasattr(value, 'tolist') else value)\n",
        "                 for metric, value in entry.items()} if isinstance(entry, dict) else entry\n",
        "                for entry in metrics\n",
        "            ]\n",
        "        else:  # Handle non-list entries\n",
        "            processed_history2[phase] = metrics.tolist() if hasattr(metrics, 'tolist') else metrics\n",
        "\n",
        "    # Save processed history to a JSON file\n",
        "    with open(save_path_stage2, 'w') as f:\n",
        "        json.dump(processed_history2, f, indent=4)\n",
        "\n",
        "    print(f\"Training history saved to: {save_path_stage2}\")\n",
        "\n",
        "    # Load checkpoint to get best epoch info\n",
        "    checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
        "    # print(\"\\nCheckpoint contents:\")\n",
        "    # for key in checkpoint.keys():\n",
        "    #     print(f\"- {key}\")\n",
        "\n",
        "    # Extract best epoch information\n",
        "    epoch_data = {\n",
        "        'best_epoch': int(checkpoint['epoch']),\n",
        "        'total_loss': float(checkpoint['val_loss']),\n",
        "        'accuracy': float(checkpoint['val_metrics']['accuracy']),\n",
        "        'precision': float(checkpoint['val_metrics']['precision']),\n",
        "        'recall': float(checkpoint['val_metrics']['recall']),\n",
        "        'f1': float(checkpoint['val_metrics']['f1_score']),\n",
        "        'miou': float(checkpoint['val_metrics']['miou']),\n",
        "        'kappa': float(checkpoint['val_metrics']['kappa'])\n",
        "    }\n",
        "\n",
        "    # Save the best epoch info\n",
        "    with open(save_path_bestepoch, 'w') as f:\n",
        "        json.dump(epoch_data, f, indent=4)\n",
        "    print(f\"Best epoch info saved to: {save_path_bestepoch}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn9IeC8Gh_t0"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI84JS8oeXsO",
        "outputId": "d5e7b179-afd0-43cc-e330-6cae7097c0ba"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Model configuration\n",
        "input_channels = 3\n",
        "num_semantic_classes = len(SEMANTIC_CLASSES)\n",
        "num_cd_classes = len(CLASSES)\n",
        "\n",
        "# Create model\n",
        "model = MultiTaskChangeDetectionModel(\n",
        "    input_channels=input_channels,\n",
        "    num_semantic_classes=num_semantic_classes,\n",
        "    num_cd_classes=num_cd_classes\n",
        ").to(device)\n",
        "\n",
        "# Define checkpoint paths\n",
        "lcm_checkpoint_path = f'{SAVING_DIR}/best_lcm_model_{NUM_EPOCHS}.pt'\n",
        "full_checkpoint_path = f'{SAVING_DIR}/best_full_model_{NUM_EPOCHS}.pt'\n",
        "\n",
        "# Stage 1: Train LCM branches\n",
        "model1, stage1_history = stage_one_training(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    device=device,\n",
        "    checkpoint_path=lcm_checkpoint_path,\n",
        "    numepochs=NUM_EPOCHS\n",
        ")\n",
        "\n",
        "# Load best LCM model before stage 2\n",
        "if os.path.exists(lcm_checkpoint_path):\n",
        "    checkpoint = torch.load(lcm_checkpoint_path, map_location=device, weights_only=False)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"Loaded best LCM model from epoch {checkpoint['epoch']}\")\n",
        "\n",
        "# Stage 2: End-to-end training\n",
        "model2, stage2_history = stage_two_training(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    device=device,\n",
        "    checkpoint_path=full_checkpoint_path,\n",
        "    numepochs=NUM_EPOCHS\n",
        ")\n",
        "\n",
        "# Save training history\n",
        "save_path_stage1 = f'{SAVING_DIR}/strategy4_training_history_stage1_{NUM_EPOCHS}.json'\n",
        "save_path_stage2 = f'{SAVING_DIR}/strategy4_training_history_stage2_{NUM_EPOCHS}.json'\n",
        "save_path_bestepoch = f'{SAVING_DIR}/strategy4_best_epoch_{NUM_EPOCHS}.json'\n",
        "\n",
        "save_training_history(stage1_history,stage2_history, \n",
        "                      full_checkpoint_path, \n",
        "                      save_path_stage1, save_path_stage2, save_path_bestepoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01y-GwvKbjgl"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E7mY-U5_n8rj",
        "outputId": "ef743eb6-ba80-4c32-f2ae-5e94c92da2be"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def test_model_complete(model, test_loader, device, checkpoint_path, num_classes=13, num_semantic_classes=4):\n",
        "    \"\"\"\n",
        "    Complete test function for multi-task change detection model.\n",
        "    Tests both LCM and CD branches and provides detailed metrics.\n",
        "    \"\"\"\n",
        "    print(\"\\nStarting model testing...\")\n",
        "\n",
        "    # Load model checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "    print(\"Loaded model checkpoint\")\n",
        "\n",
        "    # Initialize storage for metrics\n",
        "    all_cd_metrics = []\n",
        "    all_lcm_metrics = []  # Single list for averaged LCM metrics\n",
        "    total_cd_loss = 0\n",
        "    total_lcm_loss = 0\n",
        "    samples = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Store some random samples for visualization\n",
        "    random_samples = []\n",
        "\n",
        "    print(\"\\nProcessing test data...\")\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (img1, img2, mask1, mask2, cd_mask) in enumerate(tqdm(test_loader)):\n",
        "            # Move data to device\n",
        "            img1, img2 = img1.to(device), img2.to(device)\n",
        "            mask1, mask2 = mask1.to(device), mask2.to(device)\n",
        "            cd_mask = cd_mask.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            lcm1_out, lcm2_out, cd_out = model(img1, img2)\n",
        "\n",
        "            # Calculate losses\n",
        "            cd_loss = criterion(cd_out, cd_mask)\n",
        "            lcm_loss = (criterion(lcm1_out, mask1) + criterion(lcm2_out, mask2)) / 2\n",
        "\n",
        "            batch_size = img1.size(0)\n",
        "            total_cd_loss += cd_loss.item() * batch_size\n",
        "            total_lcm_loss += lcm_loss.item() * batch_size\n",
        "            samples += batch_size\n",
        "\n",
        "            # Get predictions\n",
        "            cd_preds = torch.argmax(cd_out, dim=1)\n",
        "            lcm1_preds = torch.argmax(lcm1_out, dim=1)\n",
        "            lcm2_preds = torch.argmax(lcm2_out, dim=1)\n",
        "\n",
        "            # Calculate metrics\n",
        "            cd_metrics = calculate_metrics(cd_preds.cpu().numpy(),\n",
        "                                        cd_mask.cpu().numpy(),\n",
        "                                        num_classes=num_classes)  # 13 change classes\n",
        "\n",
        "            # Calculate LCM metrics and average them\n",
        "            lcm1_metrics = calculate_metrics(lcm1_preds.cpu().numpy(),\n",
        "                                          mask1.cpu().numpy(),\n",
        "                                          num_classes=num_semantic_classes)   # 4 semantic classes\n",
        "            lcm2_metrics = calculate_metrics(lcm2_preds.cpu().numpy(),\n",
        "                                          mask2.cpu().numpy(),\n",
        "                                          num_classes=num_semantic_classes)   # 4 semantic classes\n",
        "\n",
        "            # Average the LCM metrics\n",
        "            lcm_metrics = {}\n",
        "            for key in lcm1_metrics.keys():\n",
        "                lcm_metrics[key] = (lcm1_metrics[key] + lcm2_metrics[key]) / 2\n",
        "\n",
        "            all_cd_metrics.append(cd_metrics)\n",
        "            all_lcm_metrics.append(lcm_metrics)\n",
        "\n",
        "            # Store random samples for visualization\n",
        "            if len(random_samples) < 5 and batch_idx % 10 == 0:  # Every 10th batch\n",
        "                for i in range(min(batch_size, 5 - len(random_samples))):\n",
        "                    random_samples.append({\n",
        "                        'img1': img1[i].cpu(),\n",
        "                        'img2': img2[i].cpu(),\n",
        "                        'lcm1_pred': lcm1_preds[i].cpu(),\n",
        "                        'lcm1_true': mask1[i].cpu(),\n",
        "                        'lcm2_pred': lcm2_preds[i].cpu(),\n",
        "                        'lcm2_true': mask2[i].cpu(),\n",
        "                        'cd_pred': cd_preds[i].cpu(),\n",
        "                        'cd_true': cd_mask[i].cpu(),\n",
        "                        'cd_probs': torch.softmax(cd_out[i], dim=0).cpu()\n",
        "                    })\n",
        "\n",
        "            # Clear memory\n",
        "            del lcm1_out, lcm2_out, cd_out\n",
        "            del cd_preds, lcm1_preds, lcm2_preds\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    # Calculate average losses\n",
        "    avg_cd_loss = total_cd_loss / samples\n",
        "    avg_lcm_loss = total_lcm_loss / samples\n",
        "\n",
        "    # Calculate average metrics\n",
        "    def aggregate_metrics(metrics_list):\n",
        "        result = {}\n",
        "        for key in metrics_list[0].keys():\n",
        "            result[key] = np.mean([m[key] for m in metrics_list])\n",
        "        return result\n",
        "\n",
        "    cd_metrics = aggregate_metrics(all_cd_metrics)\n",
        "    lcm_metrics = aggregate_metrics(all_lcm_metrics)\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nTest Results:\")\n",
        "    print(\"\\nChange Detection Metrics:\")\n",
        "    print(f\"Loss: {avg_cd_loss:.4f}\")\n",
        "    print(f\"Accuracy: {cd_metrics['accuracy']:.4f}\")\n",
        "    print(f\"mIoU: {cd_metrics['miou']:.4f}\")\n",
        "    print(f\"F1-Score: {cd_metrics['f1_score']:.4f}\")\n",
        "    print(f\"Kappa: {cd_metrics['kappa']:.4f}\")\n",
        "\n",
        "    print(\"\\nLand Cover Mapping Metrics (Averaged):\")\n",
        "    print(f\"Loss: {avg_lcm_loss:.4f}\")\n",
        "    print(f\"Accuracy: {lcm_metrics['accuracy']:.4f}\")\n",
        "    print(f\"mIoU: {lcm_metrics['miou']:.4f}\")\n",
        "    print(f\"F1-Score: {lcm_metrics['f1_score']:.4f}\")\n",
        "    print(f\"Kappa: {lcm_metrics['kappa']:.4f}\")\n",
        "\n",
        "    # Visualize results\n",
        "    if random_samples:\n",
        "        visualize_results(random_samples)\n",
        "    else:\n",
        "        print(\"\\nNo samples available for visualization\")\n",
        "\n",
        "    return {\n",
        "        'cd_metrics': cd_metrics,\n",
        "        'lcm_metrics': lcm_metrics,  # Single set of averaged LCM metrics\n",
        "        'cd_loss': avg_cd_loss,\n",
        "        'lcm_loss': avg_lcm_loss\n",
        "    }\n",
        "\n",
        "def visualize_results(samples):\n",
        "    \"\"\"\n",
        "    Visualize test results including original images, predictions, \n",
        "    and ground truth for both LCM and CD\n",
        "    \"\"\"\n",
        "    num_samples = len(samples)\n",
        "    fig, axes = plt.subplots(num_samples, 8, figsize=(32, 4*num_samples))\n",
        "    if num_samples == 1:\n",
        "        axes = axes[np.newaxis, :]\n",
        "\n",
        "    for idx, sample in enumerate(samples):\n",
        "        # Original images\n",
        "        axes[idx, 0].imshow(sample['img1'].permute(1, 2, 0))\n",
        "        axes[idx, 0].set_title('Image 2019')\n",
        "        axes[idx, 0].axis('off')\n",
        "\n",
        "        axes[idx, 1].imshow(sample['img2'].permute(1, 2, 0))\n",
        "        axes[idx, 1].set_title('Image 2024')\n",
        "        axes[idx, 1].axis('off')\n",
        "\n",
        "        # LCM 2019 results\n",
        "        axes[idx, 2].imshow(sample['lcm1_pred'], cmap='tab10')\n",
        "        axes[idx, 2].set_title('LCM 2019 Pred')\n",
        "        axes[idx, 2].axis('off')\n",
        "\n",
        "        axes[idx, 3].imshow(sample['lcm1_true'], cmap='tab10')\n",
        "        axes[idx, 3].set_title('LCM 2019 GT')\n",
        "        axes[idx, 3].axis('off')\n",
        "\n",
        "        # LCM 2024 results\n",
        "        axes[idx, 4].imshow(sample['lcm2_pred'], cmap='tab10')\n",
        "        axes[idx, 4].set_title('LCM 2024 Pred')\n",
        "        axes[idx, 4].axis('off')\n",
        "\n",
        "        axes[idx, 5].imshow(sample['lcm2_true'], cmap='tab10')\n",
        "        axes[idx, 5].set_title('LCM 2024 GT')\n",
        "        axes[idx, 5].axis('off')\n",
        "\n",
        "        # CD results\n",
        "        axes[idx, 6].imshow(sample['cd_pred'], cmap='tab10')\n",
        "        axes[idx, 6].set_title('CD Prediction')\n",
        "        axes[idx, 6].axis('off')\n",
        "\n",
        "        axes[idx, 7].imshow(sample['cd_true'], cmap='tab10')\n",
        "        axes[idx, 7].set_title('CD Ground Truth')\n",
        "        axes[idx, 7].axis('off')\n",
        "\n",
        "    # Add colorbars and adjust layout\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def save_test_metrics(history, save_path):\n",
        "    # Convert tensors or arrays in the history to lists for JSON serialization\n",
        "    processed_history = {}\n",
        "    for phase, metrics in history.items():\n",
        "        if isinstance(metrics, list):  # Check if metrics is a list\n",
        "            processed_history[phase] = [\n",
        "                {metric: (value.tolist() if hasattr(value, 'tolist') else value)\n",
        "                 for metric, value in entry.items()} if isinstance(entry, dict) else entry\n",
        "                for entry in metrics\n",
        "            ]\n",
        "        else:  # Handle non-list entries\n",
        "            processed_history[phase] = metrics.tolist() if hasattr(metrics, 'tolist') else metrics\n",
        "\n",
        "    # Save processed history to a JSON file\n",
        "    with open(save_path, 'w') as f:\n",
        "        json.dump(processed_history, f, indent=4)\n",
        "\n",
        "    print(f\"Testing history saved to: {save_path}\")\n",
        "\n",
        "# Test the model\n",
        "test_metrics = test_model_complete(\n",
        "    model=model,\n",
        "    test_loader=test_loader,\n",
        "    device=device,\n",
        "    checkpoint_path=full_checkpoint_path,\n",
        "    num_classes=num_cd_classes,\n",
        "    num_semantic_classes=num_semantic_classes\n",
        ")\n",
        "save_path = f'{SAVING_DIR}/strategy4_test_metrics.json'\n",
        "save_test_metrics(test_metrics, save_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
