{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FHV3km-tCqoU",
        "outputId": "180a146c-bc4d-49a8-9b58-459cee67177c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "T7-GLHykC2dB",
        "outputId": "a36c503c-8d99-4b09-f858-1c6add38c521"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/ChangeDetectionUSADividedSplit-png.zip' -d '/content/ChangeDetectionUSADividedSplit-png'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMowMJXZChmE"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRKZrxCtChmG",
        "outputId": "e514eae3-b2d7-4fe2-9346-0efd0d73eb85"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# DataLoader for Change Detection\n",
        "class ChangeDetectionDataset(Dataset):\n",
        "    def __init__(self, t2019_dir, t2024_dir, mask_dir, classes, transform=None):\n",
        "        self.t2019_dir = t2019_dir\n",
        "        self.t2024_dir = t2024_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.classes = classes\n",
        "        self.transform = transform\n",
        "        self.t2019_paths = sorted([f for f in os.listdir(t2019_dir) if f.endswith('.png')])\n",
        "        self.t2024_paths = sorted([f for f in os.listdir(t2024_dir) if f.endswith('.png')])\n",
        "        self.mask_paths = sorted([f for f in os.listdir(mask_dir) if f.endswith('.png')])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.t2019_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Load 2019 and 2024 images\n",
        "        img_t2019 = np.array(Image.open(os.path.join(self.t2019_dir, self.t2019_paths[index])),\n",
        "                            dtype=np.float32) / 255.0\n",
        "        img_t2024 = np.array(Image.open(os.path.join(self.t2024_dir, self.t2024_paths[index])),\n",
        "                            dtype=np.float32) / 255.0\n",
        "\n",
        "        # Load mask and normalize values\n",
        "        mask = np.array(Image.open(os.path.join(self.mask_dir, self.mask_paths[index])), dtype=np.int64)\n",
        "\n",
        "        # Normalize mask values\n",
        "        mask[mask == 127] = 1\n",
        "        mask[mask == 255] = 2\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        img_t2019 = torch.from_numpy(img_t2019).permute(2, 0, 1)\n",
        "        img_t2024 = torch.from_numpy(img_t2024).permute(2, 0, 1)\n",
        "        mask = torch.from_numpy(mask)\n",
        "\n",
        "        return img_t2019, img_t2024, mask\n",
        "\n",
        "# Define class labels\n",
        "CLASSES = ['no_change', 'increase_vegetation', 'decrease_vegetation']\n",
        "ROOT_DIRECTORY = \"ChangeDetectionUSADividedSplit-png\"\n",
        "CHANGE_MASK = \"cd1_Output\"\n",
        "\n",
        "# DataLoader Setup\n",
        "train_dataset = ChangeDetectionDataset(\n",
        "    t2019_dir=f\"{ROOT_DIRECTORY}/train/Images/T2019\",\n",
        "    t2024_dir=f\"{ROOT_DIRECTORY}/train/Images/T2024\",\n",
        "    mask_dir=f\"{ROOT_DIRECTORY}/train/{CHANGE_MASK}\",\n",
        "    classes=CLASSES\n",
        ")\n",
        "\n",
        "val_dataset = ChangeDetectionDataset(\n",
        "    t2019_dir=f\"{ROOT_DIRECTORY}/val/Images/T2019\",\n",
        "    t2024_dir=f\"{ROOT_DIRECTORY}/val/Images/T2024\",\n",
        "    mask_dir=f\"{ROOT_DIRECTORY}/val/{CHANGE_MASK}\",\n",
        "    classes=CLASSES\n",
        ")\n",
        "\n",
        "test_dataset = ChangeDetectionDataset(\n",
        "    t2019_dir=f\"{ROOT_DIRECTORY}/test/Images/T2019\",\n",
        "    t2024_dir=f\"{ROOT_DIRECTORY}/test/Images/T2024\",\n",
        "    mask_dir=f\"{ROOT_DIRECTORY}/test/{CHANGE_MASK}\",\n",
        "    classes=CLASSES\n",
        ")\n",
        "\n",
        "# Create DataLoader instances\n",
        "num_workers = 8\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "def describe_loader(loader_type):\n",
        "    print(\"Batch size: \", loader_type.batch_size)\n",
        "    print(\"Shape: \", loader_type.dataset[0][0].shape,\n",
        "          loader_type.dataset[0][1].shape, loader_type.dataset[0][2].shape)\n",
        "    print(\"Number of images: \", len(loader_type.dataset))\n",
        "    print(\"Classes: \", loader_type.dataset.classes)\n",
        "\n",
        "print(\"------------Train------------\")\n",
        "describe_loader(train_loader)\n",
        "print(\"------------Val------------\")\n",
        "describe_loader(val_loader)\n",
        "print(\"------------Test------------\")\n",
        "describe_loader(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpBgPG9nChmH"
      },
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "execution": {
          "iopub.execute_input": "2024-11-23T07:31:08.133857Z",
          "iopub.status.busy": "2024-11-23T07:31:08.133489Z",
          "iopub.status.idle": "2024-11-23T07:31:09.149435Z",
          "shell.execute_reply": "2024-11-23T07:31:09.148146Z",
          "shell.execute_reply.started": "2024-11-23T07:31:08.133829Z"
        },
        "id": "EkAWjfmNChmH",
        "outputId": "15f7e24d-ae16-4bef-97b4-6c69286af714",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Set up the plot size and remove axes\n",
        "fig, axs = plt.subplots(5, 3, figsize=(10,10))\n",
        "#plt.figure(figsize=(10, 10))  # Set the figure size to be larger\n",
        "\n",
        "for i in range(5):\n",
        "    j = random.randint(0, len(train_dataset) - 1)\n",
        "#for i in range(len()):\n",
        "    image1, image2, mask = train_dataset[j]\n",
        "\n",
        "    # Display images\n",
        "    axs[i, 0].imshow(image1.permute(1, 2, 0))\n",
        "    axs[i, 0].set_title(f\"Real 2019\")\n",
        "    axs[i, 0].axis(\"off\")\n",
        "\n",
        "    axs[i, 1].imshow(image2.permute(1, 2, 0))\n",
        "    axs[i, 1].set_title(f\"Real 2024\")\n",
        "    axs[i, 1].axis(\"off\")\n",
        "\n",
        "    axs[i, 2].imshow(mask, cmap=\"turbo\")\n",
        "    print(np.unique(mask))\n",
        "    axs[i, 2].set_title(f\"CD Mask\")\n",
        "    axs[i, 2].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzg6sjHCChmH"
      },
      "source": [
        "## Siamese U-Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKI0wDXtChmI"
      },
      "source": [
        "### Model Definition and Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js4x7bG3tQJ4",
        "outputId": "e02fc9e9-9d52-4f2a-8fdd-e3af016a05a3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.modules.padding import ReplicationPad2d\n",
        "import torch.optim as optim\n",
        "\n",
        "class SiamUnet_conc(nn.Module):\n",
        "    \"\"\"SiamUnet_conc segmentation network for multiclass change detection.\"\"\"\n",
        "\n",
        "    def __init__(self, input_nbr, label_nbr):\n",
        "        super(SiamUnet_conc, self).__init__()\n",
        "\n",
        "        self.input_nbr = input_nbr\n",
        "\n",
        "        # Encoder Layers\n",
        "        self.conv11 = nn.Conv2d(input_nbr, 16, kernel_size=3, padding=1)\n",
        "        self.bn11 = nn.BatchNorm2d(16)\n",
        "        self.do11 = nn.Dropout2d(p=0.2)\n",
        "        self.conv12 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n",
        "        self.bn12 = nn.BatchNorm2d(16)\n",
        "        self.do12 = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.conv21 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.bn21 = nn.BatchNorm2d(32)\n",
        "        self.do21 = nn.Dropout2d(p=0.2)\n",
        "        self.conv22 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
        "        self.bn22 = nn.BatchNorm2d(32)\n",
        "        self.do22 = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.conv31 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn31 = nn.BatchNorm2d(64)\n",
        "        self.do31 = nn.Dropout2d(p=0.2)\n",
        "        self.conv32 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn32 = nn.BatchNorm2d(64)\n",
        "        self.do32 = nn.Dropout2d(p=0.2)\n",
        "        self.conv33 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn33 = nn.BatchNorm2d(64)\n",
        "        self.do33 = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.conv41 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn41 = nn.BatchNorm2d(128)\n",
        "        self.do41 = nn.Dropout2d(p=0.2)\n",
        "        self.conv42 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn42 = nn.BatchNorm2d(128)\n",
        "        self.do42 = nn.Dropout2d(p=0.2)\n",
        "        self.conv43 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn43 = nn.BatchNorm2d(128)\n",
        "        self.do43 = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose2d(128, 128, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
        "\n",
        "        # Decoder Layers\n",
        "        self.conv43d = nn.ConvTranspose2d(384, 128, kernel_size=3, padding=1)\n",
        "        self.bn43d = nn.BatchNorm2d(128)\n",
        "        self.do43d = nn.Dropout2d(p=0.2)\n",
        "        self.conv42d = nn.ConvTranspose2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn42d = nn.BatchNorm2d(128)\n",
        "        self.do42d = nn.Dropout2d(p=0.2)\n",
        "        self.conv41d = nn.ConvTranspose2d(128, 64, kernel_size=3, padding=1)\n",
        "        self.bn41d = nn.BatchNorm2d(64)\n",
        "        self.do41d = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.upconv3 = nn.ConvTranspose2d(64, 64, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
        "\n",
        "        self.conv33d = nn.ConvTranspose2d(192, 64, kernel_size=3, padding=1)\n",
        "        self.bn33d = nn.BatchNorm2d(64)\n",
        "        self.do33d = nn.Dropout2d(p=0.2)\n",
        "        self.conv32d = nn.ConvTranspose2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn32d = nn.BatchNorm2d(64)\n",
        "        self.do32d = nn.Dropout2d(p=0.2)\n",
        "        self.conv31d = nn.ConvTranspose2d(64, 32, kernel_size=3, padding=1)\n",
        "        self.bn31d = nn.BatchNorm2d(32)\n",
        "        self.do31d = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.upconv2 = nn.ConvTranspose2d(32, 32, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
        "\n",
        "        self.conv22d = nn.ConvTranspose2d(96, 32, kernel_size=3, padding=1)\n",
        "        self.bn22d = nn.BatchNorm2d(32)\n",
        "        self.do22d = nn.Dropout2d(p=0.2)\n",
        "        self.conv21d = nn.ConvTranspose2d(32, 16, kernel_size=3, padding=1)\n",
        "        self.bn21d = nn.BatchNorm2d(16)\n",
        "        self.do21d = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.upconv1 = nn.ConvTranspose2d(16, 16, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
        "\n",
        "        self.conv12d = nn.ConvTranspose2d(48, 16, kernel_size=3, padding=1)\n",
        "        self.bn12d = nn.BatchNorm2d(16)\n",
        "        self.do12d = nn.Dropout2d(p=0.2)\n",
        "        # self.conv11d = nn.ConvTranspose2d(16, label_nbr, kernel_size=3, padding=1)\n",
        "        self.conv11d = nn.ConvTranspose2d(16, 3, kernel_size=3, padding=1)\n",
        "\n",
        "        # Multiclass activation (Softmax instead of LogSoftmax)\n",
        "        self.sm = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "\n",
        "        \"\"\"Forward method.\"\"\"\n",
        "        # Stage 1\n",
        "        x11 = self.do11(F.relu(self.bn11(self.conv11(x1))))\n",
        "        x12_1 = self.do12(F.relu(self.bn12(self.conv12(x11))))\n",
        "        x1p = F.max_pool2d(x12_1, kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "        # Stage 2\n",
        "        x21 = self.do21(F.relu(self.bn21(self.conv21(x1p))))\n",
        "        x22_1 = self.do22(F.relu(self.bn22(self.conv22(x21))))\n",
        "        x2p = F.max_pool2d(x22_1, kernel_size=2, stride=2)\n",
        "\n",
        "        # Stage 3\n",
        "        x31 = self.do31(F.relu(self.bn31(self.conv31(x2p))))\n",
        "        x32 = self.do32(F.relu(self.bn32(self.conv32(x31))))\n",
        "        x33_1 = self.do33(F.relu(self.bn33(self.conv33(x32))))\n",
        "        x3p = F.max_pool2d(x33_1, kernel_size=2, stride=2)\n",
        "\n",
        "        # Stage 4\n",
        "        x41 = self.do41(F.relu(self.bn41(self.conv41(x3p))))\n",
        "        x42 = self.do42(F.relu(self.bn42(self.conv42(x41))))\n",
        "        x43_1 = self.do43(F.relu(self.bn43(self.conv43(x42))))\n",
        "        x4p = F.max_pool2d(x43_1, kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "        ####################################################\n",
        "        # Stage 1\n",
        "        x11 = self.do11(F.relu(self.bn11(self.conv11(x2))))\n",
        "        x12_2 = self.do12(F.relu(self.bn12(self.conv12(x11))))\n",
        "        x1p = F.max_pool2d(x12_2, kernel_size=2, stride=2)\n",
        "\n",
        "        # Stage 2\n",
        "        x21 = self.do21(F.relu(self.bn21(self.conv21(x1p))))\n",
        "        x22_2 = self.do22(F.relu(self.bn22(self.conv22(x21))))\n",
        "        x2p = F.max_pool2d(x22_2, kernel_size=2, stride=2)\n",
        "\n",
        "        # Stage 3\n",
        "        x31 = self.do31(F.relu(self.bn31(self.conv31(x2p))))\n",
        "        x32 = self.do32(F.relu(self.bn32(self.conv32(x31))))\n",
        "        x33_2 = self.do33(F.relu(self.bn33(self.conv33(x32))))\n",
        "        x3p = F.max_pool2d(x33_2, kernel_size=2, stride=2)\n",
        "\n",
        "        # Stage 4\n",
        "        x41 = self.do41(F.relu(self.bn41(self.conv41(x3p))))\n",
        "        x42 = self.do42(F.relu(self.bn42(self.conv42(x41))))\n",
        "        x43_2 = self.do43(F.relu(self.bn43(self.conv43(x42))))\n",
        "        x4p = F.max_pool2d(x43_2, kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "        ####################################################\n",
        "        # Stage 4d\n",
        "        x4d = self.upconv4(x4p)\n",
        "        pad4 = ReplicationPad2d((0, x43_1.size(3) - x4d.size(3), 0, x43_1.size(2) - x4d.size(2)))\n",
        "        x4d = torch.cat((pad4(x4d), x43_1, x43_2), 1)\n",
        "        x43d = self.do43d(F.relu(self.bn43d(self.conv43d(x4d))))\n",
        "        x42d = self.do42d(F.relu(self.bn42d(self.conv42d(x43d))))\n",
        "        x41d = self.do41d(F.relu(self.bn41d(self.conv41d(x42d))))\n",
        "\n",
        "        # Stage 3d\n",
        "        x3d = self.upconv3(x41d)\n",
        "        pad3 = ReplicationPad2d((0, x33_1.size(3) - x3d.size(3), 0, x33_1.size(2) - x3d.size(2)))\n",
        "        x3d = torch.cat((pad3(x3d), x33_1, x33_2), 1)\n",
        "        x33d = self.do33d(F.relu(self.bn33d(self.conv33d(x3d))))\n",
        "        x32d = self.do32d(F.relu(self.bn32d(self.conv32d(x33d))))\n",
        "        x31d = self.do31d(F.relu(self.bn31d(self.conv31d(x32d))))\n",
        "\n",
        "        # Stage 2d\n",
        "        x2d = self.upconv2(x31d)\n",
        "        pad2 = ReplicationPad2d((0, x22_1.size(3) - x2d.size(3), 0, x22_1.size(2) - x2d.size(2)))\n",
        "        x2d = torch.cat((pad2(x2d), x22_1, x22_2), 1)\n",
        "        x22d = self.do22d(F.relu(self.bn22d(self.conv22d(x2d))))\n",
        "        x21d = self.do21d(F.relu(self.bn21d(self.conv21d(x22d))))\n",
        "\n",
        "        # Stage 1d\n",
        "        x1d = self.upconv1(x21d)\n",
        "        pad1 = ReplicationPad2d((0, x12_1.size(3) - x1d.size(3), 0, x12_1.size(2) - x1d.size(2)))\n",
        "        x1d = torch.cat((pad1(x1d), x12_1, x12_2), 1)\n",
        "        x12d = self.do12d(F.relu(self.bn12d(self.conv12d(x1d))))\n",
        "        x11d = self.conv11d(x12d)\n",
        "\n",
        "        return self.sm(x11d)\n",
        "\n",
        "def calculate_metrics(outputs, labels):\n",
        "    \"\"\"\n",
        "    Calculate metrics for a multiclass classification model, including:\n",
        "    - Accuracy, precision, recall, F1-score, IoU, and Dice coefficient per class\n",
        "    - Overall accuracy and kappa coefficient\n",
        "    \"\"\"\n",
        "    # Get predicted classes\n",
        "    preds = torch.argmax(outputs, dim=1)\n",
        "    num_classes = outputs.size(1)\n",
        "\n",
        "    # Initialize variables to calculate metrics\n",
        "    class_metrics = []\n",
        "    confusion_matrix = torch.zeros((num_classes, num_classes), dtype=torch.float)\n",
        "\n",
        "    # Populate the confusion matrix\n",
        "    for t, p in zip(labels.view(-1), preds.view(-1)):\n",
        "        confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "    # Calculate metrics for each class\n",
        "    for class_idx in range(num_classes):\n",
        "        true_positives = confusion_matrix[class_idx, class_idx]\n",
        "        false_positives = confusion_matrix[:, class_idx].sum() - true_positives\n",
        "        false_negatives = confusion_matrix[class_idx, :].sum() - true_positives\n",
        "        true_negatives = confusion_matrix.sum() - (true_positives + false_positives + false_negatives)\n",
        "\n",
        "        # Metrics for the class\n",
        "        precision = true_positives / (true_positives + false_positives + 1e-8)\n",
        "        recall = true_positives / (true_positives + false_negatives + 1e-8)\n",
        "        f1_score = 2 * precision * recall / (precision + recall + 1e-8)\n",
        "        iou = true_positives / (true_positives + false_positives + false_negatives + 1e-8)\n",
        "        dice = 2 * true_positives / (2 * true_positives + false_positives + false_negatives + 1e-8)\n",
        "        accuracy = (true_positives + true_negatives) / confusion_matrix.sum()\n",
        "\n",
        "        # Store metrics for the class\n",
        "        class_metrics.append({\n",
        "            'class': class_idx,\n",
        "            'accuracy': accuracy.item(),\n",
        "            'precision': precision.item(),\n",
        "            'recall': recall.item(),\n",
        "            'f1_score': f1_score.item(),\n",
        "            'iou': iou.item(),\n",
        "            'dice': dice.item(),\n",
        "        })\n",
        "\n",
        "    # Overall accuracy\n",
        "    overall_accuracy = (preds == labels).float().mean().item()\n",
        "\n",
        "    # Kappa coefficient\n",
        "    total_samples = confusion_matrix.sum()\n",
        "    row_marginals = confusion_matrix.sum(dim=1)\n",
        "    col_marginals = confusion_matrix.sum(dim=0)\n",
        "    expected_matrix = torch.outer(row_marginals, col_marginals) / total_samples\n",
        "    observed_agreement = confusion_matrix.trace()\n",
        "    expected_agreement = expected_matrix.trace()\n",
        "    kappa_coefficient = (observed_agreement - expected_agreement) / (total_samples - expected_agreement + 1e-8)\n",
        "\n",
        "    return class_metrics, overall_accuracy, kappa_coefficient\n",
        "\n",
        "def calculate_effective_weights(train_loader, device, num_classes=3, method='balanced'):\n",
        "    \"\"\"Calculate class weights with different strategies to handle class imbalance\n",
        "\n",
        "    Args:\n",
        "        train_loader: DataLoader containing training data\n",
        "        device: torch device\n",
        "        num_classes: number of classes (default: 3)\n",
        "        method: weighting strategy ('balanced', 'square_balanced', or 'custom')\n",
        "    \"\"\"\n",
        "    class_counts = torch.zeros(num_classes)\n",
        "    total_pixels = 0\n",
        "\n",
        "    # Count class frequencies\n",
        "    for _, _, labels in train_loader:\n",
        "        labels = labels.to(device)\n",
        "        for i in range(num_classes):\n",
        "            class_counts[i] += (labels == i).sum().item()\n",
        "        total_pixels += labels.numel()\n",
        "\n",
        "    class_frequencies = class_counts / total_pixels\n",
        "\n",
        "    if method == 'balanced':\n",
        "        # Standard balanced weighting (inverse frequency)\n",
        "        weights = 1.0 / class_frequencies\n",
        "\n",
        "    elif method == 'square_balanced':\n",
        "        # Square root of inverse frequencies (less aggressive balancing)\n",
        "        weights = torch.sqrt(1.0 / class_frequencies)\n",
        "\n",
        "    elif method == 'custom':\n",
        "        # Custom weighting that maintains some natural class distribution\n",
        "        # Adjust these factors based on your domain knowledge\n",
        "        base_weights = 1.0 / class_frequencies\n",
        "        adjustment_factors = torch.tensor([0.7, 1.2, 1.2])  # Reduce weight of class 0, increase others\n",
        "        weights = base_weights * adjustment_factors\n",
        "\n",
        "    # Normalize weights to sum to num_classes\n",
        "    weights = weights * (num_classes / weights.sum())\n",
        "\n",
        "    return weights, class_frequencies\n",
        "\n",
        "# Define Focal Loss\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, weight=None, gamma=2.0):\n",
        "        super().__init__()\n",
        "        self.weight = weight\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        ce_loss = F.cross_entropy(input, target, reduction='none', weight=self.weight)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
        "        return focal_loss\n",
        "\n",
        "def train_model_balanced(model, train_loader, val_loader, num_epochs=50, device='cuda',\n",
        "                         weighting_method='square_balanced', LOSS='focal', checkpoint_path='best_model_multiclass.pt'):\n",
        "    \"\"\"\n",
        "    Training function with checkpoint loading and saving capability.\n",
        "    Args:\n",
        "        model: The model to train\n",
        "        train_loader: Training data loader\n",
        "        val_loader: Validation data loader\n",
        "        num_epochs: Total number of epochs to train\n",
        "        device: Device to train on\n",
        "        weighting_method: Method for calculating class weights\n",
        "        LOSS: Loss function to use ('focal' or 'CE')\n",
        "        checkpoint_path: Path to save/load checkpoint\n",
        "    \"\"\"\n",
        "    start_epoch = 0\n",
        "    best_val_iou = 0\n",
        "\n",
        "    # Try to load checkpoint if it exists\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        print(f\"Loading checkpoint from {checkpoint_path}\")\n",
        "        try:\n",
        "            checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            start_epoch = checkpoint['epoch']\n",
        "            best_val_iou = checkpoint['best_val_iou']\n",
        "            print(f\"Resuming from epoch {start_epoch} with best IoU: {best_val_iou:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading checkpoint: {e}\")\n",
        "            print(\"Starting training from scratch\")\n",
        "            start_epoch = 0\n",
        "            best_val_iou = 0\n",
        "    else:\n",
        "        print(\"No checkpoint found. Starting training from scratch\")\n",
        "\n",
        "    # Calculate class weights\n",
        "    class_weights, _ = calculate_effective_weights(train_loader, device, num_classes=3, method=weighting_method)\n",
        "    print(f\"Class weights: {class_weights}\")\n",
        "\n",
        "    # Select loss function\n",
        "    if LOSS.lower() == 'focal':\n",
        "        focal_gamma = 2.0\n",
        "        criterion = FocalLoss(weight=class_weights.to(device), gamma=focal_gamma)\n",
        "    else:  # 'CE'\n",
        "        criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "\n",
        "    # Initialize optimizer and scheduler\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, verbose=True)\n",
        "\n",
        "    # Load optimizer and scheduler states if available\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        try:\n",
        "            checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
        "            if 'optimizer_state_dict' in checkpoint:\n",
        "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            if 'scheduler_state_dict' in checkpoint:\n",
        "                scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading optimizer/scheduler states: {e}\")\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_metrics = {'loss': 0, 'accuracy': 0, 'precision': [0, 0, 0], 'recall': [0, 0, 0], \n",
        "                         'f1': [0, 0, 0], 'dice': 0, 'iou': [0, 0, 0]}\n",
        "        train_samples = 0\n",
        "        train_class_predictions = torch.zeros(3).to(device)\n",
        "\n",
        "        for inputs1, inputs2, labels in train_loader:\n",
        "            inputs1, inputs2, labels = inputs1.to(device), inputs2.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs1, inputs2)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculate metrics for training\n",
        "            acc, precision, recall, f1, dice, iou = calculate_metrics(outputs, labels)\n",
        "            batch_size = inputs1.size(0)\n",
        "\n",
        "            train_metrics['loss'] += loss.item() * batch_size\n",
        "            train_metrics['accuracy'] += acc * batch_size\n",
        "            for i in range(3):\n",
        "                train_metrics['precision'][i] += precision[i] * batch_size\n",
        "                train_metrics['recall'][i] += recall[i] * batch_size\n",
        "                train_metrics['f1'][i] += f1[i] * batch_size\n",
        "                train_metrics['iou'][i] += iou[i] * batch_size\n",
        "            train_metrics['dice'] += dice * batch_size\n",
        "            train_samples += batch_size\n",
        "\n",
        "            # Track class distribution\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            for i in range(3):\n",
        "                train_class_predictions[i] += (preds == i).sum().item()\n",
        "\n",
        "        # Calculate average training metrics\n",
        "        train_metrics['loss'] /= train_samples\n",
        "        train_metrics['accuracy'] /= train_samples\n",
        "        train_metrics['precision'] = [p / train_samples for p in train_metrics['precision']]\n",
        "        train_metrics['recall'] = [r / train_samples for r in train_metrics['recall']]\n",
        "        train_metrics['f1'] = [f / train_samples for f in train_metrics['f1']]\n",
        "        train_metrics['iou'] = [iou / train_samples for iou in train_metrics['iou']]\n",
        "        train_metrics['dice'] /= train_samples\n",
        "        train_class_dist = train_class_predictions / train_class_predictions.sum()\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_metrics = {'loss': 0, 'accuracy': 0, 'precision': [0, 0, 0], 'recall': [0, 0, 0],\n",
        "                       'f1': [0, 0, 0], 'dice': 0, 'iou': [0, 0, 0]}\n",
        "        val_samples = 0\n",
        "        val_class_predictions = torch.zeros(3).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs1, inputs2, labels in val_loader:\n",
        "                inputs1, inputs2, labels = inputs1.to(device), inputs2.to(device), labels.to(device)\n",
        "                outputs = model(inputs1, inputs2)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Calculate validation metrics\n",
        "                acc, precision, recall, f1, dice, iou = calculate_metrics(outputs, labels)\n",
        "                batch_size = inputs1.size(0)\n",
        "\n",
        "                val_metrics['loss'] += loss.item() * batch_size\n",
        "                val_metrics['accuracy'] += acc * batch_size\n",
        "                for i in range(3):\n",
        "                    val_metrics['precision'][i] += precision[i] * batch_size\n",
        "                    val_metrics['recall'][i] += recall[i] * batch_size\n",
        "                    val_metrics['f1'][i] += f1[i] * batch_size\n",
        "                    val_metrics['iou'][i] += iou[i] * batch_size\n",
        "                val_metrics['dice'] += dice * batch_size\n",
        "                val_samples += batch_size\n",
        "\n",
        "                # Track class distribution\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                for i in range(3):\n",
        "                    val_class_predictions[i] += (preds == i).sum().item()\n",
        "\n",
        "        # Calculate average validation metrics\n",
        "        val_metrics['loss'] /= val_samples\n",
        "        val_metrics['accuracy'] /= val_samples\n",
        "        val_metrics['precision'] = [p / val_samples for p in val_metrics['precision']]\n",
        "        val_metrics['recall'] = [r / val_samples for r in val_metrics['recall']]\n",
        "        val_metrics['f1'] = [f / val_samples for f in val_metrics['f1']]\n",
        "        val_metrics['iou'] = [iou / val_samples for iou in val_metrics['iou']]\n",
        "        val_metrics['dice'] /= val_samples\n",
        "        val_class_dist = val_class_predictions / val_class_predictions.sum()\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step(val_metrics['iou'])\n",
        "\n",
        "        # Print metrics\n",
        "        print(f'\\nEpoch {epoch + 1}/{num_epochs}:')\n",
        "        print(f'Training Loss: {train_metrics[\"loss\"]:.4f}, Accuracy: {train_metrics[\"accuracy\"]:.4f}, Dice: {train_metrics[\"dice\"]:.4f}')\n",
        "        print(f'Training Precision (per class): {train_metrics[\"precision\"]}')\n",
        "        print(f'Training Recall (per class): {train_metrics[\"recall\"]}')\n",
        "        print(f'Training F1-score (per class): {train_metrics[\"f1\"]}')\n",
        "        print(f'Training IoU (per class): {train_metrics[\"iou\"]}')\n",
        "        print(f'Validation Loss: {val_metrics[\"loss\"]:.4f}, Accuracy: {val_metrics[\"accuracy\"]:.4f}, Dice: {val_metrics[\"dice\"]:.4f}')\n",
        "        print(f'Validation Precision (per class): {val_metrics[\"precision\"]}')\n",
        "        print(f'Validation Recall (per class): {val_metrics[\"recall\"]}')\n",
        "        print(f'Validation F1-score (per class): {val_metrics[\"f1\"]}')\n",
        "        print(f'Validation IoU (per class): {val_metrics[\"iou\"]}')\n",
        "\n",
        "        # Save checkpoint if it's the best model\n",
        "        if val_metrics['iou'][1] > best_val_iou:  # Example: Tracking IoU for the second class\n",
        "            best_val_iou = val_metrics['iou'][1]\n",
        "            checkpoint = {\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'best_val_iou': best_val_iou,\n",
        "                'train_loss': train_metrics['loss'],\n",
        "                'val_loss': val_metrics['loss']\n",
        "            }\n",
        "            torch.save(checkpoint, checkpoint_path)\n",
        "            print(f'\\nSaved new best model with validation IoU: {val_metrics[\"iou\"][1]:.4f}')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Initialize and train the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SiamUnet_conc(input_nbr = 3, label_nbr=3).to(device)\n",
        "train_model_balanced(model, train_loader, val_loader,\n",
        "                     num_epochs=50, device=device,\n",
        "                     weighting_method='square_balanced',LOSS='CE')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa0RAqCdChmI"
      },
      "source": [
        "# Eval and Result Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QWMNN7bIoene",
        "outputId": "ab7a8107-78dd-4d07-cc35-119e986b74a0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def analyze_model_outputs(model, test_loader, device, num_samples=5):\n",
        "    model.eval()\n",
        "    outputs_analysis = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs1, inputs2, labels in test_loader:\n",
        "            inputs1, inputs2, labels = inputs1.to(device), inputs2.to(device), labels.to(device)\n",
        "            outputs = model(inputs1, inputs2)\n",
        "\n",
        "            # Store raw outputs and probabilities\n",
        "            for i in range(len(outputs)):\n",
        "                raw_output = outputs[i].cpu()\n",
        "                probabilities = F.softmax(raw_output, dim=0)\n",
        "                predicted_class = torch.argmax(raw_output, dim=0)\n",
        "                true_class = labels[i]\n",
        "\n",
        "                outputs_analysis.append({\n",
        "                    'raw_output': raw_output.numpy(),\n",
        "                    'probabilities': probabilities.numpy(),\n",
        "                    'predicted_class': predicted_class.numpy(),\n",
        "                    'true_class': true_class.cpu().numpy()\n",
        "                })\n",
        "\n",
        "                if len(outputs_analysis) >= num_samples:\n",
        "                    break\n",
        "            if len(outputs_analysis) >= num_samples:\n",
        "                break\n",
        "\n",
        "    # Print analysis\n",
        "    print(\"\\nModel Output Analysis:\")\n",
        "    print(\"-\" * 50)\n",
        "    for i, analysis in enumerate(outputs_analysis):\n",
        "        print(f\"\\nSample {i+1}:\")\n",
        "        print(f\"Raw output range: {analysis['raw_output'].min():.4f} to {analysis['raw_output'].max():.4f}\")\n",
        "        print(\"Class probabilities:\", analysis['probabilities'].mean(axis=(1,2)))\n",
        "        print(\"Unique predicted classes:\", np.unique(analysis['predicted_class']))\n",
        "        print(\"Unique true classes:\", np.unique(analysis['true_class']))\n",
        "\n",
        "    # Plot distribution of predictions\n",
        "    all_preds = np.concatenate([a['predicted_class'].flatten() for a in outputs_analysis])\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.hist(all_preds, bins=np.arange(-0.5, 3.5, 1), alpha=0.7)\n",
        "    plt.title('Distribution of Predicted Classes')\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel('Count')\n",
        "    plt.xticks([0, 1, 2])\n",
        "    plt.show()\n",
        "\n",
        "def test_model_verbose(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    class_predictions = []\n",
        "    softmax_outputs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs1, inputs2, labels in test_loader:\n",
        "            inputs1, inputs2, labels = inputs1.to(device), inputs2.to(device), labels.to(device)\n",
        "            outputs = model(inputs1, inputs2)\n",
        "\n",
        "            # Store predictions and softmax outputs\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            class_predictions.extend(preds.cpu().numpy().flatten())\n",
        "            softmax_outputs.extend(probs.cpu().numpy())\n",
        "\n",
        "            if len(class_predictions) > 1000:  # Analyze first 1000 predictions\n",
        "                break\n",
        "\n",
        "    # Print analysis\n",
        "    unique_classes = np.unique(class_predictions)\n",
        "    print(\"\\nPrediction Analysis:\")\n",
        "    print(f\"Unique predicted classes: {unique_classes}\")\n",
        "    print(\"\\nClass distribution:\")\n",
        "    for cls in range(3):\n",
        "        count = np.sum(np.array(class_predictions) == cls)\n",
        "        percentage = (count / len(class_predictions)) * 100\n",
        "        print(f\"Class {cls}: {count} predictions ({percentage:.2f}%)\")\n",
        "\n",
        "    # Analyze softmax outputs\n",
        "    softmax_array = np.array(softmax_outputs)\n",
        "    print(\"\\nSoftmax output analysis:\")\n",
        "    for cls in range(3):\n",
        "        mean_prob = np.mean(softmax_array[:, cls])\n",
        "        max_prob = np.max(softmax_array[:, cls])\n",
        "        print(f\"Class {cls}:\")\n",
        "        print(f\"  Mean probability: {mean_prob:.4f}\")\n",
        "        print(f\"  Max probability: {max_prob:.4f}\")\n",
        "\n",
        "def main():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Load your trained model\n",
        "    model = SiamUnet_conc(3, 3).to(device)\n",
        "\n",
        "    # Load the checkpoint properly\n",
        "    checkpoint = torch.load('best_model_multiclass.pt', weights_only=True)\n",
        "    # Extract just the model state dict\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "\n",
        "    # Run analysis\n",
        "    print(\"Running detailed model output analysis...\")\n",
        "    analyze_model_outputs(model, test_loader, device)\n",
        "\n",
        "    print(\"\\nRunning verbose testing with distribution analysis...\")\n",
        "    test_model_verbose(model, test_loader, nn.CrossEntropyLoss(), device)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942
        },
        "id": "3qh8xFXixc8J",
        "outputId": "5dd20c94-f28c-4a9d-d1cf-af525d2451f8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "import random\n",
        "\n",
        "def test_model(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_test_loss = 0.0\n",
        "    test_acc_sum = 0\n",
        "    test_precision_sum = 0\n",
        "    test_recall_sum = 0\n",
        "    test_dice_sum = 0\n",
        "    test_iou_sum = 0\n",
        "    test_samples = 0\n",
        "\n",
        "    # For visualization\n",
        "    random_samples = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs1, inputs2, labels in test_loader:\n",
        "            inputs1, inputs2, labels = inputs1.to(device), inputs2.to(device), labels.to(device)\n",
        "            outputs = model(inputs1, inputs2)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Calculate metrics\n",
        "            # acc, precision, recall, dice, iou = calculate_metrics(outputs, labels, num_classes=3)\n",
        "            acc, precision, recall, dice, iou = calculate_metrics(outputs, labels)\n",
        "\n",
        "            # Accumulate metrics\n",
        "            batch_size = inputs1.size(0)\n",
        "            running_test_loss += loss.item() * batch_size\n",
        "            test_acc_sum += acc * batch_size\n",
        "            test_precision_sum += precision * batch_size\n",
        "            test_recall_sum += recall * batch_size\n",
        "            test_dice_sum += dice * batch_size\n",
        "            test_iou_sum += iou * batch_size\n",
        "            test_samples += batch_size\n",
        "\n",
        "            # Store random samples for visualization\n",
        "            if len(random_samples) < 5:\n",
        "                # Get predictions\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "                # Randomly select samples from this batch\n",
        "                for i in range(min(batch_size, 5 - len(random_samples))):\n",
        "                    if random.random() < 0.2:  # 20% chance to select each sample\n",
        "                        random_samples.append({\n",
        "                            'image1': inputs1[i].cpu(),\n",
        "                            'image2': inputs2[i].cpu(),\n",
        "                            'label': labels[i].cpu(),\n",
        "                            'pred': preds[i].cpu(),\n",
        "                            'probabilities': torch.softmax(outputs[i], dim=0).cpu()\n",
        "                        })\n",
        "\n",
        "    # Calculate final metrics\n",
        "    test_loss = running_test_loss / test_samples\n",
        "    test_acc = test_acc_sum / test_samples\n",
        "    test_precision = test_precision_sum / test_samples\n",
        "    test_recall = test_recall_sum / test_samples\n",
        "    test_dice = test_dice_sum / test_samples\n",
        "    test_iou = test_iou_sum / test_samples\n",
        "\n",
        "    # Print metrics\n",
        "    print(f'Test Loss: {test_loss:.4f} | '\n",
        "          f'Test IoU: {test_iou:.4f} | '\n",
        "          f'Test Acc: {test_acc:.4f} | '\n",
        "          f'Test Precision: {test_precision:.4f} | '\n",
        "          f'Test Recall: {test_recall:.4f} | '\n",
        "          f'Test Dice: {test_dice:.4f}')\n",
        "\n",
        "    return random_samples\n",
        "\n",
        "def visualize_results(random_samples):\n",
        "    # Create a figure with subplots\n",
        "    fig, axes = plt.subplots(5, 4, figsize=(20, 25))\n",
        "    plt.subplots_adjust(hspace=0.3)\n",
        "\n",
        "    # Define custom colormap for change masks\n",
        "    colors = ['black', 'red', 'blue']  # Customize colors for your classes\n",
        "    cmap = plt.matplotlib.colors.ListedColormap(colors)\n",
        "\n",
        "    class_names = ['No Change', 'Class 1', 'Class 2']  # Replace with your class names\n",
        "\n",
        "    for idx, sample in enumerate(random_samples):\n",
        "        # Normalize and convert images for display\n",
        "        img1 = sample['image1'].numpy().transpose(1, 2, 0)\n",
        "        img2 = sample['image2'].numpy().transpose(1, 2, 0)\n",
        "        img1 = (img1 - img1.min()) / (img1.max() - img1.min())\n",
        "        img2 = (img2 - img2.min()) / (img2.max() - img2.min())\n",
        "\n",
        "        # Get masks\n",
        "        pred_mask = sample['pred'].numpy()\n",
        "        true_mask = sample['label'].numpy()\n",
        "\n",
        "        # Plot images and masks\n",
        "        axes[idx, 0].imshow(img1)\n",
        "        axes[idx, 0].set_title('Image 1')\n",
        "        axes[idx, 0].axis('off')\n",
        "\n",
        "        axes[idx, 1].imshow(img2)\n",
        "        axes[idx, 1].set_title('Image 2')\n",
        "        axes[idx, 1].axis('off')\n",
        "\n",
        "        # Plot predicted mask\n",
        "        pred_plot = axes[idx, 2].imshow(pred_mask, cmap=cmap, vmin=0, vmax=2)\n",
        "        axes[idx, 2].set_title('Predicted Change')\n",
        "        axes[idx, 2].axis('off')\n",
        "\n",
        "        # Plot ground truth mask\n",
        "        true_plot = axes[idx, 3].imshow(true_mask, cmap=cmap, vmin=0, vmax=2)\n",
        "        axes[idx, 3].set_title('Ground Truth')\n",
        "        axes[idx, 3].axis('off')\n",
        "\n",
        "        # Add class probabilities as text\n",
        "        probs = sample['probabilities'].mean(dim=(1, 2)).numpy()\n",
        "        prob_text = \"\\n\".join([f\"{class_names[i]}: {probs[i]:.3f}\" for i in range(3)])\n",
        "        axes[idx, 2].text(1.5, 0.5, prob_text,\n",
        "                         transform=axes[idx, 2].transAxes,\n",
        "                         bbox=dict(facecolor='white', alpha=0.8))\n",
        "\n",
        "    # Add colorbar\n",
        "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
        "    cbar = fig.colorbar(pred_plot, cax=cbar_ax)\n",
        "    cbar.set_ticks([0, 1, 2])\n",
        "    cbar.set_ticklabels(class_names)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def main():\n",
        "    # Set device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Load model\n",
        "    model = SiamUnet_conc(3, 3).to(device)\n",
        "    # Load the checkpoint properly\n",
        "    checkpoint = torch.load('best_model_multiclass.pt', weights_only=True)\n",
        "    # Extract just the model state dict\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "\n",
        "    # Test the model\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    random_samples = test_model(model, test_loader, criterion, device)\n",
        "\n",
        "    # Visualize results\n",
        "    visualize_results(random_samples)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_model(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_test_loss = 0.0\n",
        "    metrics_sum = {\n",
        "        'acc': 0,\n",
        "        'precision': 0,\n",
        "        'recall': 0,\n",
        "        'dice': 0,\n",
        "        'iou': 0\n",
        "    }\n",
        "    test_samples = 0\n",
        "\n",
        "    # For visualization\n",
        "    random_samples = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs1, inputs2, labels in test_loader:\n",
        "            inputs1, inputs2, labels = inputs1.to(device), inputs2.to(device), labels.to(device)\n",
        "            outputs = model(inputs1, inputs2)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Calculate metrics\n",
        "            metrics = calculate_metrics(outputs, labels)\n",
        "\n",
        "            # Accumulate metrics\n",
        "            batch_size = inputs1.size(0)\n",
        "            running_test_loss += loss.item() * batch_size\n",
        "            for key in metrics_sum.keys():\n",
        "                metrics_sum[key] += metrics[key] * batch_size\n",
        "            test_samples += batch_size\n",
        "\n",
        "            # Store random samples for visualization\n",
        "            if len(random_samples) < 5:\n",
        "                # Get predictions\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "                # Randomly select samples from this batch\n",
        "                for i in range(min(batch_size, 5 - len(random_samples))):\n",
        "                    if random.random() < 0.2:  # 20% chance to select each sample\n",
        "                        random_samples.append({\n",
        "                            'image1': inputs1[i].cpu(),\n",
        "                            'image2': inputs2[i].cpu(),\n",
        "                            'label': labels[i].cpu(),\n",
        "                            'pred': preds[i].cpu(),\n",
        "                            'probabilities': torch.softmax(outputs[i], dim=0).cpu()\n",
        "                        })\n",
        "\n",
        "    # Calculate final metrics\n",
        "    test_loss = running_test_loss / test_samples\n",
        "    avg_metrics = {key: metrics_sum[key] / test_samples for key in metrics_sum.keys()}\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Test Loss: {test_loss:.4f} | \"\n",
        "          f\"Test IoU: {avg_metrics['iou']:.4f} | \"\n",
        "          f\"Test Acc: {avg_metrics['acc']:.4f} | \"\n",
        "          f\"Test Precision: {avg_metrics['precision']:.4f} | \"\n",
        "          f\"Test Recall: {avg_metrics['recall']:.4f} | \"\n",
        "          f\"Test Dice: {avg_metrics['dice']:.4f}\")\n",
        "\n",
        "    return random_samples\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 5939633,
          "sourceId": 9710583,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30787,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
